<!DOCTYPE html>
<html>
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=emulateIE7" />
    <title>Coverage for C:\Users\paper\Anaconda3\Lib\site-packages\torch\nn\init.py: 48%</title>
    <link rel="stylesheet" href="style.css" type="text/css">
    <script type="text/javascript" src="jquery.min.js"></script>
    <script type="text/javascript" src="jquery.hotkeys.js"></script>
    <script type="text/javascript" src="jquery.isonscreen.js"></script>
    <script type="text/javascript" src="coverage_html.js"></script>
    <script type="text/javascript">
        jQuery(document).ready(coverage.pyfile_ready);
    </script>
</head>
<body class="pyfile">
<div id="header">
    <div class="content">
        <h1>Coverage for <b>C:\Users\paper\Anaconda3\Lib\site-packages\torch\nn\init.py</b> :
            <span class="pc_cov">48%</span>
        </h1>
        <img id="keyboard_icon" src="keybd_closed.png" alt="Show keyboard shortcuts" />
        <h2 class="stats">
            154 statements &nbsp;
            <span class="run shortkey_r button_toggle_run">74 run</span>
            <span class="mis show_mis shortkey_m button_toggle_mis">80 missing</span>
            <span class="exc show_exc shortkey_x button_toggle_exc">0 excluded</span>
        </h2>
    </div>
</div>
<div class="help_panel">
    <img id="panel_icon" src="keybd_open.png" alt="Hide keyboard shortcuts" />
    <p class="legend">Hot-keys on this page</p>
    <div>
    <p class="keyhelp">
        <span class="key">r</span>
        <span class="key">m</span>
        <span class="key">x</span>
        <span class="key">p</span> &nbsp; toggle line displays
    </p>
    <p class="keyhelp">
        <span class="key">j</span>
        <span class="key">k</span> &nbsp; next/prev highlighted chunk
    </p>
    <p class="keyhelp">
        <span class="key">0</span> &nbsp; (zero) top of page
    </p>
    <p class="keyhelp">
        <span class="key">1</span> &nbsp; (one) first highlighted chunk
    </p>
    </div>
</div>
<div id="source">
    <p id="t1" class="run"><span class="n"><a href="#t1">1</a></span><span class="t"><span class="key">from</span> <span class="nam">__future__</span> <span class="key">import</span> <span class="nam">division</span>&nbsp;</span><span class="r"></span></p>
    <p id="t2" class="pln"><span class="n"><a href="#t2">2</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t3" class="run"><span class="n"><a href="#t3">3</a></span><span class="t"><span class="key">import</span> <span class="nam">math</span>&nbsp;</span><span class="r"></span></p>
    <p id="t4" class="run"><span class="n"><a href="#t4">4</a></span><span class="t"><span class="key">import</span> <span class="nam">warnings</span>&nbsp;</span><span class="r"></span></p>
    <p id="t5" class="pln"><span class="n"><a href="#t5">5</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t6" class="run"><span class="n"><a href="#t6">6</a></span><span class="t"><span class="key">import</span> <span class="nam">torch</span>&nbsp;</span><span class="r"></span></p>
    <p id="t7" class="pln"><span class="n"><a href="#t7">7</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t8" class="pln"><span class="n"><a href="#t8">8</a></span><span class="t"><span class="com"># These no_grad_* functions are necessary as wrappers around the parts of these</span>&nbsp;</span><span class="r"></span></p>
    <p id="t9" class="pln"><span class="n"><a href="#t9">9</a></span><span class="t"><span class="com"># functions that use `with torch.no_grad()`. The JIT doesn't support context</span>&nbsp;</span><span class="r"></span></p>
    <p id="t10" class="pln"><span class="n"><a href="#t10">10</a></span><span class="t"><span class="com"># managers, so these need to be implemented as builtins. Using these wrappers</span>&nbsp;</span><span class="r"></span></p>
    <p id="t11" class="pln"><span class="n"><a href="#t11">11</a></span><span class="t"><span class="com"># lets us keep those builtins small and re-usable.</span>&nbsp;</span><span class="r"></span></p>
    <p id="t12" class="run"><span class="n"><a href="#t12">12</a></span><span class="t"><span class="key">def</span> <span class="nam">_no_grad_uniform_</span><span class="op">(</span><span class="nam">tensor</span><span class="op">,</span> <span class="nam">a</span><span class="op">,</span> <span class="nam">b</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t13" class="run"><span class="n"><a href="#t13">13</a></span><span class="t">    <span class="key">with</span> <span class="nam">torch</span><span class="op">.</span><span class="nam">no_grad</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t14" class="run"><span class="n"><a href="#t14">14</a></span><span class="t">        <span class="key">return</span> <span class="nam">tensor</span><span class="op">.</span><span class="nam">uniform_</span><span class="op">(</span><span class="nam">a</span><span class="op">,</span> <span class="nam">b</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t15" class="pln"><span class="n"><a href="#t15">15</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t16" class="pln"><span class="n"><a href="#t16">16</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t17" class="run"><span class="n"><a href="#t17">17</a></span><span class="t"><span class="key">def</span> <span class="nam">_no_grad_normal_</span><span class="op">(</span><span class="nam">tensor</span><span class="op">,</span> <span class="nam">mean</span><span class="op">,</span> <span class="nam">std</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t18" class="mis show_mis"><span class="n"><a href="#t18">18</a></span><span class="t">    <span class="key">with</span> <span class="nam">torch</span><span class="op">.</span><span class="nam">no_grad</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t19" class="mis show_mis"><span class="n"><a href="#t19">19</a></span><span class="t">        <span class="key">return</span> <span class="nam">tensor</span><span class="op">.</span><span class="nam">normal_</span><span class="op">(</span><span class="nam">mean</span><span class="op">,</span> <span class="nam">std</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t20" class="pln"><span class="n"><a href="#t20">20</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t21" class="pln"><span class="n"><a href="#t21">21</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t22" class="run"><span class="n"><a href="#t22">22</a></span><span class="t"><span class="key">def</span> <span class="nam">_no_grad_fill_</span><span class="op">(</span><span class="nam">tensor</span><span class="op">,</span> <span class="nam">val</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t23" class="mis show_mis"><span class="n"><a href="#t23">23</a></span><span class="t">    <span class="key">with</span> <span class="nam">torch</span><span class="op">.</span><span class="nam">no_grad</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t24" class="mis show_mis"><span class="n"><a href="#t24">24</a></span><span class="t">        <span class="key">return</span> <span class="nam">tensor</span><span class="op">.</span><span class="nam">fill_</span><span class="op">(</span><span class="nam">val</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t25" class="pln"><span class="n"><a href="#t25">25</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t26" class="pln"><span class="n"><a href="#t26">26</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t27" class="run"><span class="n"><a href="#t27">27</a></span><span class="t"><span class="key">def</span> <span class="nam">_no_grad_zero_</span><span class="op">(</span><span class="nam">tensor</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t28" class="mis show_mis"><span class="n"><a href="#t28">28</a></span><span class="t">    <span class="key">with</span> <span class="nam">torch</span><span class="op">.</span><span class="nam">no_grad</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t29" class="mis show_mis"><span class="n"><a href="#t29">29</a></span><span class="t">        <span class="key">return</span> <span class="nam">tensor</span><span class="op">.</span><span class="nam">zero_</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t30" class="pln"><span class="n"><a href="#t30">30</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t31" class="pln"><span class="n"><a href="#t31">31</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t32" class="run"><span class="n"><a href="#t32">32</a></span><span class="t"><span class="key">def</span> <span class="nam">calculate_gain</span><span class="op">(</span><span class="nam">nonlinearity</span><span class="op">,</span> <span class="nam">param</span><span class="op">=</span><span class="key">None</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t33" class="pln"><span class="n"><a href="#t33">33</a></span><span class="t">    <span class="str">r"""Return the recommended gain value for the given nonlinearity function.</span>&nbsp;</span><span class="r"></span></p>
    <p id="t34" class="pln"><span class="n"><a href="#t34">34</a></span><span class="t"><span class="str">    The values are as follows:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t35" class="pln"><span class="n"><a href="#t35">35</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t36" class="pln"><span class="n"><a href="#t36">36</a></span><span class="t"><span class="str">    ================= ====================================================</span>&nbsp;</span><span class="r"></span></p>
    <p id="t37" class="pln"><span class="n"><a href="#t37">37</a></span><span class="t"><span class="str">    nonlinearity      gain</span>&nbsp;</span><span class="r"></span></p>
    <p id="t38" class="pln"><span class="n"><a href="#t38">38</a></span><span class="t"><span class="str">    ================= ====================================================</span>&nbsp;</span><span class="r"></span></p>
    <p id="t39" class="pln"><span class="n"><a href="#t39">39</a></span><span class="t"><span class="str">    Linear / Identity :math:`1`</span>&nbsp;</span><span class="r"></span></p>
    <p id="t40" class="pln"><span class="n"><a href="#t40">40</a></span><span class="t"><span class="str">    Conv{1,2,3}D      :math:`1`</span>&nbsp;</span><span class="r"></span></p>
    <p id="t41" class="pln"><span class="n"><a href="#t41">41</a></span><span class="t"><span class="str">    Sigmoid           :math:`1`</span>&nbsp;</span><span class="r"></span></p>
    <p id="t42" class="pln"><span class="n"><a href="#t42">42</a></span><span class="t"><span class="str">    Tanh              :math:`\frac{5}{3}`</span>&nbsp;</span><span class="r"></span></p>
    <p id="t43" class="pln"><span class="n"><a href="#t43">43</a></span><span class="t"><span class="str">    ReLU              :math:`\sqrt{2}`</span>&nbsp;</span><span class="r"></span></p>
    <p id="t44" class="pln"><span class="n"><a href="#t44">44</a></span><span class="t"><span class="str">    Leaky Relu        :math:`\sqrt{\frac{2}{1 + \text{negative\_slope}^2}}`</span>&nbsp;</span><span class="r"></span></p>
    <p id="t45" class="pln"><span class="n"><a href="#t45">45</a></span><span class="t"><span class="str">    ================= ====================================================</span>&nbsp;</span><span class="r"></span></p>
    <p id="t46" class="pln"><span class="n"><a href="#t46">46</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t47" class="pln"><span class="n"><a href="#t47">47</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t48" class="pln"><span class="n"><a href="#t48">48</a></span><span class="t"><span class="str">        nonlinearity: the non-linear function (`nn.functional` name)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t49" class="pln"><span class="n"><a href="#t49">49</a></span><span class="t"><span class="str">        param: optional parameter for the non-linear function</span>&nbsp;</span><span class="r"></span></p>
    <p id="t50" class="pln"><span class="n"><a href="#t50">50</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t51" class="pln"><span class="n"><a href="#t51">51</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t52" class="pln"><span class="n"><a href="#t52">52</a></span><span class="t"><span class="str">        >>> gain = nn.init.calculate_gain('leaky_relu', 0.2)  # leaky_relu with negative_slope=0.2</span>&nbsp;</span><span class="r"></span></p>
    <p id="t53" class="pln"><span class="n"><a href="#t53">53</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p id="t54" class="run"><span class="n"><a href="#t54">54</a></span><span class="t">    <span class="nam">linear_fns</span> <span class="op">=</span> <span class="op">[</span><span class="str">'linear'</span><span class="op">,</span> <span class="str">'conv1d'</span><span class="op">,</span> <span class="str">'conv2d'</span><span class="op">,</span> <span class="str">'conv3d'</span><span class="op">,</span> <span class="str">'conv_transpose1d'</span><span class="op">,</span> <span class="str">'conv_transpose2d'</span><span class="op">,</span> <span class="str">'conv_transpose3d'</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p id="t55" class="run"><span class="n"><a href="#t55">55</a></span><span class="t">    <span class="key">if</span> <span class="nam">nonlinearity</span> <span class="key">in</span> <span class="nam">linear_fns</span> <span class="key">or</span> <span class="nam">nonlinearity</span> <span class="op">==</span> <span class="str">'sigmoid'</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t56" class="mis show_mis"><span class="n"><a href="#t56">56</a></span><span class="t">        <span class="key">return</span> <span class="num">1</span>&nbsp;</span><span class="r"></span></p>
    <p id="t57" class="run"><span class="n"><a href="#t57">57</a></span><span class="t">    <span class="key">elif</span> <span class="nam">nonlinearity</span> <span class="op">==</span> <span class="str">'tanh'</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t58" class="mis show_mis"><span class="n"><a href="#t58">58</a></span><span class="t">        <span class="key">return</span> <span class="num">5.0</span> <span class="op">/</span> <span class="num">3</span>&nbsp;</span><span class="r"></span></p>
    <p id="t59" class="run"><span class="n"><a href="#t59">59</a></span><span class="t">    <span class="key">elif</span> <span class="nam">nonlinearity</span> <span class="op">==</span> <span class="str">'relu'</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t60" class="mis show_mis"><span class="n"><a href="#t60">60</a></span><span class="t">        <span class="key">return</span> <span class="nam">math</span><span class="op">.</span><span class="nam">sqrt</span><span class="op">(</span><span class="num">2.0</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t61" class="run"><span class="n"><a href="#t61">61</a></span><span class="t">    <span class="key">elif</span> <span class="nam">nonlinearity</span> <span class="op">==</span> <span class="str">'leaky_relu'</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t62" class="run"><span class="n"><a href="#t62">62</a></span><span class="t">        <span class="key">if</span> <span class="nam">param</span> <span class="key">is</span> <span class="key">None</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t63" class="mis show_mis"><span class="n"><a href="#t63">63</a></span><span class="t">            <span class="nam">negative_slope</span> <span class="op">=</span> <span class="num">0.01</span>&nbsp;</span><span class="r"></span></p>
    <p id="t64" class="run"><span class="n"><a href="#t64">64</a></span><span class="t">        <span class="key">elif</span> <span class="key">not</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">param</span><span class="op">,</span> <span class="nam">bool</span><span class="op">)</span> <span class="key">and</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">param</span><span class="op">,</span> <span class="nam">int</span><span class="op">)</span> <span class="key">or</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">param</span><span class="op">,</span> <span class="nam">float</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t65" class="pln"><span class="n"><a href="#t65">65</a></span><span class="t">            <span class="com"># True/False are instances of int, hence check above</span>&nbsp;</span><span class="r"></span></p>
    <p id="t66" class="run"><span class="n"><a href="#t66">66</a></span><span class="t">            <span class="nam">negative_slope</span> <span class="op">=</span> <span class="nam">param</span>&nbsp;</span><span class="r"></span></p>
    <p id="t67" class="pln"><span class="n"><a href="#t67">67</a></span><span class="t">        <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t68" class="mis show_mis"><span class="n"><a href="#t68">68</a></span><span class="t">            <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span><span class="str">"negative_slope {} not a valid number"</span><span class="op">.</span><span class="nam">format</span><span class="op">(</span><span class="nam">param</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t69" class="run"><span class="n"><a href="#t69">69</a></span><span class="t">        <span class="key">return</span> <span class="nam">math</span><span class="op">.</span><span class="nam">sqrt</span><span class="op">(</span><span class="num">2.0</span> <span class="op">/</span> <span class="op">(</span><span class="num">1</span> <span class="op">+</span> <span class="nam">negative_slope</span> <span class="op">**</span> <span class="num">2</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t70" class="pln"><span class="n"><a href="#t70">70</a></span><span class="t">    <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t71" class="mis show_mis"><span class="n"><a href="#t71">71</a></span><span class="t">        <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span><span class="str">"Unsupported nonlinearity {}"</span><span class="op">.</span><span class="nam">format</span><span class="op">(</span><span class="nam">nonlinearity</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t72" class="pln"><span class="n"><a href="#t72">72</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t73" class="pln"><span class="n"><a href="#t73">73</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t74" class="run"><span class="n"><a href="#t74">74</a></span><span class="t"><span class="key">def</span> <span class="nam">uniform_</span><span class="op">(</span><span class="nam">tensor</span><span class="op">,</span> <span class="nam">a</span><span class="op">=</span><span class="num">0.</span><span class="op">,</span> <span class="nam">b</span><span class="op">=</span><span class="num">1.</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t75" class="pln"><span class="n"><a href="#t75">75</a></span><span class="t">    <span class="com"># type: (Tensor, float, float) -> Tensor</span>&nbsp;</span><span class="r"></span></p>
    <p id="t76" class="pln"><span class="n"><a href="#t76">76</a></span><span class="t">    <span class="str">r"""Fills the input Tensor with values drawn from the uniform</span>&nbsp;</span><span class="r"></span></p>
    <p id="t77" class="pln"><span class="n"><a href="#t77">77</a></span><span class="t"><span class="str">    distribution :math:`\mathcal{U}(a, b)`.</span>&nbsp;</span><span class="r"></span></p>
    <p id="t78" class="pln"><span class="n"><a href="#t78">78</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t79" class="pln"><span class="n"><a href="#t79">79</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t80" class="pln"><span class="n"><a href="#t80">80</a></span><span class="t"><span class="str">        tensor: an n-dimensional `torch.Tensor`</span>&nbsp;</span><span class="r"></span></p>
    <p id="t81" class="pln"><span class="n"><a href="#t81">81</a></span><span class="t"><span class="str">        a: the lower bound of the uniform distribution</span>&nbsp;</span><span class="r"></span></p>
    <p id="t82" class="pln"><span class="n"><a href="#t82">82</a></span><span class="t"><span class="str">        b: the upper bound of the uniform distribution</span>&nbsp;</span><span class="r"></span></p>
    <p id="t83" class="pln"><span class="n"><a href="#t83">83</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t84" class="pln"><span class="n"><a href="#t84">84</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t85" class="pln"><span class="n"><a href="#t85">85</a></span><span class="t"><span class="str">        >>> w = torch.empty(3, 5)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t86" class="pln"><span class="n"><a href="#t86">86</a></span><span class="t"><span class="str">        >>> nn.init.uniform_(w)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t87" class="pln"><span class="n"><a href="#t87">87</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p id="t88" class="run"><span class="n"><a href="#t88">88</a></span><span class="t">    <span class="key">return</span> <span class="nam">_no_grad_uniform_</span><span class="op">(</span><span class="nam">tensor</span><span class="op">,</span> <span class="nam">a</span><span class="op">,</span> <span class="nam">b</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t89" class="pln"><span class="n"><a href="#t89">89</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t90" class="pln"><span class="n"><a href="#t90">90</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t91" class="run"><span class="n"><a href="#t91">91</a></span><span class="t"><span class="key">def</span> <span class="nam">normal_</span><span class="op">(</span><span class="nam">tensor</span><span class="op">,</span> <span class="nam">mean</span><span class="op">=</span><span class="num">0.</span><span class="op">,</span> <span class="nam">std</span><span class="op">=</span><span class="num">1.</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t92" class="pln"><span class="n"><a href="#t92">92</a></span><span class="t">    <span class="com"># type: (Tensor, float, float) -> Tensor</span>&nbsp;</span><span class="r"></span></p>
    <p id="t93" class="pln"><span class="n"><a href="#t93">93</a></span><span class="t">    <span class="str">r"""Fills the input Tensor with values drawn from the normal</span>&nbsp;</span><span class="r"></span></p>
    <p id="t94" class="pln"><span class="n"><a href="#t94">94</a></span><span class="t"><span class="str">    distribution :math:`\mathcal{N}(\text{mean}, \text{std}^2)`.</span>&nbsp;</span><span class="r"></span></p>
    <p id="t95" class="pln"><span class="n"><a href="#t95">95</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t96" class="pln"><span class="n"><a href="#t96">96</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t97" class="pln"><span class="n"><a href="#t97">97</a></span><span class="t"><span class="str">        tensor: an n-dimensional `torch.Tensor`</span>&nbsp;</span><span class="r"></span></p>
    <p id="t98" class="pln"><span class="n"><a href="#t98">98</a></span><span class="t"><span class="str">        mean: the mean of the normal distribution</span>&nbsp;</span><span class="r"></span></p>
    <p id="t99" class="pln"><span class="n"><a href="#t99">99</a></span><span class="t"><span class="str">        std: the standard deviation of the normal distribution</span>&nbsp;</span><span class="r"></span></p>
    <p id="t100" class="pln"><span class="n"><a href="#t100">100</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t101" class="pln"><span class="n"><a href="#t101">101</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t102" class="pln"><span class="n"><a href="#t102">102</a></span><span class="t"><span class="str">        >>> w = torch.empty(3, 5)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t103" class="pln"><span class="n"><a href="#t103">103</a></span><span class="t"><span class="str">        >>> nn.init.normal_(w)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t104" class="pln"><span class="n"><a href="#t104">104</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p id="t105" class="mis show_mis"><span class="n"><a href="#t105">105</a></span><span class="t">    <span class="key">return</span> <span class="nam">_no_grad_normal_</span><span class="op">(</span><span class="nam">tensor</span><span class="op">,</span> <span class="nam">mean</span><span class="op">,</span> <span class="nam">std</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t106" class="pln"><span class="n"><a href="#t106">106</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t107" class="pln"><span class="n"><a href="#t107">107</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t108" class="run"><span class="n"><a href="#t108">108</a></span><span class="t"><span class="key">def</span> <span class="nam">constant_</span><span class="op">(</span><span class="nam">tensor</span><span class="op">,</span> <span class="nam">val</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t109" class="pln"><span class="n"><a href="#t109">109</a></span><span class="t">    <span class="com"># type: (Tensor, float) -> Tensor</span>&nbsp;</span><span class="r"></span></p>
    <p id="t110" class="pln"><span class="n"><a href="#t110">110</a></span><span class="t">    <span class="str">r"""Fills the input Tensor with the value :math:`\text{val}`.</span>&nbsp;</span><span class="r"></span></p>
    <p id="t111" class="pln"><span class="n"><a href="#t111">111</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t112" class="pln"><span class="n"><a href="#t112">112</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t113" class="pln"><span class="n"><a href="#t113">113</a></span><span class="t"><span class="str">        tensor: an n-dimensional `torch.Tensor`</span>&nbsp;</span><span class="r"></span></p>
    <p id="t114" class="pln"><span class="n"><a href="#t114">114</a></span><span class="t"><span class="str">        val: the value to fill the tensor with</span>&nbsp;</span><span class="r"></span></p>
    <p id="t115" class="pln"><span class="n"><a href="#t115">115</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t116" class="pln"><span class="n"><a href="#t116">116</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t117" class="pln"><span class="n"><a href="#t117">117</a></span><span class="t"><span class="str">        >>> w = torch.empty(3, 5)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t118" class="pln"><span class="n"><a href="#t118">118</a></span><span class="t"><span class="str">        >>> nn.init.constant_(w, 0.3)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t119" class="pln"><span class="n"><a href="#t119">119</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p id="t120" class="mis show_mis"><span class="n"><a href="#t120">120</a></span><span class="t">    <span class="key">return</span> <span class="nam">_no_grad_fill_</span><span class="op">(</span><span class="nam">tensor</span><span class="op">,</span> <span class="nam">val</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t121" class="pln"><span class="n"><a href="#t121">121</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t122" class="pln"><span class="n"><a href="#t122">122</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t123" class="run"><span class="n"><a href="#t123">123</a></span><span class="t"><span class="key">def</span> <span class="nam">ones_</span><span class="op">(</span><span class="nam">tensor</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t124" class="pln"><span class="n"><a href="#t124">124</a></span><span class="t">    <span class="com"># type: (Tensor) -> Tensor</span>&nbsp;</span><span class="r"></span></p>
    <p id="t125" class="pln"><span class="n"><a href="#t125">125</a></span><span class="t">    <span class="str">r"""Fills the input Tensor with the scalar value `1`.</span>&nbsp;</span><span class="r"></span></p>
    <p id="t126" class="pln"><span class="n"><a href="#t126">126</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t127" class="pln"><span class="n"><a href="#t127">127</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t128" class="pln"><span class="n"><a href="#t128">128</a></span><span class="t"><span class="str">        tensor: an n-dimensional `torch.Tensor`</span>&nbsp;</span><span class="r"></span></p>
    <p id="t129" class="pln"><span class="n"><a href="#t129">129</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t130" class="pln"><span class="n"><a href="#t130">130</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t131" class="pln"><span class="n"><a href="#t131">131</a></span><span class="t"><span class="str">        >>> w = torch.empty(3, 5)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t132" class="pln"><span class="n"><a href="#t132">132</a></span><span class="t"><span class="str">        >>> nn.init.ones_(w)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t133" class="pln"><span class="n"><a href="#t133">133</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p id="t134" class="mis show_mis"><span class="n"><a href="#t134">134</a></span><span class="t">    <span class="key">return</span> <span class="nam">_no_grad_fill_</span><span class="op">(</span><span class="nam">tensor</span><span class="op">,</span> <span class="num">1.</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t135" class="pln"><span class="n"><a href="#t135">135</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t136" class="pln"><span class="n"><a href="#t136">136</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t137" class="run"><span class="n"><a href="#t137">137</a></span><span class="t"><span class="key">def</span> <span class="nam">zeros_</span><span class="op">(</span><span class="nam">tensor</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t138" class="pln"><span class="n"><a href="#t138">138</a></span><span class="t">    <span class="com"># type: (Tensor) -> Tensor</span>&nbsp;</span><span class="r"></span></p>
    <p id="t139" class="pln"><span class="n"><a href="#t139">139</a></span><span class="t">    <span class="str">r"""Fills the input Tensor with the scalar value `0`.</span>&nbsp;</span><span class="r"></span></p>
    <p id="t140" class="pln"><span class="n"><a href="#t140">140</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t141" class="pln"><span class="n"><a href="#t141">141</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t142" class="pln"><span class="n"><a href="#t142">142</a></span><span class="t"><span class="str">        tensor: an n-dimensional `torch.Tensor`</span>&nbsp;</span><span class="r"></span></p>
    <p id="t143" class="pln"><span class="n"><a href="#t143">143</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t144" class="pln"><span class="n"><a href="#t144">144</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t145" class="pln"><span class="n"><a href="#t145">145</a></span><span class="t"><span class="str">        >>> w = torch.empty(3, 5)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t146" class="pln"><span class="n"><a href="#t146">146</a></span><span class="t"><span class="str">        >>> nn.init.zeros_(w)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t147" class="pln"><span class="n"><a href="#t147">147</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p id="t148" class="mis show_mis"><span class="n"><a href="#t148">148</a></span><span class="t">    <span class="key">return</span> <span class="nam">_no_grad_zero_</span><span class="op">(</span><span class="nam">tensor</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t149" class="pln"><span class="n"><a href="#t149">149</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t150" class="pln"><span class="n"><a href="#t150">150</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t151" class="run"><span class="n"><a href="#t151">151</a></span><span class="t"><span class="key">def</span> <span class="nam">eye_</span><span class="op">(</span><span class="nam">tensor</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t152" class="pln"><span class="n"><a href="#t152">152</a></span><span class="t">    <span class="str">r"""Fills the 2-dimensional input `Tensor` with the identity</span>&nbsp;</span><span class="r"></span></p>
    <p id="t153" class="pln"><span class="n"><a href="#t153">153</a></span><span class="t"><span class="str">    matrix. Preserves the identity of the inputs in `Linear` layers, where as</span>&nbsp;</span><span class="r"></span></p>
    <p id="t154" class="pln"><span class="n"><a href="#t154">154</a></span><span class="t"><span class="str">    many inputs are preserved as possible.</span>&nbsp;</span><span class="r"></span></p>
    <p id="t155" class="pln"><span class="n"><a href="#t155">155</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t156" class="pln"><span class="n"><a href="#t156">156</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t157" class="pln"><span class="n"><a href="#t157">157</a></span><span class="t"><span class="str">        tensor: a 2-dimensional `torch.Tensor`</span>&nbsp;</span><span class="r"></span></p>
    <p id="t158" class="pln"><span class="n"><a href="#t158">158</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t159" class="pln"><span class="n"><a href="#t159">159</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t160" class="pln"><span class="n"><a href="#t160">160</a></span><span class="t"><span class="str">        >>> w = torch.empty(3, 5)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t161" class="pln"><span class="n"><a href="#t161">161</a></span><span class="t"><span class="str">        >>> nn.init.eye_(w)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t162" class="pln"><span class="n"><a href="#t162">162</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p id="t163" class="mis show_mis"><span class="n"><a href="#t163">163</a></span><span class="t">    <span class="key">if</span> <span class="nam">tensor</span><span class="op">.</span><span class="nam">ndimension</span><span class="op">(</span><span class="op">)</span> <span class="op">!=</span> <span class="num">2</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t164" class="mis show_mis"><span class="n"><a href="#t164">164</a></span><span class="t">        <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span><span class="str">"Only tensors with 2 dimensions are supported"</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t165" class="pln"><span class="n"><a href="#t165">165</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t166" class="mis show_mis"><span class="n"><a href="#t166">166</a></span><span class="t">    <span class="key">with</span> <span class="nam">torch</span><span class="op">.</span><span class="nam">no_grad</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t167" class="mis show_mis"><span class="n"><a href="#t167">167</a></span><span class="t">        <span class="nam">torch</span><span class="op">.</span><span class="nam">eye</span><span class="op">(</span><span class="op">*</span><span class="nam">tensor</span><span class="op">.</span><span class="nam">shape</span><span class="op">,</span> <span class="nam">out</span><span class="op">=</span><span class="nam">tensor</span><span class="op">,</span> <span class="nam">requires_grad</span><span class="op">=</span><span class="nam">tensor</span><span class="op">.</span><span class="nam">requires_grad</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t168" class="mis show_mis"><span class="n"><a href="#t168">168</a></span><span class="t">    <span class="key">return</span> <span class="nam">tensor</span>&nbsp;</span><span class="r"></span></p>
    <p id="t169" class="pln"><span class="n"><a href="#t169">169</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t170" class="pln"><span class="n"><a href="#t170">170</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t171" class="run"><span class="n"><a href="#t171">171</a></span><span class="t"><span class="key">def</span> <span class="nam">dirac_</span><span class="op">(</span><span class="nam">tensor</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t172" class="pln"><span class="n"><a href="#t172">172</a></span><span class="t">    <span class="str">r"""Fills the {3, 4, 5}-dimensional input `Tensor` with the Dirac</span>&nbsp;</span><span class="r"></span></p>
    <p id="t173" class="pln"><span class="n"><a href="#t173">173</a></span><span class="t"><span class="str">    delta function. Preserves the identity of the inputs in `Convolutional`</span>&nbsp;</span><span class="r"></span></p>
    <p id="t174" class="pln"><span class="n"><a href="#t174">174</a></span><span class="t"><span class="str">    layers, where as many input channels are preserved as possible.</span>&nbsp;</span><span class="r"></span></p>
    <p id="t175" class="pln"><span class="n"><a href="#t175">175</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t176" class="pln"><span class="n"><a href="#t176">176</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t177" class="pln"><span class="n"><a href="#t177">177</a></span><span class="t"><span class="str">        tensor: a {3, 4, 5}-dimensional `torch.Tensor`</span>&nbsp;</span><span class="r"></span></p>
    <p id="t178" class="pln"><span class="n"><a href="#t178">178</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t179" class="pln"><span class="n"><a href="#t179">179</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t180" class="pln"><span class="n"><a href="#t180">180</a></span><span class="t"><span class="str">        >>> w = torch.empty(3, 16, 5, 5)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t181" class="pln"><span class="n"><a href="#t181">181</a></span><span class="t"><span class="str">        >>> nn.init.dirac_(w)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t182" class="pln"><span class="n"><a href="#t182">182</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p id="t183" class="mis show_mis"><span class="n"><a href="#t183">183</a></span><span class="t">    <span class="nam">dimensions</span> <span class="op">=</span> <span class="nam">tensor</span><span class="op">.</span><span class="nam">ndimension</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t184" class="mis show_mis"><span class="n"><a href="#t184">184</a></span><span class="t">    <span class="key">if</span> <span class="nam">dimensions</span> <span class="key">not</span> <span class="key">in</span> <span class="op">[</span><span class="num">3</span><span class="op">,</span> <span class="num">4</span><span class="op">,</span> <span class="num">5</span><span class="op">]</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t185" class="mis show_mis"><span class="n"><a href="#t185">185</a></span><span class="t">        <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span><span class="str">"Only tensors with 3, 4, or 5 dimensions are supported"</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t186" class="pln"><span class="n"><a href="#t186">186</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t187" class="mis show_mis"><span class="n"><a href="#t187">187</a></span><span class="t">    <span class="nam">sizes</span> <span class="op">=</span> <span class="nam">tensor</span><span class="op">.</span><span class="nam">size</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t188" class="mis show_mis"><span class="n"><a href="#t188">188</a></span><span class="t">    <span class="nam">min_dim</span> <span class="op">=</span> <span class="nam">min</span><span class="op">(</span><span class="nam">sizes</span><span class="op">[</span><span class="num">0</span><span class="op">]</span><span class="op">,</span> <span class="nam">sizes</span><span class="op">[</span><span class="num">1</span><span class="op">]</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t189" class="mis show_mis"><span class="n"><a href="#t189">189</a></span><span class="t">    <span class="key">with</span> <span class="nam">torch</span><span class="op">.</span><span class="nam">no_grad</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t190" class="mis show_mis"><span class="n"><a href="#t190">190</a></span><span class="t">        <span class="nam">tensor</span><span class="op">.</span><span class="nam">zero_</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t191" class="pln"><span class="n"><a href="#t191">191</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t192" class="mis show_mis"><span class="n"><a href="#t192">192</a></span><span class="t">        <span class="key">for</span> <span class="nam">d</span> <span class="key">in</span> <span class="nam">range</span><span class="op">(</span><span class="nam">min_dim</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t193" class="mis show_mis"><span class="n"><a href="#t193">193</a></span><span class="t">            <span class="key">if</span> <span class="nam">dimensions</span> <span class="op">==</span> <span class="num">3</span><span class="op">:</span>  <span class="com"># Temporal convolution</span>&nbsp;</span><span class="r"></span></p>
    <p id="t194" class="mis show_mis"><span class="n"><a href="#t194">194</a></span><span class="t">                <span class="nam">tensor</span><span class="op">[</span><span class="nam">d</span><span class="op">,</span> <span class="nam">d</span><span class="op">,</span> <span class="nam">tensor</span><span class="op">.</span><span class="nam">size</span><span class="op">(</span><span class="num">2</span><span class="op">)</span> <span class="op">//</span> <span class="num">2</span><span class="op">]</span> <span class="op">=</span> <span class="num">1</span>&nbsp;</span><span class="r"></span></p>
    <p id="t195" class="mis show_mis"><span class="n"><a href="#t195">195</a></span><span class="t">            <span class="key">elif</span> <span class="nam">dimensions</span> <span class="op">==</span> <span class="num">4</span><span class="op">:</span>  <span class="com"># Spatial convolution</span>&nbsp;</span><span class="r"></span></p>
    <p id="t196" class="mis show_mis"><span class="n"><a href="#t196">196</a></span><span class="t">                <span class="nam">tensor</span><span class="op">[</span><span class="nam">d</span><span class="op">,</span> <span class="nam">d</span><span class="op">,</span> <span class="nam">tensor</span><span class="op">.</span><span class="nam">size</span><span class="op">(</span><span class="num">2</span><span class="op">)</span> <span class="op">//</span> <span class="num">2</span><span class="op">,</span> <span class="nam">tensor</span><span class="op">.</span><span class="nam">size</span><span class="op">(</span><span class="num">3</span><span class="op">)</span> <span class="op">//</span> <span class="num">2</span><span class="op">]</span> <span class="op">=</span> <span class="num">1</span>&nbsp;</span><span class="r"></span></p>
    <p id="t197" class="pln"><span class="n"><a href="#t197">197</a></span><span class="t">            <span class="key">else</span><span class="op">:</span>  <span class="com"># Volumetric convolution</span>&nbsp;</span><span class="r"></span></p>
    <p id="t198" class="mis show_mis"><span class="n"><a href="#t198">198</a></span><span class="t">                <span class="nam">tensor</span><span class="op">[</span><span class="nam">d</span><span class="op">,</span> <span class="nam">d</span><span class="op">,</span> <span class="nam">tensor</span><span class="op">.</span><span class="nam">size</span><span class="op">(</span><span class="num">2</span><span class="op">)</span> <span class="op">//</span> <span class="num">2</span><span class="op">,</span> <span class="nam">tensor</span><span class="op">.</span><span class="nam">size</span><span class="op">(</span><span class="num">3</span><span class="op">)</span> <span class="op">//</span> <span class="num">2</span><span class="op">,</span> <span class="nam">tensor</span><span class="op">.</span><span class="nam">size</span><span class="op">(</span><span class="num">4</span><span class="op">)</span> <span class="op">//</span> <span class="num">2</span><span class="op">]</span> <span class="op">=</span> <span class="num">1</span>&nbsp;</span><span class="r"></span></p>
    <p id="t199" class="mis show_mis"><span class="n"><a href="#t199">199</a></span><span class="t">    <span class="key">return</span> <span class="nam">tensor</span>&nbsp;</span><span class="r"></span></p>
    <p id="t200" class="pln"><span class="n"><a href="#t200">200</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t201" class="pln"><span class="n"><a href="#t201">201</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t202" class="run"><span class="n"><a href="#t202">202</a></span><span class="t"><span class="key">def</span> <span class="nam">_calculate_fan_in_and_fan_out</span><span class="op">(</span><span class="nam">tensor</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t203" class="run"><span class="n"><a href="#t203">203</a></span><span class="t">    <span class="nam">dimensions</span> <span class="op">=</span> <span class="nam">tensor</span><span class="op">.</span><span class="nam">dim</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t204" class="run"><span class="n"><a href="#t204">204</a></span><span class="t">    <span class="key">if</span> <span class="nam">dimensions</span> <span class="op">&lt;</span> <span class="num">2</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t205" class="mis show_mis"><span class="n"><a href="#t205">205</a></span><span class="t">        <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span><span class="str">"Fan in and fan out can not be computed for tensor with fewer than 2 dimensions"</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t206" class="pln"><span class="n"><a href="#t206">206</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t207" class="run"><span class="n"><a href="#t207">207</a></span><span class="t">    <span class="nam">num_input_fmaps</span> <span class="op">=</span> <span class="nam">tensor</span><span class="op">.</span><span class="nam">size</span><span class="op">(</span><span class="num">1</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t208" class="run"><span class="n"><a href="#t208">208</a></span><span class="t">    <span class="nam">num_output_fmaps</span> <span class="op">=</span> <span class="nam">tensor</span><span class="op">.</span><span class="nam">size</span><span class="op">(</span><span class="num">0</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t209" class="run"><span class="n"><a href="#t209">209</a></span><span class="t">    <span class="nam">receptive_field_size</span> <span class="op">=</span> <span class="num">1</span>&nbsp;</span><span class="r"></span></p>
    <p id="t210" class="run"><span class="n"><a href="#t210">210</a></span><span class="t">    <span class="key">if</span> <span class="nam">tensor</span><span class="op">.</span><span class="nam">dim</span><span class="op">(</span><span class="op">)</span> <span class="op">></span> <span class="num">2</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t211" class="mis show_mis"><span class="n"><a href="#t211">211</a></span><span class="t">        <span class="nam">receptive_field_size</span> <span class="op">=</span> <span class="nam">tensor</span><span class="op">[</span><span class="num">0</span><span class="op">]</span><span class="op">[</span><span class="num">0</span><span class="op">]</span><span class="op">.</span><span class="nam">numel</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t212" class="run"><span class="n"><a href="#t212">212</a></span><span class="t">    <span class="nam">fan_in</span> <span class="op">=</span> <span class="nam">num_input_fmaps</span> <span class="op">*</span> <span class="nam">receptive_field_size</span>&nbsp;</span><span class="r"></span></p>
    <p id="t213" class="run"><span class="n"><a href="#t213">213</a></span><span class="t">    <span class="nam">fan_out</span> <span class="op">=</span> <span class="nam">num_output_fmaps</span> <span class="op">*</span> <span class="nam">receptive_field_size</span>&nbsp;</span><span class="r"></span></p>
    <p id="t214" class="pln"><span class="n"><a href="#t214">214</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t215" class="run"><span class="n"><a href="#t215">215</a></span><span class="t">    <span class="key">return</span> <span class="nam">fan_in</span><span class="op">,</span> <span class="nam">fan_out</span>&nbsp;</span><span class="r"></span></p>
    <p id="t216" class="pln"><span class="n"><a href="#t216">216</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t217" class="pln"><span class="n"><a href="#t217">217</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t218" class="run"><span class="n"><a href="#t218">218</a></span><span class="t"><span class="key">def</span> <span class="nam">xavier_uniform_</span><span class="op">(</span><span class="nam">tensor</span><span class="op">,</span> <span class="nam">gain</span><span class="op">=</span><span class="num">1.</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t219" class="pln"><span class="n"><a href="#t219">219</a></span><span class="t">    <span class="com"># type: (Tensor, float) -> Tensor</span>&nbsp;</span><span class="r"></span></p>
    <p id="t220" class="pln"><span class="n"><a href="#t220">220</a></span><span class="t">    <span class="str">r"""Fills the input `Tensor` with values according to the method</span>&nbsp;</span><span class="r"></span></p>
    <p id="t221" class="pln"><span class="n"><a href="#t221">221</a></span><span class="t"><span class="str">    described in `Understanding the difficulty of training deep feedforward</span>&nbsp;</span><span class="r"></span></p>
    <p id="t222" class="pln"><span class="n"><a href="#t222">222</a></span><span class="t"><span class="str">    neural networks` - Glorot, X. &amp; Bengio, Y. (2010), using a uniform</span>&nbsp;</span><span class="r"></span></p>
    <p id="t223" class="pln"><span class="n"><a href="#t223">223</a></span><span class="t"><span class="str">    distribution. The resulting tensor will have values sampled from</span>&nbsp;</span><span class="r"></span></p>
    <p id="t224" class="pln"><span class="n"><a href="#t224">224</a></span><span class="t"><span class="str">    :math:`\mathcal{U}(-a, a)` where</span>&nbsp;</span><span class="r"></span></p>
    <p id="t225" class="pln"><span class="n"><a href="#t225">225</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t226" class="pln"><span class="n"><a href="#t226">226</a></span><span class="t"><span class="str">    .. math::</span>&nbsp;</span><span class="r"></span></p>
    <p id="t227" class="pln"><span class="n"><a href="#t227">227</a></span><span class="t"><span class="str">        a = \text{gain} \times \sqrt{\frac{6}{\text{fan\_in} + \text{fan\_out}}}</span>&nbsp;</span><span class="r"></span></p>
    <p id="t228" class="pln"><span class="n"><a href="#t228">228</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t229" class="pln"><span class="n"><a href="#t229">229</a></span><span class="t"><span class="str">    Also known as Glorot initialization.</span>&nbsp;</span><span class="r"></span></p>
    <p id="t230" class="pln"><span class="n"><a href="#t230">230</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t231" class="pln"><span class="n"><a href="#t231">231</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t232" class="pln"><span class="n"><a href="#t232">232</a></span><span class="t"><span class="str">        tensor: an n-dimensional `torch.Tensor`</span>&nbsp;</span><span class="r"></span></p>
    <p id="t233" class="pln"><span class="n"><a href="#t233">233</a></span><span class="t"><span class="str">        gain: an optional scaling factor</span>&nbsp;</span><span class="r"></span></p>
    <p id="t234" class="pln"><span class="n"><a href="#t234">234</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t235" class="pln"><span class="n"><a href="#t235">235</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t236" class="pln"><span class="n"><a href="#t236">236</a></span><span class="t"><span class="str">        >>> w = torch.empty(3, 5)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t237" class="pln"><span class="n"><a href="#t237">237</a></span><span class="t"><span class="str">        >>> nn.init.xavier_uniform_(w, gain=nn.init.calculate_gain('relu'))</span>&nbsp;</span><span class="r"></span></p>
    <p id="t238" class="pln"><span class="n"><a href="#t238">238</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p id="t239" class="mis show_mis"><span class="n"><a href="#t239">239</a></span><span class="t">    <span class="nam">fan_in</span><span class="op">,</span> <span class="nam">fan_out</span> <span class="op">=</span> <span class="nam">_calculate_fan_in_and_fan_out</span><span class="op">(</span><span class="nam">tensor</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t240" class="mis show_mis"><span class="n"><a href="#t240">240</a></span><span class="t">    <span class="nam">std</span> <span class="op">=</span> <span class="nam">gain</span> <span class="op">*</span> <span class="nam">math</span><span class="op">.</span><span class="nam">sqrt</span><span class="op">(</span><span class="num">2.0</span> <span class="op">/</span> <span class="nam">float</span><span class="op">(</span><span class="nam">fan_in</span> <span class="op">+</span> <span class="nam">fan_out</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t241" class="mis show_mis"><span class="n"><a href="#t241">241</a></span><span class="t">    <span class="nam">a</span> <span class="op">=</span> <span class="nam">math</span><span class="op">.</span><span class="nam">sqrt</span><span class="op">(</span><span class="num">3.0</span><span class="op">)</span> <span class="op">*</span> <span class="nam">std</span>  <span class="com"># Calculate uniform bounds from standard deviation</span>&nbsp;</span><span class="r"></span></p>
    <p id="t242" class="pln"><span class="n"><a href="#t242">242</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t243" class="mis show_mis"><span class="n"><a href="#t243">243</a></span><span class="t">    <span class="key">return</span> <span class="nam">_no_grad_uniform_</span><span class="op">(</span><span class="nam">tensor</span><span class="op">,</span> <span class="op">-</span><span class="nam">a</span><span class="op">,</span> <span class="nam">a</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t244" class="pln"><span class="n"><a href="#t244">244</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t245" class="pln"><span class="n"><a href="#t245">245</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t246" class="run"><span class="n"><a href="#t246">246</a></span><span class="t"><span class="key">def</span> <span class="nam">xavier_normal_</span><span class="op">(</span><span class="nam">tensor</span><span class="op">,</span> <span class="nam">gain</span><span class="op">=</span><span class="num">1.</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t247" class="pln"><span class="n"><a href="#t247">247</a></span><span class="t">    <span class="com"># type: (Tensor, float) -> Tensor</span>&nbsp;</span><span class="r"></span></p>
    <p id="t248" class="pln"><span class="n"><a href="#t248">248</a></span><span class="t">    <span class="str">r"""Fills the input `Tensor` with values according to the method</span>&nbsp;</span><span class="r"></span></p>
    <p id="t249" class="pln"><span class="n"><a href="#t249">249</a></span><span class="t"><span class="str">    described in `Understanding the difficulty of training deep feedforward</span>&nbsp;</span><span class="r"></span></p>
    <p id="t250" class="pln"><span class="n"><a href="#t250">250</a></span><span class="t"><span class="str">    neural networks` - Glorot, X. &amp; Bengio, Y. (2010), using a normal</span>&nbsp;</span><span class="r"></span></p>
    <p id="t251" class="pln"><span class="n"><a href="#t251">251</a></span><span class="t"><span class="str">    distribution. The resulting tensor will have values sampled from</span>&nbsp;</span><span class="r"></span></p>
    <p id="t252" class="pln"><span class="n"><a href="#t252">252</a></span><span class="t"><span class="str">    :math:`\mathcal{N}(0, \text{std}^2)` where</span>&nbsp;</span><span class="r"></span></p>
    <p id="t253" class="pln"><span class="n"><a href="#t253">253</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t254" class="pln"><span class="n"><a href="#t254">254</a></span><span class="t"><span class="str">    .. math::</span>&nbsp;</span><span class="r"></span></p>
    <p id="t255" class="pln"><span class="n"><a href="#t255">255</a></span><span class="t"><span class="str">        \text{std} = \text{gain} \times \sqrt{\frac{2}{\text{fan\_in} + \text{fan\_out}}}</span>&nbsp;</span><span class="r"></span></p>
    <p id="t256" class="pln"><span class="n"><a href="#t256">256</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t257" class="pln"><span class="n"><a href="#t257">257</a></span><span class="t"><span class="str">    Also known as Glorot initialization.</span>&nbsp;</span><span class="r"></span></p>
    <p id="t258" class="pln"><span class="n"><a href="#t258">258</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t259" class="pln"><span class="n"><a href="#t259">259</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t260" class="pln"><span class="n"><a href="#t260">260</a></span><span class="t"><span class="str">        tensor: an n-dimensional `torch.Tensor`</span>&nbsp;</span><span class="r"></span></p>
    <p id="t261" class="pln"><span class="n"><a href="#t261">261</a></span><span class="t"><span class="str">        gain: an optional scaling factor</span>&nbsp;</span><span class="r"></span></p>
    <p id="t262" class="pln"><span class="n"><a href="#t262">262</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t263" class="pln"><span class="n"><a href="#t263">263</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t264" class="pln"><span class="n"><a href="#t264">264</a></span><span class="t"><span class="str">        >>> w = torch.empty(3, 5)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t265" class="pln"><span class="n"><a href="#t265">265</a></span><span class="t"><span class="str">        >>> nn.init.xavier_normal_(w)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t266" class="pln"><span class="n"><a href="#t266">266</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p id="t267" class="mis show_mis"><span class="n"><a href="#t267">267</a></span><span class="t">    <span class="nam">fan_in</span><span class="op">,</span> <span class="nam">fan_out</span> <span class="op">=</span> <span class="nam">_calculate_fan_in_and_fan_out</span><span class="op">(</span><span class="nam">tensor</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t268" class="mis show_mis"><span class="n"><a href="#t268">268</a></span><span class="t">    <span class="nam">std</span> <span class="op">=</span> <span class="nam">gain</span> <span class="op">*</span> <span class="nam">math</span><span class="op">.</span><span class="nam">sqrt</span><span class="op">(</span><span class="num">2.0</span> <span class="op">/</span> <span class="nam">float</span><span class="op">(</span><span class="nam">fan_in</span> <span class="op">+</span> <span class="nam">fan_out</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t269" class="pln"><span class="n"><a href="#t269">269</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t270" class="mis show_mis"><span class="n"><a href="#t270">270</a></span><span class="t">    <span class="key">return</span> <span class="nam">_no_grad_normal_</span><span class="op">(</span><span class="nam">tensor</span><span class="op">,</span> <span class="num">0.</span><span class="op">,</span> <span class="nam">std</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t271" class="pln"><span class="n"><a href="#t271">271</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t272" class="pln"><span class="n"><a href="#t272">272</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t273" class="run"><span class="n"><a href="#t273">273</a></span><span class="t"><span class="key">def</span> <span class="nam">_calculate_correct_fan</span><span class="op">(</span><span class="nam">tensor</span><span class="op">,</span> <span class="nam">mode</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t274" class="run"><span class="n"><a href="#t274">274</a></span><span class="t">    <span class="nam">mode</span> <span class="op">=</span> <span class="nam">mode</span><span class="op">.</span><span class="nam">lower</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t275" class="run"><span class="n"><a href="#t275">275</a></span><span class="t">    <span class="nam">valid_modes</span> <span class="op">=</span> <span class="op">[</span><span class="str">'fan_in'</span><span class="op">,</span> <span class="str">'fan_out'</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p id="t276" class="run"><span class="n"><a href="#t276">276</a></span><span class="t">    <span class="key">if</span> <span class="nam">mode</span> <span class="key">not</span> <span class="key">in</span> <span class="nam">valid_modes</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t277" class="mis show_mis"><span class="n"><a href="#t277">277</a></span><span class="t">        <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span><span class="str">"Mode {} not supported, please use one of {}"</span><span class="op">.</span><span class="nam">format</span><span class="op">(</span><span class="nam">mode</span><span class="op">,</span> <span class="nam">valid_modes</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t278" class="pln"><span class="n"><a href="#t278">278</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t279" class="run"><span class="n"><a href="#t279">279</a></span><span class="t">    <span class="nam">fan_in</span><span class="op">,</span> <span class="nam">fan_out</span> <span class="op">=</span> <span class="nam">_calculate_fan_in_and_fan_out</span><span class="op">(</span><span class="nam">tensor</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t280" class="run"><span class="n"><a href="#t280">280</a></span><span class="t">    <span class="key">return</span> <span class="nam">fan_in</span> <span class="key">if</span> <span class="nam">mode</span> <span class="op">==</span> <span class="str">'fan_in'</span> <span class="key">else</span> <span class="nam">fan_out</span>&nbsp;</span><span class="r"></span></p>
    <p id="t281" class="pln"><span class="n"><a href="#t281">281</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t282" class="pln"><span class="n"><a href="#t282">282</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t283" class="run"><span class="n"><a href="#t283">283</a></span><span class="t"><span class="key">def</span> <span class="nam">kaiming_uniform_</span><span class="op">(</span><span class="nam">tensor</span><span class="op">,</span> <span class="nam">a</span><span class="op">=</span><span class="num">0</span><span class="op">,</span> <span class="nam">mode</span><span class="op">=</span><span class="str">'fan_in'</span><span class="op">,</span> <span class="nam">nonlinearity</span><span class="op">=</span><span class="str">'leaky_relu'</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t284" class="pln"><span class="n"><a href="#t284">284</a></span><span class="t">    <span class="str">r"""Fills the input `Tensor` with values according to the method</span>&nbsp;</span><span class="r"></span></p>
    <p id="t285" class="pln"><span class="n"><a href="#t285">285</a></span><span class="t"><span class="str">    described in `Delving deep into rectifiers: Surpassing human-level</span>&nbsp;</span><span class="r"></span></p>
    <p id="t286" class="pln"><span class="n"><a href="#t286">286</a></span><span class="t"><span class="str">    performance on ImageNet classification` - He, K. et al. (2015), using a</span>&nbsp;</span><span class="r"></span></p>
    <p id="t287" class="pln"><span class="n"><a href="#t287">287</a></span><span class="t"><span class="str">    uniform distribution. The resulting tensor will have values sampled from</span>&nbsp;</span><span class="r"></span></p>
    <p id="t288" class="pln"><span class="n"><a href="#t288">288</a></span><span class="t"><span class="str">    :math:`\mathcal{U}(-\text{bound}, \text{bound})` where</span>&nbsp;</span><span class="r"></span></p>
    <p id="t289" class="pln"><span class="n"><a href="#t289">289</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t290" class="pln"><span class="n"><a href="#t290">290</a></span><span class="t"><span class="str">    .. math::</span>&nbsp;</span><span class="r"></span></p>
    <p id="t291" class="pln"><span class="n"><a href="#t291">291</a></span><span class="t"><span class="str">        \text{bound} = \text{gain} \times \sqrt{\frac{3}{\text{fan\_mode}}}</span>&nbsp;</span><span class="r"></span></p>
    <p id="t292" class="pln"><span class="n"><a href="#t292">292</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t293" class="pln"><span class="n"><a href="#t293">293</a></span><span class="t"><span class="str">    Also known as He initialization.</span>&nbsp;</span><span class="r"></span></p>
    <p id="t294" class="pln"><span class="n"><a href="#t294">294</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t295" class="pln"><span class="n"><a href="#t295">295</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t296" class="pln"><span class="n"><a href="#t296">296</a></span><span class="t"><span class="str">        tensor: an n-dimensional `torch.Tensor`</span>&nbsp;</span><span class="r"></span></p>
    <p id="t297" class="pln"><span class="n"><a href="#t297">297</a></span><span class="t"><span class="str">        a: the negative slope of the rectifier used after this layer (only </span>&nbsp;</span><span class="r"></span></p>
    <p id="t298" class="pln"><span class="n"><a href="#t298">298</a></span><span class="t"><span class="str">        used with ``'leaky_relu'``)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t299" class="pln"><span class="n"><a href="#t299">299</a></span><span class="t"><span class="str">        mode: either ``'fan_in'`` (default) or ``'fan_out'``. Choosing ``'fan_in'``</span>&nbsp;</span><span class="r"></span></p>
    <p id="t300" class="pln"><span class="n"><a href="#t300">300</a></span><span class="t"><span class="str">            preserves the magnitude of the variance of the weights in the</span>&nbsp;</span><span class="r"></span></p>
    <p id="t301" class="pln"><span class="n"><a href="#t301">301</a></span><span class="t"><span class="str">            forward pass. Choosing ``'fan_out'`` preserves the magnitudes in the</span>&nbsp;</span><span class="r"></span></p>
    <p id="t302" class="pln"><span class="n"><a href="#t302">302</a></span><span class="t"><span class="str">            backwards pass.</span>&nbsp;</span><span class="r"></span></p>
    <p id="t303" class="pln"><span class="n"><a href="#t303">303</a></span><span class="t"><span class="str">        nonlinearity: the non-linear function (`nn.functional` name),</span>&nbsp;</span><span class="r"></span></p>
    <p id="t304" class="pln"><span class="n"><a href="#t304">304</a></span><span class="t"><span class="str">            recommended to use only with ``'relu'`` or ``'leaky_relu'`` (default).</span>&nbsp;</span><span class="r"></span></p>
    <p id="t305" class="pln"><span class="n"><a href="#t305">305</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t306" class="pln"><span class="n"><a href="#t306">306</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t307" class="pln"><span class="n"><a href="#t307">307</a></span><span class="t"><span class="str">        >>> w = torch.empty(3, 5)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t308" class="pln"><span class="n"><a href="#t308">308</a></span><span class="t"><span class="str">        >>> nn.init.kaiming_uniform_(w, mode='fan_in', nonlinearity='relu')</span>&nbsp;</span><span class="r"></span></p>
    <p id="t309" class="pln"><span class="n"><a href="#t309">309</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p id="t310" class="run"><span class="n"><a href="#t310">310</a></span><span class="t">    <span class="nam">fan</span> <span class="op">=</span> <span class="nam">_calculate_correct_fan</span><span class="op">(</span><span class="nam">tensor</span><span class="op">,</span> <span class="nam">mode</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t311" class="run"><span class="n"><a href="#t311">311</a></span><span class="t">    <span class="nam">gain</span> <span class="op">=</span> <span class="nam">calculate_gain</span><span class="op">(</span><span class="nam">nonlinearity</span><span class="op">,</span> <span class="nam">a</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t312" class="run"><span class="n"><a href="#t312">312</a></span><span class="t">    <span class="nam">std</span> <span class="op">=</span> <span class="nam">gain</span> <span class="op">/</span> <span class="nam">math</span><span class="op">.</span><span class="nam">sqrt</span><span class="op">(</span><span class="nam">fan</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t313" class="run"><span class="n"><a href="#t313">313</a></span><span class="t">    <span class="nam">bound</span> <span class="op">=</span> <span class="nam">math</span><span class="op">.</span><span class="nam">sqrt</span><span class="op">(</span><span class="num">3.0</span><span class="op">)</span> <span class="op">*</span> <span class="nam">std</span>  <span class="com"># Calculate uniform bounds from standard deviation</span>&nbsp;</span><span class="r"></span></p>
    <p id="t314" class="run"><span class="n"><a href="#t314">314</a></span><span class="t">    <span class="key">with</span> <span class="nam">torch</span><span class="op">.</span><span class="nam">no_grad</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t315" class="run"><span class="n"><a href="#t315">315</a></span><span class="t">        <span class="key">return</span> <span class="nam">tensor</span><span class="op">.</span><span class="nam">uniform_</span><span class="op">(</span><span class="op">-</span><span class="nam">bound</span><span class="op">,</span> <span class="nam">bound</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t316" class="pln"><span class="n"><a href="#t316">316</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t317" class="pln"><span class="n"><a href="#t317">317</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t318" class="run"><span class="n"><a href="#t318">318</a></span><span class="t"><span class="key">def</span> <span class="nam">kaiming_normal_</span><span class="op">(</span><span class="nam">tensor</span><span class="op">,</span> <span class="nam">a</span><span class="op">=</span><span class="num">0</span><span class="op">,</span> <span class="nam">mode</span><span class="op">=</span><span class="str">'fan_in'</span><span class="op">,</span> <span class="nam">nonlinearity</span><span class="op">=</span><span class="str">'leaky_relu'</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t319" class="pln"><span class="n"><a href="#t319">319</a></span><span class="t">    <span class="str">r"""Fills the input `Tensor` with values according to the method</span>&nbsp;</span><span class="r"></span></p>
    <p id="t320" class="pln"><span class="n"><a href="#t320">320</a></span><span class="t"><span class="str">    described in `Delving deep into rectifiers: Surpassing human-level</span>&nbsp;</span><span class="r"></span></p>
    <p id="t321" class="pln"><span class="n"><a href="#t321">321</a></span><span class="t"><span class="str">    performance on ImageNet classification` - He, K. et al. (2015), using a</span>&nbsp;</span><span class="r"></span></p>
    <p id="t322" class="pln"><span class="n"><a href="#t322">322</a></span><span class="t"><span class="str">    normal distribution. The resulting tensor will have values sampled from</span>&nbsp;</span><span class="r"></span></p>
    <p id="t323" class="pln"><span class="n"><a href="#t323">323</a></span><span class="t"><span class="str">    :math:`\mathcal{N}(0, \text{std}^2)` where</span>&nbsp;</span><span class="r"></span></p>
    <p id="t324" class="pln"><span class="n"><a href="#t324">324</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t325" class="pln"><span class="n"><a href="#t325">325</a></span><span class="t"><span class="str">    .. math::</span>&nbsp;</span><span class="r"></span></p>
    <p id="t326" class="pln"><span class="n"><a href="#t326">326</a></span><span class="t"><span class="str">        \text{std} = \frac{\text{gain}}{\sqrt{\text{fan\_mode}}}</span>&nbsp;</span><span class="r"></span></p>
    <p id="t327" class="pln"><span class="n"><a href="#t327">327</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t328" class="pln"><span class="n"><a href="#t328">328</a></span><span class="t"><span class="str">    Also known as He initialization.</span>&nbsp;</span><span class="r"></span></p>
    <p id="t329" class="pln"><span class="n"><a href="#t329">329</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t330" class="pln"><span class="n"><a href="#t330">330</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t331" class="pln"><span class="n"><a href="#t331">331</a></span><span class="t"><span class="str">        tensor: an n-dimensional `torch.Tensor`</span>&nbsp;</span><span class="r"></span></p>
    <p id="t332" class="pln"><span class="n"><a href="#t332">332</a></span><span class="t"><span class="str">        a: the negative slope of the rectifier used after this layer (only </span>&nbsp;</span><span class="r"></span></p>
    <p id="t333" class="pln"><span class="n"><a href="#t333">333</a></span><span class="t"><span class="str">        used with ``'leaky_relu'``)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t334" class="pln"><span class="n"><a href="#t334">334</a></span><span class="t"><span class="str">        mode: either ``'fan_in'`` (default) or ``'fan_out'``. Choosing ``'fan_in'``</span>&nbsp;</span><span class="r"></span></p>
    <p id="t335" class="pln"><span class="n"><a href="#t335">335</a></span><span class="t"><span class="str">            preserves the magnitude of the variance of the weights in the</span>&nbsp;</span><span class="r"></span></p>
    <p id="t336" class="pln"><span class="n"><a href="#t336">336</a></span><span class="t"><span class="str">            forward pass. Choosing ``'fan_out'`` preserves the magnitudes in the</span>&nbsp;</span><span class="r"></span></p>
    <p id="t337" class="pln"><span class="n"><a href="#t337">337</a></span><span class="t"><span class="str">            backwards pass.</span>&nbsp;</span><span class="r"></span></p>
    <p id="t338" class="pln"><span class="n"><a href="#t338">338</a></span><span class="t"><span class="str">        nonlinearity: the non-linear function (`nn.functional` name),</span>&nbsp;</span><span class="r"></span></p>
    <p id="t339" class="pln"><span class="n"><a href="#t339">339</a></span><span class="t"><span class="str">            recommended to use only with ``'relu'`` or ``'leaky_relu'`` (default).</span>&nbsp;</span><span class="r"></span></p>
    <p id="t340" class="pln"><span class="n"><a href="#t340">340</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t341" class="pln"><span class="n"><a href="#t341">341</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t342" class="pln"><span class="n"><a href="#t342">342</a></span><span class="t"><span class="str">        >>> w = torch.empty(3, 5)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t343" class="pln"><span class="n"><a href="#t343">343</a></span><span class="t"><span class="str">        >>> nn.init.kaiming_normal_(w, mode='fan_out', nonlinearity='relu')</span>&nbsp;</span><span class="r"></span></p>
    <p id="t344" class="pln"><span class="n"><a href="#t344">344</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p id="t345" class="mis show_mis"><span class="n"><a href="#t345">345</a></span><span class="t">    <span class="nam">fan</span> <span class="op">=</span> <span class="nam">_calculate_correct_fan</span><span class="op">(</span><span class="nam">tensor</span><span class="op">,</span> <span class="nam">mode</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t346" class="mis show_mis"><span class="n"><a href="#t346">346</a></span><span class="t">    <span class="nam">gain</span> <span class="op">=</span> <span class="nam">calculate_gain</span><span class="op">(</span><span class="nam">nonlinearity</span><span class="op">,</span> <span class="nam">a</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t347" class="mis show_mis"><span class="n"><a href="#t347">347</a></span><span class="t">    <span class="nam">std</span> <span class="op">=</span> <span class="nam">gain</span> <span class="op">/</span> <span class="nam">math</span><span class="op">.</span><span class="nam">sqrt</span><span class="op">(</span><span class="nam">fan</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t348" class="mis show_mis"><span class="n"><a href="#t348">348</a></span><span class="t">    <span class="key">with</span> <span class="nam">torch</span><span class="op">.</span><span class="nam">no_grad</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t349" class="mis show_mis"><span class="n"><a href="#t349">349</a></span><span class="t">        <span class="key">return</span> <span class="nam">tensor</span><span class="op">.</span><span class="nam">normal_</span><span class="op">(</span><span class="num">0</span><span class="op">,</span> <span class="nam">std</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t350" class="pln"><span class="n"><a href="#t350">350</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t351" class="pln"><span class="n"><a href="#t351">351</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t352" class="run"><span class="n"><a href="#t352">352</a></span><span class="t"><span class="key">def</span> <span class="nam">orthogonal_</span><span class="op">(</span><span class="nam">tensor</span><span class="op">,</span> <span class="nam">gain</span><span class="op">=</span><span class="num">1</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t353" class="pln"><span class="n"><a href="#t353">353</a></span><span class="t">    <span class="str">r"""Fills the input `Tensor` with a (semi) orthogonal matrix, as</span>&nbsp;</span><span class="r"></span></p>
    <p id="t354" class="pln"><span class="n"><a href="#t354">354</a></span><span class="t"><span class="str">    described in `Exact solutions to the nonlinear dynamics of learning in deep</span>&nbsp;</span><span class="r"></span></p>
    <p id="t355" class="pln"><span class="n"><a href="#t355">355</a></span><span class="t"><span class="str">    linear neural networks` - Saxe, A. et al. (2013). The input tensor must have</span>&nbsp;</span><span class="r"></span></p>
    <p id="t356" class="pln"><span class="n"><a href="#t356">356</a></span><span class="t"><span class="str">    at least 2 dimensions, and for tensors with more than 2 dimensions the</span>&nbsp;</span><span class="r"></span></p>
    <p id="t357" class="pln"><span class="n"><a href="#t357">357</a></span><span class="t"><span class="str">    trailing dimensions are flattened.</span>&nbsp;</span><span class="r"></span></p>
    <p id="t358" class="pln"><span class="n"><a href="#t358">358</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t359" class="pln"><span class="n"><a href="#t359">359</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t360" class="pln"><span class="n"><a href="#t360">360</a></span><span class="t"><span class="str">        tensor: an n-dimensional `torch.Tensor`, where :math:`n \geq 2`</span>&nbsp;</span><span class="r"></span></p>
    <p id="t361" class="pln"><span class="n"><a href="#t361">361</a></span><span class="t"><span class="str">        gain: optional scaling factor</span>&nbsp;</span><span class="r"></span></p>
    <p id="t362" class="pln"><span class="n"><a href="#t362">362</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t363" class="pln"><span class="n"><a href="#t363">363</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t364" class="pln"><span class="n"><a href="#t364">364</a></span><span class="t"><span class="str">        >>> w = torch.empty(3, 5)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t365" class="pln"><span class="n"><a href="#t365">365</a></span><span class="t"><span class="str">        >>> nn.init.orthogonal_(w)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t366" class="pln"><span class="n"><a href="#t366">366</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p id="t367" class="mis show_mis"><span class="n"><a href="#t367">367</a></span><span class="t">    <span class="key">if</span> <span class="nam">tensor</span><span class="op">.</span><span class="nam">ndimension</span><span class="op">(</span><span class="op">)</span> <span class="op">&lt;</span> <span class="num">2</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t368" class="mis show_mis"><span class="n"><a href="#t368">368</a></span><span class="t">        <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span><span class="str">"Only tensors with 2 or more dimensions are supported"</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t369" class="pln"><span class="n"><a href="#t369">369</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t370" class="mis show_mis"><span class="n"><a href="#t370">370</a></span><span class="t">    <span class="nam">rows</span> <span class="op">=</span> <span class="nam">tensor</span><span class="op">.</span><span class="nam">size</span><span class="op">(</span><span class="num">0</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t371" class="mis show_mis"><span class="n"><a href="#t371">371</a></span><span class="t">    <span class="nam">cols</span> <span class="op">=</span> <span class="nam">tensor</span><span class="op">.</span><span class="nam">numel</span><span class="op">(</span><span class="op">)</span> <span class="op">//</span> <span class="nam">rows</span>&nbsp;</span><span class="r"></span></p>
    <p id="t372" class="mis show_mis"><span class="n"><a href="#t372">372</a></span><span class="t">    <span class="nam">flattened</span> <span class="op">=</span> <span class="nam">tensor</span><span class="op">.</span><span class="nam">new</span><span class="op">(</span><span class="nam">rows</span><span class="op">,</span> <span class="nam">cols</span><span class="op">)</span><span class="op">.</span><span class="nam">normal_</span><span class="op">(</span><span class="num">0</span><span class="op">,</span> <span class="num">1</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t373" class="pln"><span class="n"><a href="#t373">373</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t374" class="mis show_mis"><span class="n"><a href="#t374">374</a></span><span class="t">    <span class="key">if</span> <span class="nam">rows</span> <span class="op">&lt;</span> <span class="nam">cols</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t375" class="mis show_mis"><span class="n"><a href="#t375">375</a></span><span class="t">        <span class="nam">flattened</span><span class="op">.</span><span class="nam">t_</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t376" class="pln"><span class="n"><a href="#t376">376</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t377" class="pln"><span class="n"><a href="#t377">377</a></span><span class="t">    <span class="com"># Compute the qr factorization</span>&nbsp;</span><span class="r"></span></p>
    <p id="t378" class="mis show_mis"><span class="n"><a href="#t378">378</a></span><span class="t">    <span class="nam">q</span><span class="op">,</span> <span class="nam">r</span> <span class="op">=</span> <span class="nam">torch</span><span class="op">.</span><span class="nam">qr</span><span class="op">(</span><span class="nam">flattened</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t379" class="pln"><span class="n"><a href="#t379">379</a></span><span class="t">    <span class="com"># Make Q uniform according to https://arxiv.org/pdf/math-ph/0609050.pdf</span>&nbsp;</span><span class="r"></span></p>
    <p id="t380" class="mis show_mis"><span class="n"><a href="#t380">380</a></span><span class="t">    <span class="nam">d</span> <span class="op">=</span> <span class="nam">torch</span><span class="op">.</span><span class="nam">diag</span><span class="op">(</span><span class="nam">r</span><span class="op">,</span> <span class="num">0</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t381" class="mis show_mis"><span class="n"><a href="#t381">381</a></span><span class="t">    <span class="nam">ph</span> <span class="op">=</span> <span class="nam">d</span><span class="op">.</span><span class="nam">sign</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t382" class="mis show_mis"><span class="n"><a href="#t382">382</a></span><span class="t">    <span class="nam">q</span> <span class="op">*=</span> <span class="nam">ph</span>&nbsp;</span><span class="r"></span></p>
    <p id="t383" class="pln"><span class="n"><a href="#t383">383</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t384" class="mis show_mis"><span class="n"><a href="#t384">384</a></span><span class="t">    <span class="key">if</span> <span class="nam">rows</span> <span class="op">&lt;</span> <span class="nam">cols</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t385" class="mis show_mis"><span class="n"><a href="#t385">385</a></span><span class="t">        <span class="nam">q</span><span class="op">.</span><span class="nam">t_</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t386" class="pln"><span class="n"><a href="#t386">386</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t387" class="mis show_mis"><span class="n"><a href="#t387">387</a></span><span class="t">    <span class="key">with</span> <span class="nam">torch</span><span class="op">.</span><span class="nam">no_grad</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t388" class="mis show_mis"><span class="n"><a href="#t388">388</a></span><span class="t">        <span class="nam">tensor</span><span class="op">.</span><span class="nam">view_as</span><span class="op">(</span><span class="nam">q</span><span class="op">)</span><span class="op">.</span><span class="nam">copy_</span><span class="op">(</span><span class="nam">q</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t389" class="mis show_mis"><span class="n"><a href="#t389">389</a></span><span class="t">        <span class="nam">tensor</span><span class="op">.</span><span class="nam">mul_</span><span class="op">(</span><span class="nam">gain</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t390" class="mis show_mis"><span class="n"><a href="#t390">390</a></span><span class="t">    <span class="key">return</span> <span class="nam">tensor</span>&nbsp;</span><span class="r"></span></p>
    <p id="t391" class="pln"><span class="n"><a href="#t391">391</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t392" class="pln"><span class="n"><a href="#t392">392</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t393" class="run"><span class="n"><a href="#t393">393</a></span><span class="t"><span class="key">def</span> <span class="nam">sparse_</span><span class="op">(</span><span class="nam">tensor</span><span class="op">,</span> <span class="nam">sparsity</span><span class="op">,</span> <span class="nam">std</span><span class="op">=</span><span class="num">0.01</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t394" class="pln"><span class="n"><a href="#t394">394</a></span><span class="t">    <span class="str">r"""Fills the 2D input `Tensor` as a sparse matrix, where the</span>&nbsp;</span><span class="r"></span></p>
    <p id="t395" class="pln"><span class="n"><a href="#t395">395</a></span><span class="t"><span class="str">    non-zero elements will be drawn from the normal distribution</span>&nbsp;</span><span class="r"></span></p>
    <p id="t396" class="pln"><span class="n"><a href="#t396">396</a></span><span class="t"><span class="str">    :math:`\mathcal{N}(0, 0.01)`, as described in `Deep learning via</span>&nbsp;</span><span class="r"></span></p>
    <p id="t397" class="pln"><span class="n"><a href="#t397">397</a></span><span class="t"><span class="str">    Hessian-free optimization` - Martens, J. (2010).</span>&nbsp;</span><span class="r"></span></p>
    <p id="t398" class="pln"><span class="n"><a href="#t398">398</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t399" class="pln"><span class="n"><a href="#t399">399</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t400" class="pln"><span class="n"><a href="#t400">400</a></span><span class="t"><span class="str">        tensor: an n-dimensional `torch.Tensor`</span>&nbsp;</span><span class="r"></span></p>
    <p id="t401" class="pln"><span class="n"><a href="#t401">401</a></span><span class="t"><span class="str">        sparsity: The fraction of elements in each column to be set to zero</span>&nbsp;</span><span class="r"></span></p>
    <p id="t402" class="pln"><span class="n"><a href="#t402">402</a></span><span class="t"><span class="str">        std: the standard deviation of the normal distribution used to generate</span>&nbsp;</span><span class="r"></span></p>
    <p id="t403" class="pln"><span class="n"><a href="#t403">403</a></span><span class="t"><span class="str">            the non-zero values</span>&nbsp;</span><span class="r"></span></p>
    <p id="t404" class="pln"><span class="n"><a href="#t404">404</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t405" class="pln"><span class="n"><a href="#t405">405</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t406" class="pln"><span class="n"><a href="#t406">406</a></span><span class="t"><span class="str">        >>> w = torch.empty(3, 5)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t407" class="pln"><span class="n"><a href="#t407">407</a></span><span class="t"><span class="str">        >>> nn.init.sparse_(w, sparsity=0.1)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t408" class="pln"><span class="n"><a href="#t408">408</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p id="t409" class="mis show_mis"><span class="n"><a href="#t409">409</a></span><span class="t">    <span class="key">if</span> <span class="nam">tensor</span><span class="op">.</span><span class="nam">ndimension</span><span class="op">(</span><span class="op">)</span> <span class="op">!=</span> <span class="num">2</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t410" class="mis show_mis"><span class="n"><a href="#t410">410</a></span><span class="t">        <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span><span class="str">"Only tensors with 2 dimensions are supported"</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t411" class="pln"><span class="n"><a href="#t411">411</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t412" class="mis show_mis"><span class="n"><a href="#t412">412</a></span><span class="t">    <span class="nam">rows</span><span class="op">,</span> <span class="nam">cols</span> <span class="op">=</span> <span class="nam">tensor</span><span class="op">.</span><span class="nam">shape</span>&nbsp;</span><span class="r"></span></p>
    <p id="t413" class="mis show_mis"><span class="n"><a href="#t413">413</a></span><span class="t">    <span class="nam">num_zeros</span> <span class="op">=</span> <span class="nam">int</span><span class="op">(</span><span class="nam">math</span><span class="op">.</span><span class="nam">ceil</span><span class="op">(</span><span class="nam">sparsity</span> <span class="op">*</span> <span class="nam">rows</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t414" class="pln"><span class="n"><a href="#t414">414</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t415" class="mis show_mis"><span class="n"><a href="#t415">415</a></span><span class="t">    <span class="key">with</span> <span class="nam">torch</span><span class="op">.</span><span class="nam">no_grad</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t416" class="mis show_mis"><span class="n"><a href="#t416">416</a></span><span class="t">        <span class="nam">tensor</span><span class="op">.</span><span class="nam">normal_</span><span class="op">(</span><span class="num">0</span><span class="op">,</span> <span class="nam">std</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t417" class="mis show_mis"><span class="n"><a href="#t417">417</a></span><span class="t">        <span class="key">for</span> <span class="nam">col_idx</span> <span class="key">in</span> <span class="nam">range</span><span class="op">(</span><span class="nam">cols</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t418" class="mis show_mis"><span class="n"><a href="#t418">418</a></span><span class="t">            <span class="nam">row_indices</span> <span class="op">=</span> <span class="nam">torch</span><span class="op">.</span><span class="nam">randperm</span><span class="op">(</span><span class="nam">rows</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t419" class="mis show_mis"><span class="n"><a href="#t419">419</a></span><span class="t">            <span class="nam">zero_indices</span> <span class="op">=</span> <span class="nam">row_indices</span><span class="op">[</span><span class="op">:</span><span class="nam">num_zeros</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p id="t420" class="mis show_mis"><span class="n"><a href="#t420">420</a></span><span class="t">            <span class="nam">tensor</span><span class="op">[</span><span class="nam">zero_indices</span><span class="op">,</span> <span class="nam">col_idx</span><span class="op">]</span> <span class="op">=</span> <span class="num">0</span>&nbsp;</span><span class="r"></span></p>
    <p id="t421" class="mis show_mis"><span class="n"><a href="#t421">421</a></span><span class="t">    <span class="key">return</span> <span class="nam">tensor</span>&nbsp;</span><span class="r"></span></p>
    <p id="t422" class="pln"><span class="n"><a href="#t422">422</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t423" class="pln"><span class="n"><a href="#t423">423</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t424" class="pln"><span class="n"><a href="#t424">424</a></span><span class="t"><span class="com"># for backward compatibility</span>&nbsp;</span><span class="r"></span></p>
    <p id="t425" class="run"><span class="n"><a href="#t425">425</a></span><span class="t"><span class="key">def</span> <span class="nam">_make_deprecate</span><span class="op">(</span><span class="nam">meth</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t426" class="run"><span class="n"><a href="#t426">426</a></span><span class="t">    <span class="nam">new_name</span> <span class="op">=</span> <span class="nam">meth</span><span class="op">.</span><span class="nam">__name__</span>&nbsp;</span><span class="r"></span></p>
    <p id="t427" class="run"><span class="n"><a href="#t427">427</a></span><span class="t">    <span class="nam">old_name</span> <span class="op">=</span> <span class="nam">new_name</span><span class="op">[</span><span class="op">:</span><span class="op">-</span><span class="num">1</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p id="t428" class="pln"><span class="n"><a href="#t428">428</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t429" class="run"><span class="n"><a href="#t429">429</a></span><span class="t">    <span class="key">def</span> <span class="nam">deprecated_init</span><span class="op">(</span><span class="op">*</span><span class="nam">args</span><span class="op">,</span> <span class="op">**</span><span class="nam">kwargs</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t430" class="mis show_mis"><span class="n"><a href="#t430">430</a></span><span class="t">        <span class="nam">warnings</span><span class="op">.</span><span class="nam">warn</span><span class="op">(</span><span class="str">"nn.init.{} is now deprecated in favor of nn.init.{}."</span>&nbsp;</span><span class="r"></span></p>
    <p id="t431" class="pln"><span class="n"><a href="#t431">431</a></span><span class="t">                      <span class="op">.</span><span class="nam">format</span><span class="op">(</span><span class="nam">old_name</span><span class="op">,</span> <span class="nam">new_name</span><span class="op">)</span><span class="op">,</span> <span class="nam">stacklevel</span><span class="op">=</span><span class="num">2</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t432" class="mis show_mis"><span class="n"><a href="#t432">432</a></span><span class="t">        <span class="key">return</span> <span class="nam">meth</span><span class="op">(</span><span class="op">*</span><span class="nam">args</span><span class="op">,</span> <span class="op">**</span><span class="nam">kwargs</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t433" class="pln"><span class="n"><a href="#t433">433</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t434" class="run"><span class="n"><a href="#t434">434</a></span><span class="t">    <span class="nam">deprecated_init</span><span class="op">.</span><span class="nam">__doc__</span> <span class="op">=</span> <span class="str">r"""</span>&nbsp;</span><span class="r"></span></p>
    <p id="t435" class="pln"><span class="n"><a href="#t435">435</a></span><span class="t"><span class="str">    {old_name}(...)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t436" class="pln"><span class="n"><a href="#t436">436</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t437" class="pln"><span class="n"><a href="#t437">437</a></span><span class="t"><span class="str">    .. warning::</span>&nbsp;</span><span class="r"></span></p>
    <p id="t438" class="pln"><span class="n"><a href="#t438">438</a></span><span class="t"><span class="str">        This method is now deprecated in favor of :func:`torch.nn.init.{new_name}`.</span>&nbsp;</span><span class="r"></span></p>
    <p id="t439" class="pln"><span class="n"><a href="#t439">439</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t440" class="pln"><span class="n"><a href="#t440">440</a></span><span class="t"><span class="str">    See :func:`~torch.nn.init.{new_name}` for details."""</span><span class="op">.</span><span class="nam">format</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p id="t441" class="pln"><span class="n"><a href="#t441">441</a></span><span class="t">        <span class="nam">old_name</span><span class="op">=</span><span class="nam">old_name</span><span class="op">,</span> <span class="nam">new_name</span><span class="op">=</span><span class="nam">new_name</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t442" class="run"><span class="n"><a href="#t442">442</a></span><span class="t">    <span class="nam">deprecated_init</span><span class="op">.</span><span class="nam">__name__</span> <span class="op">=</span> <span class="nam">old_name</span>&nbsp;</span><span class="r"></span></p>
    <p id="t443" class="run"><span class="n"><a href="#t443">443</a></span><span class="t">    <span class="key">return</span> <span class="nam">deprecated_init</span>&nbsp;</span><span class="r"></span></p>
    <p id="t444" class="pln"><span class="n"><a href="#t444">444</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t445" class="pln"><span class="n"><a href="#t445">445</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t446" class="run"><span class="n"><a href="#t446">446</a></span><span class="t"><span class="nam">uniform</span> <span class="op">=</span> <span class="nam">_make_deprecate</span><span class="op">(</span><span class="nam">uniform_</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t447" class="run"><span class="n"><a href="#t447">447</a></span><span class="t"><span class="nam">normal</span> <span class="op">=</span> <span class="nam">_make_deprecate</span><span class="op">(</span><span class="nam">normal_</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t448" class="run"><span class="n"><a href="#t448">448</a></span><span class="t"><span class="nam">constant</span> <span class="op">=</span> <span class="nam">_make_deprecate</span><span class="op">(</span><span class="nam">constant_</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t449" class="run"><span class="n"><a href="#t449">449</a></span><span class="t"><span class="nam">eye</span> <span class="op">=</span> <span class="nam">_make_deprecate</span><span class="op">(</span><span class="nam">eye_</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t450" class="run"><span class="n"><a href="#t450">450</a></span><span class="t"><span class="nam">dirac</span> <span class="op">=</span> <span class="nam">_make_deprecate</span><span class="op">(</span><span class="nam">dirac_</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t451" class="run"><span class="n"><a href="#t451">451</a></span><span class="t"><span class="nam">xavier_uniform</span> <span class="op">=</span> <span class="nam">_make_deprecate</span><span class="op">(</span><span class="nam">xavier_uniform_</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t452" class="run"><span class="n"><a href="#t452">452</a></span><span class="t"><span class="nam">xavier_normal</span> <span class="op">=</span> <span class="nam">_make_deprecate</span><span class="op">(</span><span class="nam">xavier_normal_</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t453" class="run"><span class="n"><a href="#t453">453</a></span><span class="t"><span class="nam">kaiming_uniform</span> <span class="op">=</span> <span class="nam">_make_deprecate</span><span class="op">(</span><span class="nam">kaiming_uniform_</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t454" class="run"><span class="n"><a href="#t454">454</a></span><span class="t"><span class="nam">kaiming_normal</span> <span class="op">=</span> <span class="nam">_make_deprecate</span><span class="op">(</span><span class="nam">kaiming_normal_</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t455" class="run"><span class="n"><a href="#t455">455</a></span><span class="t"><span class="nam">orthogonal</span> <span class="op">=</span> <span class="nam">_make_deprecate</span><span class="op">(</span><span class="nam">orthogonal_</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t456" class="run"><span class="n"><a href="#t456">456</a></span><span class="t"><span class="nam">sparse</span> <span class="op">=</span> <span class="nam">_make_deprecate</span><span class="op">(</span><span class="nam">sparse_</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
</div>
<div id="footer">
    <div class="content">
        <p>
            <a class="nav" href="index.html">&#xab; index</a> &nbsp; &nbsp; <a class="nav" href="https://coverage.readthedocs.io">coverage.py v5.0.3</a>,
            created at 2020-03-12 18:08
        </p>
    </div>
</div>
</body>
</html>
