<!DOCTYPE html>
<html>
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=emulateIE7" />
    <title>Coverage for C:\Users\paper\Anaconda3\Lib\site-packages\torch\sparse\__init__.py: 36%</title>
    <link rel="stylesheet" href="style.css" type="text/css">
    <script type="text/javascript" src="jquery.min.js"></script>
    <script type="text/javascript" src="jquery.hotkeys.js"></script>
    <script type="text/javascript" src="jquery.isonscreen.js"></script>
    <script type="text/javascript" src="coverage_html.js"></script>
    <script type="text/javascript">
        jQuery(document).ready(coverage.pyfile_ready);
    </script>
</head>
<body class="pyfile">
<div id="header">
    <div class="content">
        <h1>Coverage for <b>C:\Users\paper\Anaconda3\Lib\site-packages\torch\sparse\__init__.py</b> :
            <span class="pc_cov">36%</span>
        </h1>
        <img id="keyboard_icon" src="keybd_closed.png" alt="Show keyboard shortcuts" />
        <h2 class="stats">
            14 statements &nbsp;
            <span class="run shortkey_r button_toggle_run">5 run</span>
            <span class="mis show_mis shortkey_m button_toggle_mis">9 missing</span>
            <span class="exc show_exc shortkey_x button_toggle_exc">0 excluded</span>
        </h2>
    </div>
</div>
<div class="help_panel">
    <img id="panel_icon" src="keybd_open.png" alt="Hide keyboard shortcuts" />
    <p class="legend">Hot-keys on this page</p>
    <div>
    <p class="keyhelp">
        <span class="key">r</span>
        <span class="key">m</span>
        <span class="key">x</span>
        <span class="key">p</span> &nbsp; toggle line displays
    </p>
    <p class="keyhelp">
        <span class="key">j</span>
        <span class="key">k</span> &nbsp; next/prev highlighted chunk
    </p>
    <p class="keyhelp">
        <span class="key">0</span> &nbsp; (zero) top of page
    </p>
    <p class="keyhelp">
        <span class="key">1</span> &nbsp; (one) first highlighted chunk
    </p>
    </div>
</div>
<div id="source">
    <p id="t1" class="pln"><span class="n"><a href="#t1">1</a></span><span class="t"><span class="com"># The Tensor classes are added to this module by python_tensor.cpp</span>&nbsp;</span><span class="r"></span></p>
    <p id="t2" class="run"><span class="n"><a href="#t2">2</a></span><span class="t"><span class="key">import</span> <span class="nam">torch</span>&nbsp;</span><span class="r"></span></p>
    <p id="t3" class="pln"><span class="n"><a href="#t3">3</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t4" class="run"><span class="n"><a href="#t4">4</a></span><span class="t"><span class="nam">__all__</span> <span class="op">=</span> <span class="op">[</span>&nbsp;</span><span class="r"></span></p>
    <p id="t5" class="pln"><span class="n"><a href="#t5">5</a></span><span class="t">    <span class="str">'addmm'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p id="t6" class="pln"><span class="n"><a href="#t6">6</a></span><span class="t">    <span class="str">'mm'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p id="t7" class="pln"><span class="n"><a href="#t7">7</a></span><span class="t">    <span class="str">'sum'</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p id="t8" class="pln"><span class="n"><a href="#t8">8</a></span><span class="t"><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p id="t9" class="pln"><span class="n"><a href="#t9">9</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t10" class="pln"><span class="n"><a href="#t10">10</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t11" class="run"><span class="n"><a href="#t11">11</a></span><span class="t"><span class="key">def</span> <span class="nam">addmm</span><span class="op">(</span><span class="nam">mat</span><span class="op">,</span> <span class="nam">mat1</span><span class="op">,</span> <span class="nam">mat2</span><span class="op">,</span> <span class="nam">beta</span><span class="op">=</span><span class="num">1</span><span class="op">,</span> <span class="nam">alpha</span><span class="op">=</span><span class="num">1</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t12" class="pln"><span class="n"><a href="#t12">12</a></span><span class="t">    <span class="com"># type: (Tensor, Tensor, Tensor, float, float) -> Tensor</span>&nbsp;</span><span class="r"></span></p>
    <p id="t13" class="pln"><span class="n"><a href="#t13">13</a></span><span class="t">    <span class="str">r"""</span>&nbsp;</span><span class="r"></span></p>
    <p id="t14" class="pln"><span class="n"><a href="#t14">14</a></span><span class="t"><span class="str">    This function does exact same thing as :func:`torch.addmm` in the forward,</span>&nbsp;</span><span class="r"></span></p>
    <p id="t15" class="pln"><span class="n"><a href="#t15">15</a></span><span class="t"><span class="str">    except that it supports backward for sparse matrix :attr:`mat1`. :attr:`mat1`</span>&nbsp;</span><span class="r"></span></p>
    <p id="t16" class="pln"><span class="n"><a href="#t16">16</a></span><span class="t"><span class="str">    need to have `sparse_dim = 2`. Note that the gradients of :attr:`mat1` is a</span>&nbsp;</span><span class="r"></span></p>
    <p id="t17" class="pln"><span class="n"><a href="#t17">17</a></span><span class="t"><span class="str">    coalesced sparse tensor.</span>&nbsp;</span><span class="r"></span></p>
    <p id="t18" class="pln"><span class="n"><a href="#t18">18</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t19" class="pln"><span class="n"><a href="#t19">19</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t20" class="pln"><span class="n"><a href="#t20">20</a></span><span class="t"><span class="str">        mat (Tensor): a dense matrix to be added</span>&nbsp;</span><span class="r"></span></p>
    <p id="t21" class="pln"><span class="n"><a href="#t21">21</a></span><span class="t"><span class="str">        mat1 (SparseTensor): a sparse matrix to be multiplied</span>&nbsp;</span><span class="r"></span></p>
    <p id="t22" class="pln"><span class="n"><a href="#t22">22</a></span><span class="t"><span class="str">        mat2 (Tensor): a dense matrix be multiplied</span>&nbsp;</span><span class="r"></span></p>
    <p id="t23" class="pln"><span class="n"><a href="#t23">23</a></span><span class="t"><span class="str">        beta (Number, optional): multiplier for :attr:`mat` (:math:`\beta`)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t24" class="pln"><span class="n"><a href="#t24">24</a></span><span class="t"><span class="str">        alpha (Number, optional): multiplier for :math:`mat1 @ mat2` (:math:`\alpha`)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t25" class="pln"><span class="n"><a href="#t25">25</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p id="t26" class="mis show_mis"><span class="n"><a href="#t26">26</a></span><span class="t">    <span class="key">return</span> <span class="nam">torch</span><span class="op">.</span><span class="nam">_sparse_addmm</span><span class="op">(</span><span class="nam">mat</span><span class="op">,</span> <span class="nam">mat1</span><span class="op">,</span> <span class="nam">mat2</span><span class="op">,</span> <span class="nam">beta</span><span class="op">=</span><span class="nam">beta</span><span class="op">,</span> <span class="nam">alpha</span><span class="op">=</span><span class="nam">alpha</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t27" class="pln"><span class="n"><a href="#t27">27</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t28" class="pln"><span class="n"><a href="#t28">28</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t29" class="run"><span class="n"><a href="#t29">29</a></span><span class="t"><span class="key">def</span> <span class="nam">mm</span><span class="op">(</span><span class="nam">mat1</span><span class="op">,</span> <span class="nam">mat2</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t30" class="pln"><span class="n"><a href="#t30">30</a></span><span class="t">    <span class="str">r"""</span>&nbsp;</span><span class="r"></span></p>
    <p id="t31" class="pln"><span class="n"><a href="#t31">31</a></span><span class="t"><span class="str">    Performs a matrix multiplication of the sparse matrix :attr:`mat1`</span>&nbsp;</span><span class="r"></span></p>
    <p id="t32" class="pln"><span class="n"><a href="#t32">32</a></span><span class="t"><span class="str">    and dense matrix :attr:`mat2`. Similar to :func:`torch.mm`, If :attr:`mat1` is a</span>&nbsp;</span><span class="r"></span></p>
    <p id="t33" class="pln"><span class="n"><a href="#t33">33</a></span><span class="t"><span class="str">    :math:`(n \times m)` tensor, :attr:`mat2` is a :math:`(m \times p)` tensor, out will be a</span>&nbsp;</span><span class="r"></span></p>
    <p id="t34" class="pln"><span class="n"><a href="#t34">34</a></span><span class="t"><span class="str">    :math:`(n \times p)` dense tensor. :attr:`mat1` need to have `sparse_dim = 2`.</span>&nbsp;</span><span class="r"></span></p>
    <p id="t35" class="pln"><span class="n"><a href="#t35">35</a></span><span class="t"><span class="str">    This function also supports backward for both matrices. Note that the gradients of</span>&nbsp;</span><span class="r"></span></p>
    <p id="t36" class="pln"><span class="n"><a href="#t36">36</a></span><span class="t"><span class="str">    :attr:`mat1` is a coalesced sparse tensor.</span>&nbsp;</span><span class="r"></span></p>
    <p id="t37" class="pln"><span class="n"><a href="#t37">37</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t38" class="pln"><span class="n"><a href="#t38">38</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t39" class="pln"><span class="n"><a href="#t39">39</a></span><span class="t"><span class="str">        mat1 (SparseTensor): the first sparse matrix to be multiplied</span>&nbsp;</span><span class="r"></span></p>
    <p id="t40" class="pln"><span class="n"><a href="#t40">40</a></span><span class="t"><span class="str">        mat2 (Tensor): the second dense matrix to be multiplied</span>&nbsp;</span><span class="r"></span></p>
    <p id="t41" class="pln"><span class="n"><a href="#t41">41</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t42" class="pln"><span class="n"><a href="#t42">42</a></span><span class="t"><span class="str">    Example::</span>&nbsp;</span><span class="r"></span></p>
    <p id="t43" class="pln"><span class="n"><a href="#t43">43</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t44" class="pln"><span class="n"><a href="#t44">44</a></span><span class="t"><span class="str">        >>> a = torch.randn(2, 3).to_sparse().requires_grad_(True)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t45" class="pln"><span class="n"><a href="#t45">45</a></span><span class="t"><span class="str">        >>> a</span>&nbsp;</span><span class="r"></span></p>
    <p id="t46" class="pln"><span class="n"><a href="#t46">46</a></span><span class="t"><span class="str">        tensor(indices=tensor([[0, 0, 0, 1, 1, 1],</span>&nbsp;</span><span class="r"></span></p>
    <p id="t47" class="pln"><span class="n"><a href="#t47">47</a></span><span class="t"><span class="str">                               [0, 1, 2, 0, 1, 2]]),</span>&nbsp;</span><span class="r"></span></p>
    <p id="t48" class="pln"><span class="n"><a href="#t48">48</a></span><span class="t"><span class="str">               values=tensor([ 1.5901,  0.0183, -0.6146,  1.8061, -0.0112,  0.6302]),</span>&nbsp;</span><span class="r"></span></p>
    <p id="t49" class="pln"><span class="n"><a href="#t49">49</a></span><span class="t"><span class="str">               size=(2, 3), nnz=6, layout=torch.sparse_coo, requires_grad=True)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t50" class="pln"><span class="n"><a href="#t50">50</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t51" class="pln"><span class="n"><a href="#t51">51</a></span><span class="t"><span class="str">        >>> b = torch.randn(3, 2, requires_grad=True)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t52" class="pln"><span class="n"><a href="#t52">52</a></span><span class="t"><span class="str">        >>> b</span>&nbsp;</span><span class="r"></span></p>
    <p id="t53" class="pln"><span class="n"><a href="#t53">53</a></span><span class="t"><span class="str">        tensor([[-0.6479,  0.7874],</span>&nbsp;</span><span class="r"></span></p>
    <p id="t54" class="pln"><span class="n"><a href="#t54">54</a></span><span class="t"><span class="str">                [-1.2056,  0.5641],</span>&nbsp;</span><span class="r"></span></p>
    <p id="t55" class="pln"><span class="n"><a href="#t55">55</a></span><span class="t"><span class="str">                [-1.1716, -0.9923]], requires_grad=True)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t56" class="pln"><span class="n"><a href="#t56">56</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t57" class="pln"><span class="n"><a href="#t57">57</a></span><span class="t"><span class="str">        >>> y = torch.sparse.mm(a, b)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t58" class="pln"><span class="n"><a href="#t58">58</a></span><span class="t"><span class="str">        >>> y</span>&nbsp;</span><span class="r"></span></p>
    <p id="t59" class="pln"><span class="n"><a href="#t59">59</a></span><span class="t"><span class="str">        tensor([[-0.3323,  1.8723],</span>&nbsp;</span><span class="r"></span></p>
    <p id="t60" class="pln"><span class="n"><a href="#t60">60</a></span><span class="t"><span class="str">                [-1.8951,  0.7904]], grad_fn=&lt;SparseAddmmBackward>)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t61" class="pln"><span class="n"><a href="#t61">61</a></span><span class="t"><span class="str">        >>> y.sum().backward()</span>&nbsp;</span><span class="r"></span></p>
    <p id="t62" class="pln"><span class="n"><a href="#t62">62</a></span><span class="t"><span class="str">        >>> a.grad</span>&nbsp;</span><span class="r"></span></p>
    <p id="t63" class="pln"><span class="n"><a href="#t63">63</a></span><span class="t"><span class="str">        tensor(indices=tensor([[0, 0, 0, 1, 1, 1],</span>&nbsp;</span><span class="r"></span></p>
    <p id="t64" class="pln"><span class="n"><a href="#t64">64</a></span><span class="t"><span class="str">                               [0, 1, 2, 0, 1, 2]]),</span>&nbsp;</span><span class="r"></span></p>
    <p id="t65" class="pln"><span class="n"><a href="#t65">65</a></span><span class="t"><span class="str">               values=tensor([ 0.1394, -0.6415, -2.1639,  0.1394, -0.6415, -2.1639]),</span>&nbsp;</span><span class="r"></span></p>
    <p id="t66" class="pln"><span class="n"><a href="#t66">66</a></span><span class="t"><span class="str">               size=(2, 3), nnz=6, layout=torch.sparse_coo)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t67" class="pln"><span class="n"><a href="#t67">67</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p id="t68" class="mis show_mis"><span class="n"><a href="#t68">68</a></span><span class="t">    <span class="key">return</span> <span class="nam">torch</span><span class="op">.</span><span class="nam">_sparse_mm</span><span class="op">(</span><span class="nam">mat1</span><span class="op">,</span> <span class="nam">mat2</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t69" class="pln"><span class="n"><a href="#t69">69</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t70" class="pln"><span class="n"><a href="#t70">70</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t71" class="run"><span class="n"><a href="#t71">71</a></span><span class="t"><span class="key">def</span> <span class="nam">sum</span><span class="op">(</span><span class="nam">input</span><span class="op">,</span> <span class="nam">dim</span><span class="op">=</span><span class="key">None</span><span class="op">,</span> <span class="nam">dtype</span><span class="op">=</span><span class="key">None</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t72" class="pln"><span class="n"><a href="#t72">72</a></span><span class="t">    <span class="com"># type: (Tensor, Optional[Tuple[int]], Optional[int]) -> Tensor</span>&nbsp;</span><span class="r"></span></p>
    <p id="t73" class="pln"><span class="n"><a href="#t73">73</a></span><span class="t">    <span class="str">r"""</span>&nbsp;</span><span class="r"></span></p>
    <p id="t74" class="pln"><span class="n"><a href="#t74">74</a></span><span class="t"><span class="str">    Returns the sum of each row of SparseTensor :attr:`input` in the given</span>&nbsp;</span><span class="r"></span></p>
    <p id="t75" class="pln"><span class="n"><a href="#t75">75</a></span><span class="t"><span class="str">    dimensions :attr:`dim`. If :attr:`dim` is a list of dimensions,</span>&nbsp;</span><span class="r"></span></p>
    <p id="t76" class="pln"><span class="n"><a href="#t76">76</a></span><span class="t"><span class="str">    reduce over all of them. When sum over all ``sparse_dim``, this method</span>&nbsp;</span><span class="r"></span></p>
    <p id="t77" class="pln"><span class="n"><a href="#t77">77</a></span><span class="t"><span class="str">    returns a Tensor instead of SparseTensor.</span>&nbsp;</span><span class="r"></span></p>
    <p id="t78" class="pln"><span class="n"><a href="#t78">78</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t79" class="pln"><span class="n"><a href="#t79">79</a></span><span class="t"><span class="str">    All summed :attr:`dim` are squeezed (see :func:`torch.squeeze`), resulting an output</span>&nbsp;</span><span class="r"></span></p>
    <p id="t80" class="pln"><span class="n"><a href="#t80">80</a></span><span class="t"><span class="str">    tensor having :attr:`dim` fewer dimensions than :attr:`input`.</span>&nbsp;</span><span class="r"></span></p>
    <p id="t81" class="pln"><span class="n"><a href="#t81">81</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t82" class="pln"><span class="n"><a href="#t82">82</a></span><span class="t"><span class="str">    During backward, only gradients at ``nnz`` locations of :attr:`input`</span>&nbsp;</span><span class="r"></span></p>
    <p id="t83" class="pln"><span class="n"><a href="#t83">83</a></span><span class="t"><span class="str">    will propagate back. Note that the gradients of :attr:`input` is coalesced.</span>&nbsp;</span><span class="r"></span></p>
    <p id="t84" class="pln"><span class="n"><a href="#t84">84</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t85" class="pln"><span class="n"><a href="#t85">85</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t86" class="pln"><span class="n"><a href="#t86">86</a></span><span class="t"><span class="str">        input (Tensor): the input SparseTensor</span>&nbsp;</span><span class="r"></span></p>
    <p id="t87" class="pln"><span class="n"><a href="#t87">87</a></span><span class="t"><span class="str">        dim (int or tuple of ints): a dimension or a list of dimensions to reduce. Default: reduce</span>&nbsp;</span><span class="r"></span></p>
    <p id="t88" class="pln"><span class="n"><a href="#t88">88</a></span><span class="t"><span class="str">            over all dims.</span>&nbsp;</span><span class="r"></span></p>
    <p id="t89" class="pln"><span class="n"><a href="#t89">89</a></span><span class="t"><span class="str">        dtype (:class:`torch.dtype`, optional): the desired data type of returned Tensor.</span>&nbsp;</span><span class="r"></span></p>
    <p id="t90" class="pln"><span class="n"><a href="#t90">90</a></span><span class="t"><span class="str">            Default: dtype of :attr:`input`.</span>&nbsp;</span><span class="r"></span></p>
    <p id="t91" class="pln"><span class="n"><a href="#t91">91</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t92" class="pln"><span class="n"><a href="#t92">92</a></span><span class="t"><span class="str">    Example::</span>&nbsp;</span><span class="r"></span></p>
    <p id="t93" class="pln"><span class="n"><a href="#t93">93</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t94" class="pln"><span class="n"><a href="#t94">94</a></span><span class="t"><span class="str">        >>> nnz = 3</span>&nbsp;</span><span class="r"></span></p>
    <p id="t95" class="pln"><span class="n"><a href="#t95">95</a></span><span class="t"><span class="str">        >>> dims = [5, 5, 2, 3]</span>&nbsp;</span><span class="r"></span></p>
    <p id="t96" class="pln"><span class="n"><a href="#t96">96</a></span><span class="t"><span class="str">        >>> I = torch.cat([torch.randint(0, dims[0], size=(nnz,)),</span>&nbsp;</span><span class="r"></span></p>
    <p id="t97" class="pln"><span class="n"><a href="#t97">97</a></span><span class="t"><span class="str">                           torch.randint(0, dims[1], size=(nnz,))], 0).reshape(2, nnz)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t98" class="pln"><span class="n"><a href="#t98">98</a></span><span class="t"><span class="str">        >>> V = torch.randn(nnz, dims[2], dims[3])</span>&nbsp;</span><span class="r"></span></p>
    <p id="t99" class="pln"><span class="n"><a href="#t99">99</a></span><span class="t"><span class="str">        >>> size = torch.Size(dims)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t100" class="pln"><span class="n"><a href="#t100">100</a></span><span class="t"><span class="str">        >>> S = torch.sparse_coo_tensor(I, V, size)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t101" class="pln"><span class="n"><a href="#t101">101</a></span><span class="t"><span class="str">        >>> S</span>&nbsp;</span><span class="r"></span></p>
    <p id="t102" class="pln"><span class="n"><a href="#t102">102</a></span><span class="t"><span class="str">        tensor(indices=tensor([[2, 0, 3],</span>&nbsp;</span><span class="r"></span></p>
    <p id="t103" class="pln"><span class="n"><a href="#t103">103</a></span><span class="t"><span class="str">                               [2, 4, 1]]),</span>&nbsp;</span><span class="r"></span></p>
    <p id="t104" class="pln"><span class="n"><a href="#t104">104</a></span><span class="t"><span class="str">               values=tensor([[[-0.6438, -1.6467,  1.4004],</span>&nbsp;</span><span class="r"></span></p>
    <p id="t105" class="pln"><span class="n"><a href="#t105">105</a></span><span class="t"><span class="str">                               [ 0.3411,  0.0918, -0.2312]],</span>&nbsp;</span><span class="r"></span></p>
    <p id="t106" class="pln"><span class="n"><a href="#t106">106</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t107" class="pln"><span class="n"><a href="#t107">107</a></span><span class="t"><span class="str">                              [[ 0.5348,  0.0634, -2.0494],</span>&nbsp;</span><span class="r"></span></p>
    <p id="t108" class="pln"><span class="n"><a href="#t108">108</a></span><span class="t"><span class="str">                               [-0.7125, -1.0646,  2.1844]],</span>&nbsp;</span><span class="r"></span></p>
    <p id="t109" class="pln"><span class="n"><a href="#t109">109</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t110" class="pln"><span class="n"><a href="#t110">110</a></span><span class="t"><span class="str">                              [[ 0.1276,  0.1874, -0.6334],</span>&nbsp;</span><span class="r"></span></p>
    <p id="t111" class="pln"><span class="n"><a href="#t111">111</a></span><span class="t"><span class="str">                               [-1.9682, -0.5340,  0.7483]]]),</span>&nbsp;</span><span class="r"></span></p>
    <p id="t112" class="pln"><span class="n"><a href="#t112">112</a></span><span class="t"><span class="str">               size=(5, 5, 2, 3), nnz=3, layout=torch.sparse_coo)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t113" class="pln"><span class="n"><a href="#t113">113</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t114" class="pln"><span class="n"><a href="#t114">114</a></span><span class="t"><span class="str">        # when sum over only part of sparse_dims, return a SparseTensor</span>&nbsp;</span><span class="r"></span></p>
    <p id="t115" class="pln"><span class="n"><a href="#t115">115</a></span><span class="t"><span class="str">        >>> torch.sparse.sum(S, [1, 3])</span>&nbsp;</span><span class="r"></span></p>
    <p id="t116" class="pln"><span class="n"><a href="#t116">116</a></span><span class="t"><span class="str">        tensor(indices=tensor([[0, 2, 3]]),</span>&nbsp;</span><span class="r"></span></p>
    <p id="t117" class="pln"><span class="n"><a href="#t117">117</a></span><span class="t"><span class="str">               values=tensor([[-1.4512,  0.4073],</span>&nbsp;</span><span class="r"></span></p>
    <p id="t118" class="pln"><span class="n"><a href="#t118">118</a></span><span class="t"><span class="str">                              [-0.8901,  0.2017],</span>&nbsp;</span><span class="r"></span></p>
    <p id="t119" class="pln"><span class="n"><a href="#t119">119</a></span><span class="t"><span class="str">                              [-0.3183, -1.7539]]),</span>&nbsp;</span><span class="r"></span></p>
    <p id="t120" class="pln"><span class="n"><a href="#t120">120</a></span><span class="t"><span class="str">               size=(5, 2), nnz=3, layout=torch.sparse_coo)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t121" class="pln"><span class="n"><a href="#t121">121</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t122" class="pln"><span class="n"><a href="#t122">122</a></span><span class="t"><span class="str">        # when sum over all sparse dim, return a dense Tensor</span>&nbsp;</span><span class="r"></span></p>
    <p id="t123" class="pln"><span class="n"><a href="#t123">123</a></span><span class="t"><span class="str">        # with summed dims squeezed</span>&nbsp;</span><span class="r"></span></p>
    <p id="t124" class="pln"><span class="n"><a href="#t124">124</a></span><span class="t"><span class="str">        >>> torch.sparse.sum(S, [0, 1, 3])</span>&nbsp;</span><span class="r"></span></p>
    <p id="t125" class="pln"><span class="n"><a href="#t125">125</a></span><span class="t"><span class="str">        tensor([-2.6596, -1.1450])</span>&nbsp;</span><span class="r"></span></p>
    <p id="t126" class="pln"><span class="n"><a href="#t126">126</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p id="t127" class="mis show_mis"><span class="n"><a href="#t127">127</a></span><span class="t">    <span class="key">if</span> <span class="nam">dtype</span> <span class="key">is</span> <span class="key">None</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t128" class="mis show_mis"><span class="n"><a href="#t128">128</a></span><span class="t">        <span class="key">if</span> <span class="nam">dim</span> <span class="key">is</span> <span class="key">not</span> <span class="key">None</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t129" class="mis show_mis"><span class="n"><a href="#t129">129</a></span><span class="t">            <span class="key">return</span> <span class="nam">torch</span><span class="op">.</span><span class="nam">_sparse_sum</span><span class="op">(</span><span class="nam">input</span><span class="op">,</span> <span class="nam">dim</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t130" class="pln"><span class="n"><a href="#t130">130</a></span><span class="t">        <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t131" class="mis show_mis"><span class="n"><a href="#t131">131</a></span><span class="t">            <span class="key">return</span> <span class="nam">torch</span><span class="op">.</span><span class="nam">_sparse_sum</span><span class="op">(</span><span class="nam">input</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t132" class="pln"><span class="n"><a href="#t132">132</a></span><span class="t">    <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t133" class="mis show_mis"><span class="n"><a href="#t133">133</a></span><span class="t">        <span class="key">if</span> <span class="nam">dim</span> <span class="key">is</span> <span class="key">not</span> <span class="key">None</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t134" class="mis show_mis"><span class="n"><a href="#t134">134</a></span><span class="t">            <span class="key">return</span> <span class="nam">torch</span><span class="op">.</span><span class="nam">_sparse_sum</span><span class="op">(</span><span class="nam">input</span><span class="op">,</span> <span class="nam">dim</span><span class="op">,</span> <span class="nam">dtype</span><span class="op">=</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t135" class="pln"><span class="n"><a href="#t135">135</a></span><span class="t">        <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t136" class="mis show_mis"><span class="n"><a href="#t136">136</a></span><span class="t">            <span class="key">return</span> <span class="nam">torch</span><span class="op">.</span><span class="nam">_sparse_sum</span><span class="op">(</span><span class="nam">input</span><span class="op">,</span> <span class="nam">dtype</span><span class="op">=</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
</div>
<div id="footer">
    <div class="content">
        <p>
            <a class="nav" href="index.html">&#xab; index</a> &nbsp; &nbsp; <a class="nav" href="https://coverage.readthedocs.io">coverage.py v5.0.3</a>,
            created at 2020-03-12 14:01
        </p>
    </div>
</div>
</body>
</html>
