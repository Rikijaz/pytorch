<!DOCTYPE html>
<html>
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=emulateIE7" />
    <title>Coverage for C:\Users\paper\Anaconda3\Lib\site-packages\torch\multiprocessing\reductions.py: 31%</title>
    <link rel="stylesheet" href="style.css" type="text/css">
    <script type="text/javascript" src="jquery.min.js"></script>
    <script type="text/javascript" src="jquery.hotkeys.js"></script>
    <script type="text/javascript" src="jquery.isonscreen.js"></script>
    <script type="text/javascript" src="coverage_html.js"></script>
    <script type="text/javascript">
        jQuery(document).ready(coverage.pyfile_ready);
    </script>
</head>
<body class="pyfile">
<div id="header">
    <div class="content">
        <h1>Coverage for <b>C:\Users\paper\Anaconda3\Lib\site-packages\torch\multiprocessing\reductions.py</b> :
            <span class="pc_cov">31%</span>
        </h1>
        <img id="keyboard_icon" src="keybd_closed.png" alt="Show keyboard shortcuts" />
        <h2 class="stats">
            144 statements &nbsp;
            <span class="run shortkey_r button_toggle_run">45 run</span>
            <span class="mis show_mis shortkey_m button_toggle_mis">99 missing</span>
            <span class="exc show_exc shortkey_x button_toggle_exc">0 excluded</span>
        </h2>
    </div>
</div>
<div class="help_panel">
    <img id="panel_icon" src="keybd_open.png" alt="Hide keyboard shortcuts" />
    <p class="legend">Hot-keys on this page</p>
    <div>
    <p class="keyhelp">
        <span class="key">r</span>
        <span class="key">m</span>
        <span class="key">x</span>
        <span class="key">p</span> &nbsp; toggle line displays
    </p>
    <p class="keyhelp">
        <span class="key">j</span>
        <span class="key">k</span> &nbsp; next/prev highlighted chunk
    </p>
    <p class="keyhelp">
        <span class="key">0</span> &nbsp; (zero) top of page
    </p>
    <p class="keyhelp">
        <span class="key">1</span> &nbsp; (one) first highlighted chunk
    </p>
    </div>
</div>
<div id="source">
    <p id="t1" class="run"><span class="n"><a href="#t1">1</a></span><span class="t"><span class="key">import</span> <span class="nam">torch</span>&nbsp;</span><span class="r"></span></p>
    <p id="t2" class="run"><span class="n"><a href="#t2">2</a></span><span class="t"><span class="key">import</span> <span class="nam">torch</span><span class="op">.</span><span class="nam">utils</span><span class="op">.</span><span class="nam">hooks</span>&nbsp;</span><span class="r"></span></p>
    <p id="t3" class="run"><span class="n"><a href="#t3">3</a></span><span class="t"><span class="key">from</span> <span class="nam">torch</span><span class="op">.</span><span class="nam">_namedtensor_internals</span> <span class="key">import</span> <span class="nam">check_serializing_named_tensor</span>&nbsp;</span><span class="r"></span></p>
    <p id="t4" class="run"><span class="n"><a href="#t4">4</a></span><span class="t"><span class="key">import</span> <span class="nam">os</span>&nbsp;</span><span class="r"></span></p>
    <p id="t5" class="run"><span class="n"><a href="#t5">5</a></span><span class="t"><span class="key">import</span> <span class="nam">threading</span>&nbsp;</span><span class="r"></span></p>
    <p id="t6" class="run"><span class="n"><a href="#t6">6</a></span><span class="t"><span class="key">import</span> <span class="nam">errno</span>&nbsp;</span><span class="r"></span></p>
    <p id="t7" class="run"><span class="n"><a href="#t7">7</a></span><span class="t"><span class="key">import</span> <span class="nam">multiprocessing</span>&nbsp;</span><span class="r"></span></p>
    <p id="t8" class="run"><span class="n"><a href="#t8">8</a></span><span class="t"><span class="key">from</span> <span class="nam">multiprocessing</span><span class="op">.</span><span class="nam">util</span> <span class="key">import</span> <span class="nam">register_after_fork</span>&nbsp;</span><span class="r"></span></p>
    <p id="t9" class="run"><span class="n"><a href="#t9">9</a></span><span class="t"><span class="key">from</span> <span class="nam">multiprocessing</span><span class="op">.</span><span class="nam">reduction</span> <span class="key">import</span> <span class="nam">ForkingPickler</span>&nbsp;</span><span class="r"></span></p>
    <p id="t10" class="run"><span class="n"><a href="#t10">10</a></span><span class="t"><span class="key">import</span> <span class="nam">sys</span>&nbsp;</span><span class="r"></span></p>
    <p id="t11" class="run"><span class="n"><a href="#t11">11</a></span><span class="t"><span class="key">try</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t12" class="pln"><span class="n"><a href="#t12">12</a></span><span class="t">    <span class="com"># Early load resource_sharer to prevent a partially initialized instance</span>&nbsp;</span><span class="r"></span></p>
    <p id="t13" class="pln"><span class="n"><a href="#t13">13</a></span><span class="t">    <span class="com"># from being inherited in a forked child process. The reduce_storage method</span>&nbsp;</span><span class="r"></span></p>
    <p id="t14" class="pln"><span class="n"><a href="#t14">14</a></span><span class="t">    <span class="com"># requires this module indirectly through DupFd(). The built-in mp.Queue</span>&nbsp;</span><span class="r"></span></p>
    <p id="t15" class="pln"><span class="n"><a href="#t15">15</a></span><span class="t">    <span class="com"># class pickles arguments in a background thread which may overlap with the</span>&nbsp;</span><span class="r"></span></p>
    <p id="t16" class="pln"><span class="n"><a href="#t16">16</a></span><span class="t">    <span class="com"># fork.</span>&nbsp;</span><span class="r"></span></p>
    <p id="t17" class="run"><span class="n"><a href="#t17">17</a></span><span class="t">    <span class="key">import</span> <span class="nam">multiprocessing</span><span class="op">.</span><span class="nam">resource_sharer</span>&nbsp;</span><span class="r"></span></p>
    <p id="t18" class="mis show_mis"><span class="n"><a href="#t18">18</a></span><span class="t"><span class="key">except</span> <span class="nam">ImportError</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t19" class="mis show_mis"><span class="n"><a href="#t19">19</a></span><span class="t">    <span class="key">pass</span>&nbsp;</span><span class="r"></span></p>
    <p id="t20" class="pln"><span class="n"><a href="#t20">20</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t21" class="pln"><span class="n"><a href="#t21">21</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t22" class="run"><span class="n"><a href="#t22">22</a></span><span class="t"><span class="key">class</span> <span class="nam">StorageWeakRef</span><span class="op">(</span><span class="nam">object</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t23" class="pln"><span class="n"><a href="#t23">23</a></span><span class="t">    <span class="str">r"""A weak reference to a Storage.</span>&nbsp;</span><span class="r"></span></p>
    <p id="t24" class="pln"><span class="n"><a href="#t24">24</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t25" class="pln"><span class="n"><a href="#t25">25</a></span><span class="t"><span class="str">    The cdata member is a Python number containing the integer representation of</span>&nbsp;</span><span class="r"></span></p>
    <p id="t26" class="pln"><span class="n"><a href="#t26">26</a></span><span class="t"><span class="str">    the Storage pointer."""</span>&nbsp;</span><span class="r"></span></p>
    <p id="t27" class="pln"><span class="n"><a href="#t27">27</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t28" class="run"><span class="n"><a href="#t28">28</a></span><span class="t">    <span class="key">def</span> <span class="nam">__init__</span><span class="op">(</span><span class="nam">self</span><span class="op">,</span> <span class="nam">storage</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t29" class="mis show_mis"><span class="n"><a href="#t29">29</a></span><span class="t">        <span class="nam">self</span><span class="op">.</span><span class="nam">cdata</span> <span class="op">=</span> <span class="nam">storage</span><span class="op">.</span><span class="nam">_weak_ref</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t30" class="pln"><span class="n"><a href="#t30">30</a></span><span class="t">        <span class="com"># Save a direct reference to _free_weak_ref because the `torch` module</span>&nbsp;</span><span class="r"></span></p>
    <p id="t31" class="pln"><span class="n"><a href="#t31">31</a></span><span class="t">        <span class="com"># might be cleared during Python shutdown before this module is cleared.</span>&nbsp;</span><span class="r"></span></p>
    <p id="t32" class="mis show_mis"><span class="n"><a href="#t32">32</a></span><span class="t">        <span class="nam">self</span><span class="op">.</span><span class="nam">_free_weak_ref</span> <span class="op">=</span> <span class="nam">torch</span><span class="op">.</span><span class="nam">Storage</span><span class="op">.</span><span class="nam">_free_weak_ref</span>&nbsp;</span><span class="r"></span></p>
    <p id="t33" class="pln"><span class="n"><a href="#t33">33</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t34" class="run"><span class="n"><a href="#t34">34</a></span><span class="t">    <span class="key">def</span> <span class="nam">expired</span><span class="op">(</span><span class="nam">self</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t35" class="mis show_mis"><span class="n"><a href="#t35">35</a></span><span class="t">        <span class="key">return</span> <span class="nam">torch</span><span class="op">.</span><span class="nam">Storage</span><span class="op">.</span><span class="nam">_expired</span><span class="op">(</span><span class="nam">self</span><span class="op">.</span><span class="nam">cdata</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t36" class="pln"><span class="n"><a href="#t36">36</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t37" class="run"><span class="n"><a href="#t37">37</a></span><span class="t">    <span class="key">def</span> <span class="nam">__del__</span><span class="op">(</span><span class="nam">self</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t38" class="mis show_mis"><span class="n"><a href="#t38">38</a></span><span class="t">        <span class="nam">self</span><span class="op">.</span><span class="nam">_free_weak_ref</span><span class="op">(</span><span class="nam">self</span><span class="op">.</span><span class="nam">cdata</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t39" class="pln"><span class="n"><a href="#t39">39</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t40" class="pln"><span class="n"><a href="#t40">40</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t41" class="run"><span class="n"><a href="#t41">41</a></span><span class="t"><span class="key">class</span> <span class="nam">SharedCache</span><span class="op">(</span><span class="nam">dict</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t42" class="pln"><span class="n"><a href="#t42">42</a></span><span class="t">    <span class="str">"""dictionary from multiprocessing handles to StorageWeakRef"""</span>&nbsp;</span><span class="r"></span></p>
    <p id="t43" class="pln"><span class="n"><a href="#t43">43</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t44" class="run"><span class="n"><a href="#t44">44</a></span><span class="t">    <span class="key">def</span> <span class="nam">__init__</span><span class="op">(</span><span class="nam">self</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t45" class="pln"><span class="n"><a href="#t45">45</a></span><span class="t">        <span class="com"># free_dead_references() is called if the len exceeds the current</span>&nbsp;</span><span class="r"></span></p>
    <p id="t46" class="pln"><span class="n"><a href="#t46">46</a></span><span class="t">        <span class="com"># limit. The limit scales with the number of remaining live objects.</span>&nbsp;</span><span class="r"></span></p>
    <p id="t47" class="run"><span class="n"><a href="#t47">47</a></span><span class="t">        <span class="nam">self</span><span class="op">.</span><span class="nam">limit</span> <span class="op">=</span> <span class="num">128</span>&nbsp;</span><span class="r"></span></p>
    <p id="t48" class="pln"><span class="n"><a href="#t48">48</a></span><span class="t">        <span class="com"># `fork` inherits lock state, so in case we fork when the lock is held,</span>&nbsp;</span><span class="r"></span></p>
    <p id="t49" class="pln"><span class="n"><a href="#t49">49</a></span><span class="t">        <span class="com"># we register a function to reset the lock to a new object to avoid</span>&nbsp;</span><span class="r"></span></p>
    <p id="t50" class="pln"><span class="n"><a href="#t50">50</a></span><span class="t">        <span class="com"># possible deadlocks, following python multiprocessing library design.</span>&nbsp;</span><span class="r"></span></p>
    <p id="t51" class="run"><span class="n"><a href="#t51">51</a></span><span class="t">        <span class="nam">self</span><span class="op">.</span><span class="nam">_after_fork</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t52" class="run"><span class="n"><a href="#t52">52</a></span><span class="t">        <span class="nam">register_after_fork</span><span class="op">(</span><span class="nam">self</span><span class="op">,</span> <span class="nam">SharedCache</span><span class="op">.</span><span class="nam">_after_fork</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t53" class="pln"><span class="n"><a href="#t53">53</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t54" class="run"><span class="n"><a href="#t54">54</a></span><span class="t">    <span class="key">def</span> <span class="nam">_after_fork</span><span class="op">(</span><span class="nam">self</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t55" class="run"><span class="n"><a href="#t55">55</a></span><span class="t">        <span class="nam">self</span><span class="op">.</span><span class="nam">lock</span> <span class="op">=</span> <span class="nam">threading</span><span class="op">.</span><span class="nam">Lock</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t56" class="pln"><span class="n"><a href="#t56">56</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t57" class="run"><span class="n"><a href="#t57">57</a></span><span class="t">    <span class="key">def</span> <span class="nam">__setitem__</span><span class="op">(</span><span class="nam">self</span><span class="op">,</span> <span class="nam">key</span><span class="op">,</span> <span class="nam">storage_ref</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t58" class="mis show_mis"><span class="n"><a href="#t58">58</a></span><span class="t">        <span class="nam">dict</span><span class="op">.</span><span class="nam">__setitem__</span><span class="op">(</span><span class="nam">self</span><span class="op">,</span> <span class="nam">key</span><span class="op">,</span> <span class="nam">storage_ref</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t59" class="mis show_mis"><span class="n"><a href="#t59">59</a></span><span class="t">        <span class="key">if</span> <span class="nam">len</span><span class="op">(</span><span class="nam">self</span><span class="op">)</span> <span class="op">></span> <span class="nam">self</span><span class="op">.</span><span class="nam">limit</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t60" class="mis show_mis"><span class="n"><a href="#t60">60</a></span><span class="t">            <span class="nam">self</span><span class="op">.</span><span class="nam">free_dead_references</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t61" class="pln"><span class="n"><a href="#t61">61</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t62" class="run"><span class="n"><a href="#t62">62</a></span><span class="t">    <span class="key">def</span> <span class="nam">free_dead_references</span><span class="op">(</span><span class="nam">self</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t63" class="pln"><span class="n"><a href="#t63">63</a></span><span class="t">        <span class="com"># Multiple Python threads may call free_dead_references() concurrently.</span>&nbsp;</span><span class="r"></span></p>
    <p id="t64" class="pln"><span class="n"><a href="#t64">64</a></span><span class="t">        <span class="com"># Without a lock, they may try deleting the same entry multiple times.</span>&nbsp;</span><span class="r"></span></p>
    <p id="t65" class="mis show_mis"><span class="n"><a href="#t65">65</a></span><span class="t">        <span class="key">with</span> <span class="nam">self</span><span class="op">.</span><span class="nam">lock</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t66" class="mis show_mis"><span class="n"><a href="#t66">66</a></span><span class="t">            <span class="nam">live</span> <span class="op">=</span> <span class="num">0</span>&nbsp;</span><span class="r"></span></p>
    <p id="t67" class="mis show_mis"><span class="n"><a href="#t67">67</a></span><span class="t">            <span class="key">for</span> <span class="nam">key</span><span class="op">,</span> <span class="nam">storage_ref</span> <span class="key">in</span> <span class="nam">list</span><span class="op">(</span><span class="nam">self</span><span class="op">.</span><span class="nam">items</span><span class="op">(</span><span class="op">)</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t68" class="mis show_mis"><span class="n"><a href="#t68">68</a></span><span class="t">                <span class="key">if</span> <span class="nam">storage_ref</span><span class="op">.</span><span class="nam">expired</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t69" class="mis show_mis"><span class="n"><a href="#t69">69</a></span><span class="t">                    <span class="key">del</span> <span class="nam">self</span><span class="op">[</span><span class="nam">key</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p id="t70" class="pln"><span class="n"><a href="#t70">70</a></span><span class="t">                <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t71" class="mis show_mis"><span class="n"><a href="#t71">71</a></span><span class="t">                    <span class="nam">live</span> <span class="op">+=</span> <span class="num">1</span>&nbsp;</span><span class="r"></span></p>
    <p id="t72" class="mis show_mis"><span class="n"><a href="#t72">72</a></span><span class="t">            <span class="nam">self</span><span class="op">.</span><span class="nam">limit</span> <span class="op">=</span> <span class="nam">max</span><span class="op">(</span><span class="num">128</span><span class="op">,</span> <span class="nam">live</span> <span class="op">*</span> <span class="num">2</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t73" class="pln"><span class="n"><a href="#t73">73</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t74" class="pln"><span class="n"><a href="#t74">74</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t75" class="pln"><span class="n"><a href="#t75">75</a></span><span class="t"><span class="com"># mapping from handles to StorageWeakRef objects</span>&nbsp;</span><span class="r"></span></p>
    <p id="t76" class="run"><span class="n"><a href="#t76">76</a></span><span class="t"><span class="nam">shared_cache</span> <span class="op">=</span> <span class="nam">SharedCache</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t77" class="pln"><span class="n"><a href="#t77">77</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t78" class="pln"><span class="n"><a href="#t78">78</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t79" class="run"><span class="n"><a href="#t79">79</a></span><span class="t"><span class="key">def</span> <span class="nam">rebuild_event</span><span class="op">(</span><span class="nam">device</span><span class="op">,</span> <span class="nam">handle</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t80" class="mis show_mis"><span class="n"><a href="#t80">80</a></span><span class="t">    <span class="key">return</span> <span class="nam">torch</span><span class="op">.</span><span class="nam">cuda</span><span class="op">.</span><span class="nam">Event</span><span class="op">.</span><span class="nam">from_ipc_handle</span><span class="op">(</span><span class="nam">device</span><span class="op">,</span> <span class="nam">handle</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t81" class="pln"><span class="n"><a href="#t81">81</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t82" class="pln"><span class="n"><a href="#t82">82</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t83" class="run"><span class="n"><a href="#t83">83</a></span><span class="t"><span class="key">def</span> <span class="nam">reduce_event</span><span class="op">(</span><span class="nam">event</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t84" class="mis show_mis"><span class="n"><a href="#t84">84</a></span><span class="t">    <span class="nam">handle</span> <span class="op">=</span> <span class="nam">event</span><span class="op">.</span><span class="nam">ipc_handle</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t85" class="mis show_mis"><span class="n"><a href="#t85">85</a></span><span class="t">    <span class="key">return</span> <span class="op">(</span><span class="nam">rebuild_event</span><span class="op">,</span> <span class="op">(</span><span class="nam">event</span><span class="op">.</span><span class="nam">device</span><span class="op">,</span> <span class="nam">handle</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t86" class="pln"><span class="n"><a href="#t86">86</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t87" class="pln"><span class="n"><a href="#t87">87</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t88" class="run"><span class="n"><a href="#t88">88</a></span><span class="t"><span class="key">def</span> <span class="nam">rebuild_tensor</span><span class="op">(</span><span class="nam">cls</span><span class="op">,</span> <span class="nam">storage</span><span class="op">,</span> <span class="nam">metadata</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t89" class="mis show_mis"><span class="n"><a href="#t89">89</a></span><span class="t">    <span class="nam">storage_offset</span><span class="op">,</span> <span class="nam">size</span><span class="op">,</span> <span class="nam">stride</span><span class="op">,</span> <span class="nam">requires_grad</span> <span class="op">=</span> <span class="nam">metadata</span>&nbsp;</span><span class="r"></span></p>
    <p id="t90" class="mis show_mis"><span class="n"><a href="#t90">90</a></span><span class="t">    <span class="nam">t</span> <span class="op">=</span> <span class="nam">torch</span><span class="op">.</span><span class="nam">_utils</span><span class="op">.</span><span class="nam">_rebuild_tensor</span><span class="op">(</span><span class="nam">storage</span><span class="op">,</span> <span class="nam">storage_offset</span><span class="op">,</span> <span class="nam">size</span><span class="op">,</span> <span class="nam">stride</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t91" class="mis show_mis"><span class="n"><a href="#t91">91</a></span><span class="t">    <span class="key">if</span> <span class="nam">cls</span> <span class="op">==</span> <span class="nam">torch</span><span class="op">.</span><span class="nam">nn</span><span class="op">.</span><span class="nam">parameter</span><span class="op">.</span><span class="nam">Parameter</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t92" class="pln"><span class="n"><a href="#t92">92</a></span><span class="t">        <span class="com"># we have to pass requires_grad into constructor, rather than set it as an</span>&nbsp;</span><span class="r"></span></p>
    <p id="t93" class="pln"><span class="n"><a href="#t93">93</a></span><span class="t">        <span class="com"># attribute later, because it's an important check for Integer Tensors to</span>&nbsp;</span><span class="r"></span></p>
    <p id="t94" class="pln"><span class="n"><a href="#t94">94</a></span><span class="t">        <span class="com"># have requires_grad=False (or else they raise an error)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t95" class="mis show_mis"><span class="n"><a href="#t95">95</a></span><span class="t">        <span class="nam">t</span> <span class="op">=</span> <span class="nam">torch</span><span class="op">.</span><span class="nam">nn</span><span class="op">.</span><span class="nam">parameter</span><span class="op">.</span><span class="nam">Parameter</span><span class="op">(</span><span class="nam">t</span><span class="op">,</span> <span class="nam">requires_grad</span><span class="op">=</span><span class="nam">requires_grad</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t96" class="pln"><span class="n"><a href="#t96">96</a></span><span class="t">    <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t97" class="mis show_mis"><span class="n"><a href="#t97">97</a></span><span class="t">        <span class="nam">t</span><span class="op">.</span><span class="nam">requires_grad</span> <span class="op">=</span> <span class="nam">requires_grad</span>&nbsp;</span><span class="r"></span></p>
    <p id="t98" class="mis show_mis"><span class="n"><a href="#t98">98</a></span><span class="t">    <span class="key">return</span> <span class="nam">t</span>&nbsp;</span><span class="r"></span></p>
    <p id="t99" class="pln"><span class="n"><a href="#t99">99</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t100" class="pln"><span class="n"><a href="#t100">100</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t101" class="run"><span class="n"><a href="#t101">101</a></span><span class="t"><span class="key">def</span> <span class="nam">rebuild_cuda_tensor</span><span class="op">(</span><span class="nam">tensor_cls</span><span class="op">,</span> <span class="nam">tensor_size</span><span class="op">,</span> <span class="nam">tensor_stride</span><span class="op">,</span> <span class="nam">tensor_offset</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p id="t102" class="pln"><span class="n"><a href="#t102">102</a></span><span class="t">                        <span class="nam">storage_cls</span><span class="op">,</span> <span class="nam">storage_device</span><span class="op">,</span> <span class="nam">storage_handle</span><span class="op">,</span> <span class="nam">storage_size_bytes</span><span class="op">,</span> <span class="nam">storage_offset_bytes</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p id="t103" class="pln"><span class="n"><a href="#t103">103</a></span><span class="t">                        <span class="nam">requires_grad</span><span class="op">,</span> <span class="nam">ref_counter_handle</span><span class="op">,</span> <span class="nam">ref_counter_offset</span><span class="op">,</span> <span class="nam">event_handle</span><span class="op">,</span> <span class="nam">event_sync_required</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t104" class="pln"><span class="n"><a href="#t104">104</a></span><span class="t">    <span class="com"># If storage_handle is None, storage points to nullptr.</span>&nbsp;</span><span class="r"></span></p>
    <p id="t105" class="mis show_mis"><span class="n"><a href="#t105">105</a></span><span class="t">    <span class="key">if</span> <span class="nam">storage_handle</span> <span class="key">is</span> <span class="key">None</span> <span class="key">or</span> <span class="nam">storage_size_bytes</span> <span class="op">==</span> <span class="num">0</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t106" class="mis show_mis"><span class="n"><a href="#t106">106</a></span><span class="t">        <span class="nam">storage</span> <span class="op">=</span> <span class="nam">storage_cls</span><span class="op">(</span><span class="num">0</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t107" class="pln"><span class="n"><a href="#t107">107</a></span><span class="t">    <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t108" class="mis show_mis"><span class="n"><a href="#t108">108</a></span><span class="t">        <span class="nam">storage</span> <span class="op">=</span> <span class="nam">storage_from_cache</span><span class="op">(</span><span class="nam">storage_cls</span><span class="op">,</span> <span class="op">(</span><span class="nam">storage_handle</span><span class="op">,</span> <span class="nam">storage_offset_bytes</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t109" class="mis show_mis"><span class="n"><a href="#t109">109</a></span><span class="t">        <span class="key">if</span> <span class="nam">storage</span> <span class="key">is</span> <span class="key">None</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t110" class="mis show_mis"><span class="n"><a href="#t110">110</a></span><span class="t">            <span class="nam">torch</span><span class="op">.</span><span class="nam">cuda</span><span class="op">.</span><span class="nam">_lazy_init</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t111" class="mis show_mis"><span class="n"><a href="#t111">111</a></span><span class="t">            <span class="nam">storage</span> <span class="op">=</span> <span class="nam">storage_cls</span><span class="op">.</span><span class="nam">_new_shared_cuda</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p id="t112" class="pln"><span class="n"><a href="#t112">112</a></span><span class="t">                <span class="nam">storage_device</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p id="t113" class="pln"><span class="n"><a href="#t113">113</a></span><span class="t">                <span class="nam">storage_handle</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p id="t114" class="pln"><span class="n"><a href="#t114">114</a></span><span class="t">                <span class="nam">storage_size_bytes</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p id="t115" class="pln"><span class="n"><a href="#t115">115</a></span><span class="t">                <span class="nam">storage_offset_bytes</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p id="t116" class="pln"><span class="n"><a href="#t116">116</a></span><span class="t">                <span class="nam">ref_counter_handle</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p id="t117" class="pln"><span class="n"><a href="#t117">117</a></span><span class="t">                <span class="nam">ref_counter_offset</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p id="t118" class="pln"><span class="n"><a href="#t118">118</a></span><span class="t">                <span class="nam">event_handle</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p id="t119" class="pln"><span class="n"><a href="#t119">119</a></span><span class="t">                <span class="nam">event_sync_required</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t120" class="mis show_mis"><span class="n"><a href="#t120">120</a></span><span class="t">            <span class="nam">shared_cache</span><span class="op">[</span><span class="op">(</span><span class="nam">storage_handle</span><span class="op">,</span> <span class="nam">storage_offset_bytes</span><span class="op">)</span><span class="op">]</span> <span class="op">=</span> <span class="nam">StorageWeakRef</span><span class="op">(</span><span class="nam">storage</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t121" class="pln"><span class="n"><a href="#t121">121</a></span><span class="t">        <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t122" class="pln"><span class="n"><a href="#t122">122</a></span><span class="t">            <span class="com"># We already ref counting this Storage, but producer needs new ref-counters to be released.</span>&nbsp;</span><span class="r"></span></p>
    <p id="t123" class="mis show_mis"><span class="n"><a href="#t123">123</a></span><span class="t">            <span class="nam">storage_cls</span><span class="op">.</span><span class="nam">_release_ipc_counter</span><span class="op">(</span><span class="nam">ref_counter_handle</span><span class="op">,</span> <span class="nam">ref_counter_offset</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t124" class="pln"><span class="n"><a href="#t124">124</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t125" class="mis show_mis"><span class="n"><a href="#t125">125</a></span><span class="t">    <span class="nam">t</span> <span class="op">=</span> <span class="nam">torch</span><span class="op">.</span><span class="nam">_utils</span><span class="op">.</span><span class="nam">_rebuild_tensor</span><span class="op">(</span><span class="nam">storage</span><span class="op">,</span> <span class="nam">tensor_offset</span><span class="op">,</span> <span class="nam">tensor_size</span><span class="op">,</span> <span class="nam">tensor_stride</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t126" class="mis show_mis"><span class="n"><a href="#t126">126</a></span><span class="t">    <span class="key">if</span> <span class="nam">tensor_cls</span> <span class="op">==</span> <span class="nam">torch</span><span class="op">.</span><span class="nam">nn</span><span class="op">.</span><span class="nam">parameter</span><span class="op">.</span><span class="nam">Parameter</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t127" class="mis show_mis"><span class="n"><a href="#t127">127</a></span><span class="t">        <span class="nam">t</span> <span class="op">=</span> <span class="nam">torch</span><span class="op">.</span><span class="nam">nn</span><span class="op">.</span><span class="nam">parameter</span><span class="op">.</span><span class="nam">Parameter</span><span class="op">(</span><span class="nam">t</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t128" class="mis show_mis"><span class="n"><a href="#t128">128</a></span><span class="t">    <span class="nam">t</span><span class="op">.</span><span class="nam">requires_grad</span> <span class="op">=</span> <span class="nam">requires_grad</span>&nbsp;</span><span class="r"></span></p>
    <p id="t129" class="mis show_mis"><span class="n"><a href="#t129">129</a></span><span class="t">    <span class="key">return</span> <span class="nam">t</span>&nbsp;</span><span class="r"></span></p>
    <p id="t130" class="pln"><span class="n"><a href="#t130">130</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t131" class="pln"><span class="n"><a href="#t131">131</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t132" class="run"><span class="n"><a href="#t132">132</a></span><span class="t"><span class="key">def</span> <span class="nam">reduce_tensor</span><span class="op">(</span><span class="nam">tensor</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t133" class="mis show_mis"><span class="n"><a href="#t133">133</a></span><span class="t">    <span class="nam">storage</span> <span class="op">=</span> <span class="nam">tensor</span><span class="op">.</span><span class="nam">storage</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t134" class="pln"><span class="n"><a href="#t134">134</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t135" class="mis show_mis"><span class="n"><a href="#t135">135</a></span><span class="t">    <span class="key">if</span> <span class="nam">tensor</span><span class="op">.</span><span class="nam">requires_grad</span> <span class="key">and</span> <span class="key">not</span> <span class="nam">tensor</span><span class="op">.</span><span class="nam">is_leaf</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t136" class="mis show_mis"><span class="n"><a href="#t136">136</a></span><span class="t">        <span class="key">raise</span> <span class="nam">RuntimeError</span><span class="op">(</span><span class="str">"Cowardly refusing to serialize non-leaf tensor which requires_grad, "</span>&nbsp;</span><span class="r"></span></p>
    <p id="t137" class="pln"><span class="n"><a href="#t137">137</a></span><span class="t">                           <span class="str">"since autograd does not support crossing process boundaries.  "</span>&nbsp;</span><span class="r"></span></p>
    <p id="t138" class="pln"><span class="n"><a href="#t138">138</a></span><span class="t">                           <span class="str">"If you just want to transfer the data, call detach() on the tensor "</span>&nbsp;</span><span class="r"></span></p>
    <p id="t139" class="pln"><span class="n"><a href="#t139">139</a></span><span class="t">                           <span class="str">"before serializing (e.g., putting it on the queue)."</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t140" class="pln"><span class="n"><a href="#t140">140</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t141" class="mis show_mis"><span class="n"><a href="#t141">141</a></span><span class="t">    <span class="nam">check_serializing_named_tensor</span><span class="op">(</span><span class="nam">tensor</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t142" class="mis show_mis"><span class="n"><a href="#t142">142</a></span><span class="t">    <span class="nam">torch</span><span class="op">.</span><span class="nam">utils</span><span class="op">.</span><span class="nam">hooks</span><span class="op">.</span><span class="nam">warn_if_has_hooks</span><span class="op">(</span><span class="nam">tensor</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t143" class="pln"><span class="n"><a href="#t143">143</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t144" class="pln"><span class="n"><a href="#t144">144</a></span><span class="t">    <span class="com"># Note [CUDA IPC and the caching allocator]</span>&nbsp;</span><span class="r"></span></p>
    <p id="t145" class="pln"><span class="n"><a href="#t145">145</a></span><span class="t">    <span class="com"># ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~</span>&nbsp;</span><span class="r"></span></p>
    <p id="t146" class="pln"><span class="n"><a href="#t146">146</a></span><span class="t">    <span class="com"># When you send a CUDA tensor over IPC, you might expect that you will</span>&nbsp;</span><span class="r"></span></p>
    <p id="t147" class="pln"><span class="n"><a href="#t147">147</a></span><span class="t">    <span class="com"># get out the same storage from the other end.  However, the CUDA caching</span>&nbsp;</span><span class="r"></span></p>
    <p id="t148" class="pln"><span class="n"><a href="#t148">148</a></span><span class="t">    <span class="com"># allocator makes it difficult to preserve this invariant.  Consider</span>&nbsp;</span><span class="r"></span></p>
    <p id="t149" class="pln"><span class="n"><a href="#t149">149</a></span><span class="t">    <span class="com"># the following situation: a tensor of size 0x100 points to offset 0x20 of</span>&nbsp;</span><span class="r"></span></p>
    <p id="t150" class="pln"><span class="n"><a href="#t150">150</a></span><span class="t">    <span class="com"># a storage at 0xA100 of size 0x100.  (For simplicity, all of these</span>&nbsp;</span><span class="r"></span></p>
    <p id="t151" class="pln"><span class="n"><a href="#t151">151</a></span><span class="t">    <span class="com"># sizes are given in bytes).  HOWEVER, with the caching allocator, this storage</span>&nbsp;</span><span class="r"></span></p>
    <p id="t152" class="pln"><span class="n"><a href="#t152">152</a></span><span class="t">    <span class="com"># might be part of a larger cudaMalloc allocation 0xA000 of size 0x4000.</span>&nbsp;</span><span class="r"></span></p>
    <p id="t153" class="pln"><span class="n"><a href="#t153">153</a></span><span class="t">    <span class="com">#</span>&nbsp;</span><span class="r"></span></p>
    <p id="t154" class="pln"><span class="n"><a href="#t154">154</a></span><span class="t">    <span class="com"># When we want to send this CUDA tensor over IPC, we must send the</span>&nbsp;</span><span class="r"></span></p>
    <p id="t155" class="pln"><span class="n"><a href="#t155">155</a></span><span class="t">    <span class="com"># *entire* cudaMalloc allocation, i.e., the 0xA000 region, not just</span>&nbsp;</span><span class="r"></span></p>
    <p id="t156" class="pln"><span class="n"><a href="#t156">156</a></span><span class="t">    <span class="com"># the storage 0xA100 (because that is what CUDA supports).  So, on the</span>&nbsp;</span><span class="r"></span></p>
    <p id="t157" class="pln"><span class="n"><a href="#t157">157</a></span><span class="t">    <span class="com"># other end, there simply isn't any way to say, "Wait, you gave me</span>&nbsp;</span><span class="r"></span></p>
    <p id="t158" class="pln"><span class="n"><a href="#t158">158</a></span><span class="t">    <span class="com"># a bigger region (0xA000) than the one I wanted (0xA100)".</span>&nbsp;</span><span class="r"></span></p>
    <p id="t159" class="pln"><span class="n"><a href="#t159">159</a></span><span class="t">    <span class="com">#</span>&nbsp;</span><span class="r"></span></p>
    <p id="t160" class="pln"><span class="n"><a href="#t160">160</a></span><span class="t">    <span class="com"># OK, so if you sent the cudaMalloc allocation, can you just wrap that up as</span>&nbsp;</span><span class="r"></span></p>
    <p id="t161" class="pln"><span class="n"><a href="#t161">161</a></span><span class="t">    <span class="com"># one storage itself? No, because this cudaMalloc allocation might contain</span>&nbsp;</span><span class="r"></span></p>
    <p id="t162" class="pln"><span class="n"><a href="#t162">162</a></span><span class="t">    <span class="com"># storages of mixed types: float, bytes, double... If you make the entire</span>&nbsp;</span><span class="r"></span></p>
    <p id="t163" class="pln"><span class="n"><a href="#t163">163</a></span><span class="t">    <span class="com"># allocation a single storage of a type A, we'll hit an error when constructing</span>&nbsp;</span><span class="r"></span></p>
    <p id="t164" class="pln"><span class="n"><a href="#t164">164</a></span><span class="t">    <span class="com"># a tensor of type B on the storage.</span>&nbsp;</span><span class="r"></span></p>
    <p id="t165" class="pln"><span class="n"><a href="#t165">165</a></span><span class="t">    <span class="com">#</span>&nbsp;</span><span class="r"></span></p>
    <p id="t166" class="pln"><span class="n"><a href="#t166">166</a></span><span class="t">    <span class="com"># cudaIpcMemHandle is an identifier to access the sender cudaMalloc allocation on the</span>&nbsp;</span><span class="r"></span></p>
    <p id="t167" class="pln"><span class="n"><a href="#t167">167</a></span><span class="t">    <span class="com"># receiver side. However, cudaIpcMemHandles from each device in a given process may</span>&nbsp;</span><span class="r"></span></p>
    <p id="t168" class="pln"><span class="n"><a href="#t168">168</a></span><span class="t">    <span class="com"># only be opened by one context per device per other process.</span>&nbsp;</span><span class="r"></span></p>
    <p id="t169" class="pln"><span class="n"><a href="#t169">169</a></span><span class="t">    <span class="com"># If we open and close a memory handle multiples times in a process, CUDA is allowed</span>&nbsp;</span><span class="r"></span></p>
    <p id="t170" class="pln"><span class="n"><a href="#t170">170</a></span><span class="t">    <span class="com"># to give it a different address; similarly, once we close the memory, we're not</span>&nbsp;</span><span class="r"></span></p>
    <p id="t171" class="pln"><span class="n"><a href="#t171">171</a></span><span class="t">    <span class="com"># allowed to access it(and the storage/tensor built on top of it), even if it is</span>&nbsp;</span><span class="r"></span></p>
    <p id="t172" class="pln"><span class="n"><a href="#t172">172</a></span><span class="t">    <span class="com"># still live in the original process. As we cannot make a cudaMalloc allocation</span>&nbsp;</span><span class="r"></span></p>
    <p id="t173" class="pln"><span class="n"><a href="#t173">173</a></span><span class="t">    <span class="com"># to a single storage in one go, this requires us to cache the device pointer for</span>&nbsp;</span><span class="r"></span></p>
    <p id="t174" class="pln"><span class="n"><a href="#t174">174</a></span><span class="t">    <span class="com"># each cudaIpcMemHandle on C++ side to reconstruct types of storages, while keep</span>&nbsp;</span><span class="r"></span></p>
    <p id="t175" class="pln"><span class="n"><a href="#t175">175</a></span><span class="t">    <span class="com"># the old ones alives.</span>&nbsp;</span><span class="r"></span></p>
    <p id="t176" class="pln"><span class="n"><a href="#t176">176</a></span><span class="t">    <span class="com"># See [https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html]</span>&nbsp;</span><span class="r"></span></p>
    <p id="t177" class="pln"><span class="n"><a href="#t177">177</a></span><span class="t">    <span class="com">#</span>&nbsp;</span><span class="r"></span></p>
    <p id="t178" class="pln"><span class="n"><a href="#t178">178</a></span><span class="t">    <span class="com"># This is fine, because all we need to do is to save our position in the allocation,</span>&nbsp;</span><span class="r"></span></p>
    <p id="t179" class="pln"><span class="n"><a href="#t179">179</a></span><span class="t">    <span class="com"># and reconstruct storage and tensor from it.</span>&nbsp;</span><span class="r"></span></p>
    <p id="t180" class="pln"><span class="n"><a href="#t180">180</a></span><span class="t">    <span class="com"># 0xA000 ->  -------CUDA Allocation------</span>&nbsp;</span><span class="r"></span></p>
    <p id="t181" class="pln"><span class="n"><a href="#t181">181</a></span><span class="t">    <span class="com">#           |                            |</span>&nbsp;</span><span class="r"></span></p>
    <p id="t182" class="pln"><span class="n"><a href="#t182">182</a></span><span class="t">    <span class="com">#           |                            |</span>&nbsp;</span><span class="r"></span></p>
    <p id="t183" class="pln"><span class="n"><a href="#t183">183</a></span><span class="t">    <span class="com">#           |                            |</span>&nbsp;</span><span class="r"></span></p>
    <p id="t184" class="pln"><span class="n"><a href="#t184">184</a></span><span class="t">    <span class="com">#           |                            |</span>&nbsp;</span><span class="r"></span></p>
    <p id="t185" class="pln"><span class="n"><a href="#t185">185</a></span><span class="t">    <span class="com"># 0xA100 ->  --------storage1 begin------</span>&nbsp;</span><span class="r"></span></p>
    <p id="t186" class="pln"><span class="n"><a href="#t186">186</a></span><span class="t">    <span class="com">#           |                            |</span>&nbsp;</span><span class="r"></span></p>
    <p id="t187" class="pln"><span class="n"><a href="#t187">187</a></span><span class="t">    <span class="com"># 0xA120 ->  --------tensor1 begin ------</span>&nbsp;</span><span class="r"></span></p>
    <p id="t188" class="pln"><span class="n"><a href="#t188">188</a></span><span class="t">    <span class="com">#           |                            |</span>&nbsp;</span><span class="r"></span></p>
    <p id="t189" class="pln"><span class="n"><a href="#t189">189</a></span><span class="t">    <span class="com">#           |                            |</span>&nbsp;</span><span class="r"></span></p>
    <p id="t190" class="pln"><span class="n"><a href="#t190">190</a></span><span class="t">    <span class="com">#           |                            |</span>&nbsp;</span><span class="r"></span></p>
    <p id="t191" class="pln"><span class="n"><a href="#t191">191</a></span><span class="t">    <span class="com">#           |                            |</span>&nbsp;</span><span class="r"></span></p>
    <p id="t192" class="pln"><span class="n"><a href="#t192">192</a></span><span class="t">    <span class="com">#           |                            |</span>&nbsp;</span><span class="r"></span></p>
    <p id="t193" class="pln"><span class="n"><a href="#t193">193</a></span><span class="t">    <span class="com"># 0xA160 ->  --------tensor1 end---------</span>&nbsp;</span><span class="r"></span></p>
    <p id="t194" class="pln"><span class="n"><a href="#t194">194</a></span><span class="t">    <span class="com">#           |                            |</span>&nbsp;</span><span class="r"></span></p>
    <p id="t195" class="pln"><span class="n"><a href="#t195">195</a></span><span class="t">    <span class="com">#           |                            |</span>&nbsp;</span><span class="r"></span></p>
    <p id="t196" class="pln"><span class="n"><a href="#t196">196</a></span><span class="t">    <span class="com">#           |                            |</span>&nbsp;</span><span class="r"></span></p>
    <p id="t197" class="pln"><span class="n"><a href="#t197">197</a></span><span class="t">    <span class="com"># 0xA200 ->  --------storage1 end--------</span>&nbsp;</span><span class="r"></span></p>
    <p id="t198" class="pln"><span class="n"><a href="#t198">198</a></span><span class="t">    <span class="com">#           |                            |</span>&nbsp;</span><span class="r"></span></p>
    <p id="t199" class="pln"><span class="n"><a href="#t199">199</a></span><span class="t">    <span class="com"># 0xE000 ->  --------CUDA allocation-----</span>&nbsp;</span><span class="r"></span></p>
    <p id="t200" class="pln"><span class="n"><a href="#t200">200</a></span><span class="t">    <span class="com">#</span>&nbsp;</span><span class="r"></span></p>
    <p id="t201" class="pln"><span class="n"><a href="#t201">201</a></span><span class="t">    <span class="com"># To send tensor1, the following info are required from sender to receiver for</span>&nbsp;</span><span class="r"></span></p>
    <p id="t202" class="pln"><span class="n"><a href="#t202">202</a></span><span class="t">    <span class="com"># storage recontruction.</span>&nbsp;</span><span class="r"></span></p>
    <p id="t203" class="pln"><span class="n"><a href="#t203">203</a></span><span class="t">    <span class="com">#   1. cudaIpcMemHandle of 0xA000(which can be mapped to a basePtr in receiver process).</span>&nbsp;</span><span class="r"></span></p>
    <p id="t204" class="pln"><span class="n"><a href="#t204">204</a></span><span class="t">    <span class="com">#      basePtr may not be exactly 0xA000 since it's a different process.</span>&nbsp;</span><span class="r"></span></p>
    <p id="t205" class="pln"><span class="n"><a href="#t205">205</a></span><span class="t">    <span class="com">#   2. offset(0xA100) of storage1 in the CUDA allocation.</span>&nbsp;</span><span class="r"></span></p>
    <p id="t206" class="pln"><span class="n"><a href="#t206">206</a></span><span class="t">    <span class="com">#   3. size of storage1(0x100).</span>&nbsp;</span><span class="r"></span></p>
    <p id="t207" class="pln"><span class="n"><a href="#t207">207</a></span><span class="t">    <span class="com">#</span>&nbsp;</span><span class="r"></span></p>
    <p id="t208" class="pln"><span class="n"><a href="#t208">208</a></span><span class="t">    <span class="com"># On receiver side:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t209" class="pln"><span class="n"><a href="#t209">209</a></span><span class="t">    <span class="com">#   1. Get the devPtr of the MemHandle to access the memory, reconstruct a storage</span>&nbsp;</span><span class="r"></span></p>
    <p id="t210" class="pln"><span class="n"><a href="#t210">210</a></span><span class="t">    <span class="com">#      of the same type using (basePtr, offset, size).</span>&nbsp;</span><span class="r"></span></p>
    <p id="t211" class="pln"><span class="n"><a href="#t211">211</a></span><span class="t">    <span class="com">#   2. we can reconstruct the tensor on top of the reconstructed storage</span>&nbsp;</span><span class="r"></span></p>
    <p id="t212" class="pln"><span class="n"><a href="#t212">212</a></span><span class="t">    <span class="com">#   Tensor(size=0x040, offset=0x020, storage=Storage(data=basePtr+0xA100, size=0x0100))</span>&nbsp;</span><span class="r"></span></p>
    <p id="t213" class="pln"><span class="n"><a href="#t213">213</a></span><span class="t">    <span class="com">#</span>&nbsp;</span><span class="r"></span></p>
    <p id="t214" class="pln"><span class="n"><a href="#t214">214</a></span><span class="t">    <span class="com"># This strategy has a few implications:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t215" class="pln"><span class="n"><a href="#t215">215</a></span><span class="t">    <span class="com">#</span>&nbsp;</span><span class="r"></span></p>
    <p id="t216" class="pln"><span class="n"><a href="#t216">216</a></span><span class="t">    <span class="com"># 1. When we serialize a CUDA tensor for IPC, we cannot do it all in one</span>&nbsp;</span><span class="r"></span></p>
    <p id="t217" class="pln"><span class="n"><a href="#t217">217</a></span><span class="t">    <span class="com">#    go (non-compositionally), and this requires to have a global map</span>&nbsp;</span><span class="r"></span></p>
    <p id="t218" class="pln"><span class="n"><a href="#t218">218</a></span><span class="t">    <span class="com">#    memHandle -> devPtr for each process.</span>&nbsp;</span><span class="r"></span></p>
    <p id="t219" class="pln"><span class="n"><a href="#t219">219</a></span><span class="t">    <span class="com">#</span>&nbsp;</span><span class="r"></span></p>
    <p id="t220" class="pln"><span class="n"><a href="#t220">220</a></span><span class="t">    <span class="com"># 2. We MUST NOT let the new IPC tensor be resizable.  Originally, a resize</span>&nbsp;</span><span class="r"></span></p>
    <p id="t221" class="pln"><span class="n"><a href="#t221">221</a></span><span class="t">    <span class="com">#    of the storage beyond 0x100 would merely have caused us to do a</span>&nbsp;</span><span class="r"></span></p>
    <p id="t222" class="pln"><span class="n"><a href="#t222">222</a></span><span class="t">    <span class="com">#    reallocation.  You don't really want to do this, but if you did,</span>&nbsp;</span><span class="r"></span></p>
    <p id="t223" class="pln"><span class="n"><a href="#t223">223</a></span><span class="t">    <span class="com">#    all that would happen is that you would lose IPC sharing.  But if</span>&nbsp;</span><span class="r"></span></p>
    <p id="t224" class="pln"><span class="n"><a href="#t224">224</a></span><span class="t">    <span class="com">#    you do this in the new world, we will happily let you write out of</span>&nbsp;</span><span class="r"></span></p>
    <p id="t225" class="pln"><span class="n"><a href="#t225">225</a></span><span class="t">    <span class="com">#    bounds of your "allocation", clobbering unrelated data in the cached</span>&nbsp;</span><span class="r"></span></p>
    <p id="t226" class="pln"><span class="n"><a href="#t226">226</a></span><span class="t">    <span class="com">#    allocator block.  BAD!</span>&nbsp;</span><span class="r"></span></p>
    <p id="t227" class="pln"><span class="n"><a href="#t227">227</a></span><span class="t">    <span class="com">#</span>&nbsp;</span><span class="r"></span></p>
    <p id="t228" class="pln"><span class="n"><a href="#t228">228</a></span><span class="t">    <span class="com"># By the way, in old versions of PyTorch, we supported this situation</span>&nbsp;</span><span class="r"></span></p>
    <p id="t229" class="pln"><span class="n"><a href="#t229">229</a></span><span class="t">    <span class="com"># natively using a "storage view", which permitted multiple storages to be</span>&nbsp;</span><span class="r"></span></p>
    <p id="t230" class="pln"><span class="n"><a href="#t230">230</a></span><span class="t">    <span class="com"># views on each other.  But this was the *only* use of storage views, so we</span>&nbsp;</span><span class="r"></span></p>
    <p id="t231" class="pln"><span class="n"><a href="#t231">231</a></span><span class="t">    <span class="com"># eliminated it so that we could just use tensor views to implement the same</span>&nbsp;</span><span class="r"></span></p>
    <p id="t232" class="pln"><span class="n"><a href="#t232">232</a></span><span class="t">    <span class="com"># thing.</span>&nbsp;</span><span class="r"></span></p>
    <p id="t233" class="pln"><span class="n"><a href="#t233">233</a></span><span class="t">    <span class="com">#</span>&nbsp;</span><span class="r"></span></p>
    <p id="t234" class="mis show_mis"><span class="n"><a href="#t234">234</a></span><span class="t">    <span class="key">if</span> <span class="nam">storage</span><span class="op">.</span><span class="nam">is_cuda</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t235" class="mis show_mis"><span class="n"><a href="#t235">235</a></span><span class="t">        <span class="op">(</span><span class="nam">device</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p id="t236" class="pln"><span class="n"><a href="#t236">236</a></span><span class="t">         <span class="nam">handle</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p id="t237" class="pln"><span class="n"><a href="#t237">237</a></span><span class="t">         <span class="nam">storage_size_bytes</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p id="t238" class="pln"><span class="n"><a href="#t238">238</a></span><span class="t">         <span class="nam">storage_offset_bytes</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p id="t239" class="pln"><span class="n"><a href="#t239">239</a></span><span class="t">         <span class="nam">ref_counter_handle</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p id="t240" class="pln"><span class="n"><a href="#t240">240</a></span><span class="t">         <span class="nam">ref_counter_offset</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p id="t241" class="pln"><span class="n"><a href="#t241">241</a></span><span class="t">         <span class="nam">event_handle</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p id="t242" class="pln"><span class="n"><a href="#t242">242</a></span><span class="t">         <span class="nam">event_sync_required</span><span class="op">)</span> <span class="op">=</span> <span class="nam">storage</span><span class="op">.</span><span class="nam">_share_cuda_</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t243" class="mis show_mis"><span class="n"><a href="#t243">243</a></span><span class="t">        <span class="nam">tensor_offset</span> <span class="op">=</span> <span class="nam">tensor</span><span class="op">.</span><span class="nam">storage_offset</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t244" class="mis show_mis"><span class="n"><a href="#t244">244</a></span><span class="t">        <span class="nam">shared_cache</span><span class="op">[</span><span class="nam">handle</span><span class="op">]</span> <span class="op">=</span> <span class="nam">StorageWeakRef</span><span class="op">(</span><span class="nam">storage</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t245" class="pln"><span class="n"><a href="#t245">245</a></span><span class="t">        <span class="com"># _backward_hooks purposely omitted here, see</span>&nbsp;</span><span class="r"></span></p>
    <p id="t246" class="pln"><span class="n"><a href="#t246">246</a></span><span class="t">        <span class="com"># Note [Don't serialize hooks]</span>&nbsp;</span><span class="r"></span></p>
    <p id="t247" class="mis show_mis"><span class="n"><a href="#t247">247</a></span><span class="t">        <span class="key">return</span> <span class="op">(</span><span class="nam">rebuild_cuda_tensor</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p id="t248" class="pln"><span class="n"><a href="#t248">248</a></span><span class="t">                <span class="op">(</span><span class="nam">type</span><span class="op">(</span><span class="nam">tensor</span><span class="op">)</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p id="t249" class="pln"><span class="n"><a href="#t249">249</a></span><span class="t">                 <span class="nam">tensor</span><span class="op">.</span><span class="nam">size</span><span class="op">(</span><span class="op">)</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p id="t250" class="pln"><span class="n"><a href="#t250">250</a></span><span class="t">                 <span class="nam">tensor</span><span class="op">.</span><span class="nam">stride</span><span class="op">(</span><span class="op">)</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p id="t251" class="pln"><span class="n"><a href="#t251">251</a></span><span class="t">                 <span class="nam">tensor_offset</span><span class="op">,</span>  <span class="com"># tensor offset in its storage</span>&nbsp;</span><span class="r"></span></p>
    <p id="t252" class="pln"><span class="n"><a href="#t252">252</a></span><span class="t">                 <span class="nam">type</span><span class="op">(</span><span class="nam">storage</span><span class="op">)</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p id="t253" class="pln"><span class="n"><a href="#t253">253</a></span><span class="t">                 <span class="nam">device</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p id="t254" class="pln"><span class="n"><a href="#t254">254</a></span><span class="t">                 <span class="nam">handle</span><span class="op">,</span>  <span class="com"># identifier which CUDA allocation is the storage in.</span>&nbsp;</span><span class="r"></span></p>
    <p id="t255" class="pln"><span class="n"><a href="#t255">255</a></span><span class="t">                 <span class="nam">storage_size_bytes</span><span class="op">,</span>  <span class="com"># size(in bytes) of the storage</span>&nbsp;</span><span class="r"></span></p>
    <p id="t256" class="pln"><span class="n"><a href="#t256">256</a></span><span class="t">                 <span class="nam">storage_offset_bytes</span><span class="op">,</span>  <span class="com"># offset(in bytes) of the storage in the CUDA allocation</span>&nbsp;</span><span class="r"></span></p>
    <p id="t257" class="pln"><span class="n"><a href="#t257">257</a></span><span class="t">                 <span class="nam">tensor</span><span class="op">.</span><span class="nam">requires_grad</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p id="t258" class="pln"><span class="n"><a href="#t258">258</a></span><span class="t">                 <span class="nam">ref_counter_handle</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p id="t259" class="pln"><span class="n"><a href="#t259">259</a></span><span class="t">                 <span class="nam">ref_counter_offset</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p id="t260" class="pln"><span class="n"><a href="#t260">260</a></span><span class="t">                 <span class="nam">event_handle</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p id="t261" class="pln"><span class="n"><a href="#t261">261</a></span><span class="t">                 <span class="nam">event_sync_required</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t262" class="pln"><span class="n"><a href="#t262">262</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t263" class="pln"><span class="n"><a href="#t263">263</a></span><span class="t">    <span class="com"># _backward_hooks purposely omitted here, see Note [Don't serialize hooks]</span>&nbsp;</span><span class="r"></span></p>
    <p id="t264" class="mis show_mis"><span class="n"><a href="#t264">264</a></span><span class="t">    <span class="nam">metadata</span> <span class="op">=</span> <span class="op">(</span><span class="nam">tensor</span><span class="op">.</span><span class="nam">storage_offset</span><span class="op">(</span><span class="op">)</span><span class="op">,</span> <span class="nam">tensor</span><span class="op">.</span><span class="nam">size</span><span class="op">(</span><span class="op">)</span><span class="op">,</span> <span class="nam">tensor</span><span class="op">.</span><span class="nam">stride</span><span class="op">(</span><span class="op">)</span><span class="op">,</span> <span class="nam">tensor</span><span class="op">.</span><span class="nam">requires_grad</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t265" class="mis show_mis"><span class="n"><a href="#t265">265</a></span><span class="t">    <span class="key">return</span> <span class="op">(</span><span class="nam">rebuild_tensor</span><span class="op">,</span> <span class="op">(</span><span class="nam">type</span><span class="op">(</span><span class="nam">tensor</span><span class="op">)</span><span class="op">,</span> <span class="nam">storage</span><span class="op">,</span> <span class="nam">metadata</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t266" class="pln"><span class="n"><a href="#t266">266</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t267" class="pln"><span class="n"><a href="#t267">267</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t268" class="run"><span class="n"><a href="#t268">268</a></span><span class="t"><span class="key">def</span> <span class="nam">fd_id</span><span class="op">(</span><span class="nam">fd</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t269" class="pln"><span class="n"><a href="#t269">269</a></span><span class="t">    <span class="com"># Returns a tuple which uniquely identifies a file descriptor. In Mac OS,</span>&nbsp;</span><span class="r"></span></p>
    <p id="t270" class="pln"><span class="n"><a href="#t270">270</a></span><span class="t">    <span class="com"># this doesn't work with shared memory handles, which is why we don't</span>&nbsp;</span><span class="r"></span></p>
    <p id="t271" class="pln"><span class="n"><a href="#t271">271</a></span><span class="t">    <span class="com"># support the "file_descriptor" sharing method on that platform.</span>&nbsp;</span><span class="r"></span></p>
    <p id="t272" class="mis show_mis"><span class="n"><a href="#t272">272</a></span><span class="t">    <span class="nam">stat</span> <span class="op">=</span> <span class="nam">os</span><span class="op">.</span><span class="nam">fstat</span><span class="op">(</span><span class="nam">fd</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t273" class="mis show_mis"><span class="n"><a href="#t273">273</a></span><span class="t">    <span class="key">return</span> <span class="op">(</span><span class="nam">stat</span><span class="op">.</span><span class="nam">st_ino</span><span class="op">,</span> <span class="nam">stat</span><span class="op">.</span><span class="nam">st_dev</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t274" class="pln"><span class="n"><a href="#t274">274</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t275" class="pln"><span class="n"><a href="#t275">275</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t276" class="run"><span class="n"><a href="#t276">276</a></span><span class="t"><span class="key">def</span> <span class="nam">storage_from_cache</span><span class="op">(</span><span class="nam">cls</span><span class="op">,</span> <span class="nam">key</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t277" class="mis show_mis"><span class="n"><a href="#t277">277</a></span><span class="t">    <span class="nam">storage_ref</span> <span class="op">=</span> <span class="nam">shared_cache</span><span class="op">.</span><span class="nam">get</span><span class="op">(</span><span class="nam">key</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t278" class="mis show_mis"><span class="n"><a href="#t278">278</a></span><span class="t">    <span class="key">if</span> <span class="nam">storage_ref</span> <span class="key">is</span> <span class="key">None</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t279" class="mis show_mis"><span class="n"><a href="#t279">279</a></span><span class="t">        <span class="key">return</span> <span class="key">None</span>&nbsp;</span><span class="r"></span></p>
    <p id="t280" class="mis show_mis"><span class="n"><a href="#t280">280</a></span><span class="t">    <span class="key">return</span> <span class="nam">cls</span><span class="op">.</span><span class="nam">_new_with_weak_ptr</span><span class="op">(</span><span class="nam">storage_ref</span><span class="op">.</span><span class="nam">cdata</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t281" class="pln"><span class="n"><a href="#t281">281</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t282" class="pln"><span class="n"><a href="#t282">282</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t283" class="run"><span class="n"><a href="#t283">283</a></span><span class="t"><span class="key">def</span> <span class="nam">rebuild_storage_fd</span><span class="op">(</span><span class="nam">cls</span><span class="op">,</span> <span class="nam">df</span><span class="op">,</span> <span class="nam">size</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t284" class="mis show_mis"><span class="n"><a href="#t284">284</a></span><span class="t">    <span class="key">if</span> <span class="nam">sys</span><span class="op">.</span><span class="nam">version_info</span><span class="op">[</span><span class="num">0</span><span class="op">]</span> <span class="op">==</span> <span class="num">2</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t285" class="mis show_mis"><span class="n"><a href="#t285">285</a></span><span class="t">        <span class="key">while</span> <span class="key">True</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t286" class="mis show_mis"><span class="n"><a href="#t286">286</a></span><span class="t">            <span class="key">try</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t287" class="mis show_mis"><span class="n"><a href="#t287">287</a></span><span class="t">                <span class="nam">fd</span> <span class="op">=</span> <span class="nam">multiprocessing</span><span class="op">.</span><span class="nam">reduction</span><span class="op">.</span><span class="nam">rebuild_handle</span><span class="op">(</span><span class="nam">df</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t288" class="mis show_mis"><span class="n"><a href="#t288">288</a></span><span class="t">                <span class="key">break</span>&nbsp;</span><span class="r"></span></p>
    <p id="t289" class="mis show_mis"><span class="n"><a href="#t289">289</a></span><span class="t">            <span class="key">except</span> <span class="nam">OSError</span> <span class="key">as</span> <span class="nam">e</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t290" class="pln"><span class="n"><a href="#t290">290</a></span><span class="t">                <span class="com"># Retry on EINTR for platforms that support it</span>&nbsp;</span><span class="r"></span></p>
    <p id="t291" class="mis show_mis"><span class="n"><a href="#t291">291</a></span><span class="t">                <span class="key">if</span> <span class="nam">e</span><span class="op">.</span><span class="nam">errno</span> <span class="op">!=</span> <span class="nam">getattr</span><span class="op">(</span><span class="nam">errno</span><span class="op">,</span> <span class="str">'EINTR'</span><span class="op">,</span> <span class="key">None</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t292" class="mis show_mis"><span class="n"><a href="#t292">292</a></span><span class="t">                    <span class="key">raise</span>&nbsp;</span><span class="r"></span></p>
    <p id="t293" class="pln"><span class="n"><a href="#t293">293</a></span><span class="t">    <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t294" class="mis show_mis"><span class="n"><a href="#t294">294</a></span><span class="t">        <span class="nam">fd</span> <span class="op">=</span> <span class="nam">df</span><span class="op">.</span><span class="nam">detach</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t295" class="mis show_mis"><span class="n"><a href="#t295">295</a></span><span class="t">    <span class="key">try</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t296" class="mis show_mis"><span class="n"><a href="#t296">296</a></span><span class="t">        <span class="nam">storage</span> <span class="op">=</span> <span class="nam">storage_from_cache</span><span class="op">(</span><span class="nam">cls</span><span class="op">,</span> <span class="nam">fd_id</span><span class="op">(</span><span class="nam">fd</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t297" class="mis show_mis"><span class="n"><a href="#t297">297</a></span><span class="t">        <span class="key">if</span> <span class="nam">storage</span> <span class="key">is</span> <span class="key">not</span> <span class="key">None</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t298" class="mis show_mis"><span class="n"><a href="#t298">298</a></span><span class="t">            <span class="key">return</span> <span class="nam">storage</span>&nbsp;</span><span class="r"></span></p>
    <p id="t299" class="mis show_mis"><span class="n"><a href="#t299">299</a></span><span class="t">        <span class="nam">storage</span> <span class="op">=</span> <span class="nam">cls</span><span class="op">.</span><span class="nam">_new_shared_fd</span><span class="op">(</span><span class="nam">fd</span><span class="op">,</span> <span class="nam">size</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t300" class="mis show_mis"><span class="n"><a href="#t300">300</a></span><span class="t">        <span class="nam">shared_cache</span><span class="op">[</span><span class="nam">fd_id</span><span class="op">(</span><span class="nam">fd</span><span class="op">)</span><span class="op">]</span> <span class="op">=</span> <span class="nam">StorageWeakRef</span><span class="op">(</span><span class="nam">storage</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t301" class="mis show_mis"><span class="n"><a href="#t301">301</a></span><span class="t">        <span class="key">return</span> <span class="nam">storage</span>&nbsp;</span><span class="r"></span></p>
    <p id="t302" class="pln"><span class="n"><a href="#t302">302</a></span><span class="t">    <span class="key">finally</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t303" class="mis show_mis"><span class="n"><a href="#t303">303</a></span><span class="t">        <span class="nam">os</span><span class="op">.</span><span class="nam">close</span><span class="op">(</span><span class="nam">fd</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t304" class="pln"><span class="n"><a href="#t304">304</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t305" class="pln"><span class="n"><a href="#t305">305</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t306" class="run"><span class="n"><a href="#t306">306</a></span><span class="t"><span class="key">def</span> <span class="nam">rebuild_storage_filename</span><span class="op">(</span><span class="nam">cls</span><span class="op">,</span> <span class="nam">manager</span><span class="op">,</span> <span class="nam">handle</span><span class="op">,</span> <span class="nam">size</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t307" class="mis show_mis"><span class="n"><a href="#t307">307</a></span><span class="t">    <span class="nam">storage</span> <span class="op">=</span> <span class="nam">storage_from_cache</span><span class="op">(</span><span class="nam">cls</span><span class="op">,</span> <span class="nam">handle</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t308" class="mis show_mis"><span class="n"><a href="#t308">308</a></span><span class="t">    <span class="key">if</span> <span class="nam">storage</span> <span class="key">is</span> <span class="key">not</span> <span class="key">None</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t309" class="mis show_mis"><span class="n"><a href="#t309">309</a></span><span class="t">        <span class="key">return</span> <span class="nam">storage</span><span class="op">.</span><span class="nam">_shared_decref</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t310" class="mis show_mis"><span class="n"><a href="#t310">310</a></span><span class="t">    <span class="nam">storage</span> <span class="op">=</span> <span class="nam">cls</span><span class="op">.</span><span class="nam">_new_shared_filename</span><span class="op">(</span><span class="nam">manager</span><span class="op">,</span> <span class="nam">handle</span><span class="op">,</span> <span class="nam">size</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t311" class="mis show_mis"><span class="n"><a href="#t311">311</a></span><span class="t">    <span class="nam">shared_cache</span><span class="op">[</span><span class="nam">handle</span><span class="op">]</span> <span class="op">=</span> <span class="nam">StorageWeakRef</span><span class="op">(</span><span class="nam">storage</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t312" class="mis show_mis"><span class="n"><a href="#t312">312</a></span><span class="t">    <span class="key">return</span> <span class="nam">storage</span><span class="op">.</span><span class="nam">_shared_decref</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t313" class="pln"><span class="n"><a href="#t313">313</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t314" class="pln"><span class="n"><a href="#t314">314</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t315" class="run"><span class="n"><a href="#t315">315</a></span><span class="t"><span class="key">def</span> <span class="nam">rebuild_storage_empty</span><span class="op">(</span><span class="nam">cls</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t316" class="mis show_mis"><span class="n"><a href="#t316">316</a></span><span class="t">    <span class="key">return</span> <span class="nam">cls</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t317" class="pln"><span class="n"><a href="#t317">317</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t318" class="pln"><span class="n"><a href="#t318">318</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t319" class="run"><span class="n"><a href="#t319">319</a></span><span class="t"><span class="key">def</span> <span class="nam">reduce_storage</span><span class="op">(</span><span class="nam">storage</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t320" class="mis show_mis"><span class="n"><a href="#t320">320</a></span><span class="t">    <span class="key">from</span> <span class="op">.</span> <span class="key">import</span> <span class="nam">get_sharing_strategy</span>&nbsp;</span><span class="r"></span></p>
    <p id="t321" class="mis show_mis"><span class="n"><a href="#t321">321</a></span><span class="t">    <span class="key">if</span> <span class="nam">storage</span><span class="op">.</span><span class="nam">is_cuda</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t322" class="mis show_mis"><span class="n"><a href="#t322">322</a></span><span class="t">        <span class="key">raise</span> <span class="nam">RuntimeError</span><span class="op">(</span><span class="str">"Cannot pickle CUDA storage; try pickling a CUDA tensor instead"</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t323" class="mis show_mis"><span class="n"><a href="#t323">323</a></span><span class="t">    <span class="key">elif</span> <span class="nam">get_sharing_strategy</span><span class="op">(</span><span class="op">)</span> <span class="op">==</span> <span class="str">'file_system'</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t324" class="mis show_mis"><span class="n"><a href="#t324">324</a></span><span class="t">        <span class="nam">metadata</span> <span class="op">=</span> <span class="nam">storage</span><span class="op">.</span><span class="nam">_share_filename_</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t325" class="mis show_mis"><span class="n"><a href="#t325">325</a></span><span class="t">        <span class="nam">cache_key</span> <span class="op">=</span> <span class="nam">metadata</span><span class="op">[</span><span class="num">1</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p id="t326" class="mis show_mis"><span class="n"><a href="#t326">326</a></span><span class="t">        <span class="nam">rebuild</span> <span class="op">=</span> <span class="nam">rebuild_storage_filename</span>&nbsp;</span><span class="r"></span></p>
    <p id="t327" class="mis show_mis"><span class="n"><a href="#t327">327</a></span><span class="t">        <span class="nam">storage</span><span class="op">.</span><span class="nam">_shared_incref</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t328" class="mis show_mis"><span class="n"><a href="#t328">328</a></span><span class="t">    <span class="key">elif</span> <span class="nam">storage</span><span class="op">.</span><span class="nam">size</span><span class="op">(</span><span class="op">)</span> <span class="op">==</span> <span class="num">0</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t329" class="pln"><span class="n"><a href="#t329">329</a></span><span class="t">        <span class="com"># This is special cased because Empty tensors</span>&nbsp;</span><span class="r"></span></p>
    <p id="t330" class="pln"><span class="n"><a href="#t330">330</a></span><span class="t">        <span class="com"># (with size 0) cannot be mmapped.</span>&nbsp;</span><span class="r"></span></p>
    <p id="t331" class="mis show_mis"><span class="n"><a href="#t331">331</a></span><span class="t">        <span class="key">return</span> <span class="op">(</span><span class="nam">rebuild_storage_empty</span><span class="op">,</span> <span class="op">(</span><span class="nam">type</span><span class="op">(</span><span class="nam">storage</span><span class="op">)</span><span class="op">,</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t332" class="pln"><span class="n"><a href="#t332">332</a></span><span class="t">    <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t333" class="mis show_mis"><span class="n"><a href="#t333">333</a></span><span class="t">        <span class="nam">fd</span><span class="op">,</span> <span class="nam">size</span> <span class="op">=</span> <span class="nam">storage</span><span class="op">.</span><span class="nam">_share_fd_</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t334" class="mis show_mis"><span class="n"><a href="#t334">334</a></span><span class="t">        <span class="key">if</span> <span class="nam">sys</span><span class="op">.</span><span class="nam">version_info</span><span class="op">[</span><span class="num">0</span><span class="op">]</span> <span class="op">==</span> <span class="num">2</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t335" class="mis show_mis"><span class="n"><a href="#t335">335</a></span><span class="t">            <span class="nam">df</span> <span class="op">=</span> <span class="nam">multiprocessing</span><span class="op">.</span><span class="nam">reduction</span><span class="op">.</span><span class="nam">reduce_handle</span><span class="op">(</span><span class="nam">fd</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t336" class="pln"><span class="n"><a href="#t336">336</a></span><span class="t">        <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t337" class="mis show_mis"><span class="n"><a href="#t337">337</a></span><span class="t">            <span class="nam">df</span> <span class="op">=</span> <span class="nam">multiprocessing</span><span class="op">.</span><span class="nam">reduction</span><span class="op">.</span><span class="nam">DupFd</span><span class="op">(</span><span class="nam">fd</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t338" class="mis show_mis"><span class="n"><a href="#t338">338</a></span><span class="t">        <span class="nam">cache_key</span> <span class="op">=</span> <span class="nam">fd_id</span><span class="op">(</span><span class="nam">fd</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t339" class="mis show_mis"><span class="n"><a href="#t339">339</a></span><span class="t">        <span class="nam">metadata</span> <span class="op">=</span> <span class="op">(</span><span class="nam">df</span><span class="op">,</span> <span class="nam">size</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t340" class="mis show_mis"><span class="n"><a href="#t340">340</a></span><span class="t">        <span class="nam">rebuild</span> <span class="op">=</span> <span class="nam">rebuild_storage_fd</span>&nbsp;</span><span class="r"></span></p>
    <p id="t341" class="pln"><span class="n"><a href="#t341">341</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t342" class="mis show_mis"><span class="n"><a href="#t342">342</a></span><span class="t">    <span class="nam">shared_cache</span><span class="op">[</span><span class="nam">cache_key</span><span class="op">]</span> <span class="op">=</span> <span class="nam">StorageWeakRef</span><span class="op">(</span><span class="nam">storage</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t343" class="mis show_mis"><span class="n"><a href="#t343">343</a></span><span class="t">    <span class="key">return</span> <span class="op">(</span><span class="nam">rebuild</span><span class="op">,</span> <span class="op">(</span><span class="nam">type</span><span class="op">(</span><span class="nam">storage</span><span class="op">)</span><span class="op">,</span><span class="op">)</span> <span class="op">+</span> <span class="nam">metadata</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t344" class="pln"><span class="n"><a href="#t344">344</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t345" class="pln"><span class="n"><a href="#t345">345</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t346" class="run"><span class="n"><a href="#t346">346</a></span><span class="t"><span class="key">def</span> <span class="nam">init_reductions</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t347" class="run"><span class="n"><a href="#t347">347</a></span><span class="t">    <span class="nam">ForkingPickler</span><span class="op">.</span><span class="nam">register</span><span class="op">(</span><span class="nam">torch</span><span class="op">.</span><span class="nam">cuda</span><span class="op">.</span><span class="nam">Event</span><span class="op">,</span> <span class="nam">reduce_event</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t348" class="pln"><span class="n"><a href="#t348">348</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t349" class="run"><span class="n"><a href="#t349">349</a></span><span class="t">    <span class="key">for</span> <span class="nam">t</span> <span class="key">in</span> <span class="nam">torch</span><span class="op">.</span><span class="nam">_storage_classes</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t350" class="run"><span class="n"><a href="#t350">350</a></span><span class="t">        <span class="nam">ForkingPickler</span><span class="op">.</span><span class="nam">register</span><span class="op">(</span><span class="nam">t</span><span class="op">,</span> <span class="nam">reduce_storage</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t351" class="pln"><span class="n"><a href="#t351">351</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t352" class="run"><span class="n"><a href="#t352">352</a></span><span class="t">    <span class="key">for</span> <span class="nam">t</span> <span class="key">in</span> <span class="nam">torch</span><span class="op">.</span><span class="nam">_tensor_classes</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t353" class="run"><span class="n"><a href="#t353">353</a></span><span class="t">        <span class="nam">ForkingPickler</span><span class="op">.</span><span class="nam">register</span><span class="op">(</span><span class="nam">t</span><span class="op">,</span> <span class="nam">reduce_tensor</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t354" class="pln"><span class="n"><a href="#t354">354</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t355" class="pln"><span class="n"><a href="#t355">355</a></span><span class="t">    <span class="com"># TODO: Maybe this should be in tensor_classes? :)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t356" class="run"><span class="n"><a href="#t356">356</a></span><span class="t">    <span class="nam">ForkingPickler</span><span class="op">.</span><span class="nam">register</span><span class="op">(</span><span class="nam">torch</span><span class="op">.</span><span class="nam">Tensor</span><span class="op">,</span> <span class="nam">reduce_tensor</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t357" class="run"><span class="n"><a href="#t357">357</a></span><span class="t">    <span class="nam">ForkingPickler</span><span class="op">.</span><span class="nam">register</span><span class="op">(</span><span class="nam">torch</span><span class="op">.</span><span class="nam">nn</span><span class="op">.</span><span class="nam">parameter</span><span class="op">.</span><span class="nam">Parameter</span><span class="op">,</span> <span class="nam">reduce_tensor</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
</div>
<div id="footer">
    <div class="content">
        <p>
            <a class="nav" href="index.html">&#xab; index</a> &nbsp; &nbsp; <a class="nav" href="https://coverage.readthedocs.io">coverage.py v5.0.3</a>,
            created at 2020-03-12 22:47
        </p>
    </div>
</div>
</body>
</html>
