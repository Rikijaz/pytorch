<!DOCTYPE html>
<html>
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=emulateIE7" />
    <title>Coverage for C:\Users\paper\Anaconda3\Lib\site-packages\torch\cuda\__init__.py: 46%</title>
    <link rel="stylesheet" href="style.css" type="text/css">
    <script type="text/javascript" src="jquery.min.js"></script>
    <script type="text/javascript" src="jquery.hotkeys.js"></script>
    <script type="text/javascript" src="jquery.isonscreen.js"></script>
    <script type="text/javascript" src="coverage_html.js"></script>
    <script type="text/javascript">
        jQuery(document).ready(coverage.pyfile_ready);
    </script>
</head>
<body class="pyfile">
<div id="header">
    <div class="content">
        <h1>Coverage for <b>C:\Users\paper\Anaconda3\Lib\site-packages\torch\cuda\__init__.py</b> :
            <span class="pc_cov">46%</span>
        </h1>
        <img id="keyboard_icon" src="keybd_closed.png" alt="Show keyboard shortcuts" />
        <h2 class="stats">
            249 statements &nbsp;
            <span class="run shortkey_r button_toggle_run">114 run</span>
            <span class="mis show_mis shortkey_m button_toggle_mis">135 missing</span>
            <span class="exc show_exc shortkey_x button_toggle_exc">0 excluded</span>
        </h2>
    </div>
</div>
<div class="help_panel">
    <img id="panel_icon" src="keybd_open.png" alt="Hide keyboard shortcuts" />
    <p class="legend">Hot-keys on this page</p>
    <div>
    <p class="keyhelp">
        <span class="key">r</span>
        <span class="key">m</span>
        <span class="key">x</span>
        <span class="key">p</span> &nbsp; toggle line displays
    </p>
    <p class="keyhelp">
        <span class="key">j</span>
        <span class="key">k</span> &nbsp; next/prev highlighted chunk
    </p>
    <p class="keyhelp">
        <span class="key">0</span> &nbsp; (zero) top of page
    </p>
    <p class="keyhelp">
        <span class="key">1</span> &nbsp; (one) first highlighted chunk
    </p>
    </div>
</div>
<div id="source">
    <p id="t1" class="pln"><span class="n"><a href="#t1">1</a></span><span class="t"><span class="str">r"""</span>&nbsp;</span><span class="r"></span></p>
    <p id="t2" class="pln"><span class="n"><a href="#t2">2</a></span><span class="t"><span class="str">This package adds support for CUDA tensor types, that implement the same</span>&nbsp;</span><span class="r"></span></p>
    <p id="t3" class="pln"><span class="n"><a href="#t3">3</a></span><span class="t"><span class="str">function as CPU tensors, but they utilize GPUs for computation.</span>&nbsp;</span><span class="r"></span></p>
    <p id="t4" class="pln"><span class="n"><a href="#t4">4</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t5" class="pln"><span class="n"><a href="#t5">5</a></span><span class="t"><span class="str">It is lazily initialized, so you can always import it, and use</span>&nbsp;</span><span class="r"></span></p>
    <p id="t6" class="pln"><span class="n"><a href="#t6">6</a></span><span class="t"><span class="str">:func:`is_available()` to determine if your system supports CUDA.</span>&nbsp;</span><span class="r"></span></p>
    <p id="t7" class="pln"><span class="n"><a href="#t7">7</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t8" class="pln"><span class="n"><a href="#t8">8</a></span><span class="t"><span class="str">:ref:`cuda-semantics` has more details about working with CUDA.</span>&nbsp;</span><span class="r"></span></p>
    <p id="t9" class="pln"><span class="n"><a href="#t9">9</a></span><span class="t"><span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p id="t10" class="pln"><span class="n"><a href="#t10">10</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t11" class="run"><span class="n"><a href="#t11">11</a></span><span class="t"><span class="key">import</span> <span class="nam">contextlib</span>&nbsp;</span><span class="r"></span></p>
    <p id="t12" class="run"><span class="n"><a href="#t12">12</a></span><span class="t"><span class="key">import</span> <span class="nam">platform</span>&nbsp;</span><span class="r"></span></p>
    <p id="t13" class="run"><span class="n"><a href="#t13">13</a></span><span class="t"><span class="key">import</span> <span class="nam">ctypes</span>&nbsp;</span><span class="r"></span></p>
    <p id="t14" class="run"><span class="n"><a href="#t14">14</a></span><span class="t"><span class="key">import</span> <span class="nam">os</span>&nbsp;</span><span class="r"></span></p>
    <p id="t15" class="run"><span class="n"><a href="#t15">15</a></span><span class="t"><span class="key">import</span> <span class="nam">sys</span>&nbsp;</span><span class="r"></span></p>
    <p id="t16" class="run"><span class="n"><a href="#t16">16</a></span><span class="t"><span class="key">import</span> <span class="nam">torch</span>&nbsp;</span><span class="r"></span></p>
    <p id="t17" class="run"><span class="n"><a href="#t17">17</a></span><span class="t"><span class="key">import</span> <span class="nam">traceback</span>&nbsp;</span><span class="r"></span></p>
    <p id="t18" class="run"><span class="n"><a href="#t18">18</a></span><span class="t"><span class="key">import</span> <span class="nam">warnings</span>&nbsp;</span><span class="r"></span></p>
    <p id="t19" class="run"><span class="n"><a href="#t19">19</a></span><span class="t"><span class="key">import</span> <span class="nam">threading</span>&nbsp;</span><span class="r"></span></p>
    <p id="t20" class="run"><span class="n"><a href="#t20">20</a></span><span class="t"><span class="key">from</span> <span class="nam">torch</span><span class="op">.</span><span class="nam">_six</span> <span class="key">import</span> <span class="nam">raise_from</span>&nbsp;</span><span class="r"></span></p>
    <p id="t21" class="run"><span class="n"><a href="#t21">21</a></span><span class="t"><span class="key">from</span> <span class="nam">subprocess</span> <span class="key">import</span> <span class="nam">Popen</span><span class="op">,</span> <span class="nam">PIPE</span>&nbsp;</span><span class="r"></span></p>
    <p id="t22" class="run"><span class="n"><a href="#t22">22</a></span><span class="t"><span class="key">from</span> <span class="op">.</span><span class="nam">_utils</span> <span class="key">import</span> <span class="nam">_get_device_index</span>&nbsp;</span><span class="r"></span></p>
    <p id="t23" class="run"><span class="n"><a href="#t23">23</a></span><span class="t"><span class="key">import</span> <span class="nam">torch</span><span class="op">.</span><span class="nam">_C</span>&nbsp;</span><span class="r"></span></p>
    <p id="t24" class="pln"><span class="n"><a href="#t24">24</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t25" class="run"><span class="n"><a href="#t25">25</a></span><span class="t"><span class="nam">_initialized</span> <span class="op">=</span> <span class="key">False</span>&nbsp;</span><span class="r"></span></p>
    <p id="t26" class="run"><span class="n"><a href="#t26">26</a></span><span class="t"><span class="nam">_tls</span> <span class="op">=</span> <span class="nam">threading</span><span class="op">.</span><span class="nam">local</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t27" class="run"><span class="n"><a href="#t27">27</a></span><span class="t"><span class="nam">_initialization_lock</span> <span class="op">=</span> <span class="nam">threading</span><span class="op">.</span><span class="nam">Lock</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t28" class="run"><span class="n"><a href="#t28">28</a></span><span class="t"><span class="nam">_queued_calls</span> <span class="op">=</span> <span class="op">[</span><span class="op">]</span>  <span class="com"># don't invoke these until initialization occurs</span>&nbsp;</span><span class="r"></span></p>
    <p id="t29" class="run"><span class="n"><a href="#t29">29</a></span><span class="t"><span class="nam">_is_in_bad_fork</span> <span class="op">=</span> <span class="nam">getattr</span><span class="op">(</span><span class="nam">torch</span><span class="op">.</span><span class="nam">_C</span><span class="op">,</span> <span class="str">"_cuda_isInBadFork"</span><span class="op">,</span> <span class="key">lambda</span><span class="op">:</span> <span class="key">False</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t30" class="run"><span class="n"><a href="#t30">30</a></span><span class="t"><span class="nam">_cudart</span> <span class="op">=</span> <span class="key">None</span>&nbsp;</span><span class="r"></span></p>
    <p id="t31" class="pln"><span class="n"><a href="#t31">31</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t32" class="pln"><span class="n"><a href="#t32">32</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t33" class="run"><span class="n"><a href="#t33">33</a></span><span class="t"><span class="key">def</span> <span class="nam">find_cuda_windows_lib</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t34" class="pln"><span class="n"><a href="#t34">34</a></span><span class="t">    <span class="com"># Override the default search process</span>&nbsp;</span><span class="r"></span></p>
    <p id="t35" class="pln"><span class="n"><a href="#t35">35</a></span><span class="t">    <span class="com"># Fixes https://github.com/pytorch/pytorch/issues/20202</span>&nbsp;</span><span class="r"></span></p>
    <p id="t36" class="pln"><span class="n"><a href="#t36">36</a></span><span class="t">    <span class="com"># The library selection will be done in these directories one by one</span>&nbsp;</span><span class="r"></span></p>
    <p id="t37" class="pln"><span class="n"><a href="#t37">37</a></span><span class="t">    <span class="com"># 1. [Package Root]\Lib</span>&nbsp;</span><span class="r"></span></p>
    <p id="t38" class="pln"><span class="n"><a href="#t38">38</a></span><span class="t">    <span class="com">#    That's where our libraries are in, which should be loaded first.</span>&nbsp;</span><span class="r"></span></p>
    <p id="t39" class="pln"><span class="n"><a href="#t39">39</a></span><span class="t">    <span class="com"># 2. [Python Root]\Library\bin</span>&nbsp;</span><span class="r"></span></p>
    <p id="t40" class="pln"><span class="n"><a href="#t40">40</a></span><span class="t">    <span class="com">#    That's where `cudatoolkit` store the cuda libraries.</span>&nbsp;</span><span class="r"></span></p>
    <p id="t41" class="pln"><span class="n"><a href="#t41">41</a></span><span class="t">    <span class="com"># 3. Default directories</span>&nbsp;</span><span class="r"></span></p>
    <p id="t42" class="pln"><span class="n"><a href="#t42">42</a></span><span class="t">    <span class="com">#    That is stored in the environment variable `PATH`.</span>&nbsp;</span><span class="r"></span></p>
    <p id="t43" class="mis show_mis"><span class="n"><a href="#t43">43</a></span><span class="t">    <span class="nam">test_env</span> <span class="op">=</span> <span class="nam">os</span><span class="op">.</span><span class="nam">environ</span><span class="op">.</span><span class="nam">copy</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t44" class="mis show_mis"><span class="n"><a href="#t44">44</a></span><span class="t">    <span class="nam">old_path</span> <span class="op">=</span> <span class="nam">test_env</span><span class="op">[</span><span class="str">'PATH'</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p id="t45" class="mis show_mis"><span class="n"><a href="#t45">45</a></span><span class="t">    <span class="nam">py_dll_path</span> <span class="op">=</span> <span class="nam">os</span><span class="op">.</span><span class="nam">path</span><span class="op">.</span><span class="nam">join</span><span class="op">(</span><span class="nam">sys</span><span class="op">.</span><span class="nam">exec_prefix</span><span class="op">,</span> <span class="str">'Library'</span><span class="op">,</span> <span class="str">'bin'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t46" class="mis show_mis"><span class="n"><a href="#t46">46</a></span><span class="t">    <span class="nam">th_dll_path</span> <span class="op">=</span> <span class="nam">os</span><span class="op">.</span><span class="nam">path</span><span class="op">.</span><span class="nam">join</span><span class="op">(</span><span class="nam">os</span><span class="op">.</span><span class="nam">path</span><span class="op">.</span><span class="nam">dirname</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p id="t47" class="pln"><span class="n"><a href="#t47">47</a></span><span class="t">        <span class="nam">os</span><span class="op">.</span><span class="nam">path</span><span class="op">.</span><span class="nam">dirname</span><span class="op">(</span><span class="nam">__file__</span><span class="op">)</span><span class="op">)</span><span class="op">,</span> <span class="str">'lib'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t48" class="mis show_mis"><span class="n"><a href="#t48">48</a></span><span class="t">    <span class="nam">test_env</span><span class="op">[</span><span class="str">'PATH'</span><span class="op">]</span> <span class="op">=</span> <span class="str">';'</span><span class="op">.</span><span class="nam">join</span><span class="op">(</span><span class="op">[</span><span class="nam">th_dll_path</span><span class="op">,</span> <span class="nam">py_dll_path</span><span class="op">,</span> <span class="nam">old_path</span><span class="op">]</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t49" class="mis show_mis"><span class="n"><a href="#t49">49</a></span><span class="t">    <span class="nam">proc</span> <span class="op">=</span> <span class="nam">Popen</span><span class="op">(</span><span class="op">[</span><span class="str">'where'</span><span class="op">,</span> <span class="str">'cudart64*.dll'</span><span class="op">]</span><span class="op">,</span> <span class="nam">stdout</span><span class="op">=</span><span class="nam">PIPE</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p id="t50" class="pln"><span class="n"><a href="#t50">50</a></span><span class="t">                 <span class="nam">stderr</span><span class="op">=</span><span class="nam">PIPE</span><span class="op">,</span> <span class="nam">stdin</span><span class="op">=</span><span class="nam">PIPE</span><span class="op">,</span> <span class="nam">env</span><span class="op">=</span><span class="nam">test_env</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t51" class="mis show_mis"><span class="n"><a href="#t51">51</a></span><span class="t">    <span class="nam">out</span><span class="op">,</span> <span class="nam">err</span> <span class="op">=</span> <span class="nam">proc</span><span class="op">.</span><span class="nam">communicate</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t52" class="mis show_mis"><span class="n"><a href="#t52">52</a></span><span class="t">    <span class="nam">out</span> <span class="op">=</span> <span class="nam">out</span><span class="op">.</span><span class="nam">decode</span><span class="op">(</span><span class="op">)</span><span class="op">.</span><span class="nam">strip</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t53" class="mis show_mis"><span class="n"><a href="#t53">53</a></span><span class="t">    <span class="key">if</span> <span class="nam">len</span><span class="op">(</span><span class="nam">out</span><span class="op">)</span> <span class="op">></span> <span class="num">0</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t54" class="mis show_mis"><span class="n"><a href="#t54">54</a></span><span class="t">        <span class="key">if</span> <span class="nam">out</span><span class="op">.</span><span class="nam">find</span><span class="op">(</span><span class="str">'\r\n'</span><span class="op">)</span> <span class="op">!=</span> <span class="op">-</span><span class="num">1</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t55" class="mis show_mis"><span class="n"><a href="#t55">55</a></span><span class="t">            <span class="nam">out</span> <span class="op">=</span> <span class="nam">out</span><span class="op">.</span><span class="nam">split</span><span class="op">(</span><span class="str">'\r\n'</span><span class="op">)</span><span class="op">[</span><span class="num">0</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p id="t56" class="mis show_mis"><span class="n"><a href="#t56">56</a></span><span class="t">        <span class="nam">cuda_lib</span> <span class="op">=</span> <span class="nam">str</span><span class="op">(</span><span class="nam">out</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t57" class="mis show_mis"><span class="n"><a href="#t57">57</a></span><span class="t">        <span class="key">return</span> <span class="nam">ctypes</span><span class="op">.</span><span class="nam">cdll</span><span class="op">.</span><span class="nam">LoadLibrary</span><span class="op">(</span><span class="nam">cuda_lib</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t58" class="pln"><span class="n"><a href="#t58">58</a></span><span class="t">    <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t59" class="mis show_mis"><span class="n"><a href="#t59">59</a></span><span class="t">        <span class="key">return</span> <span class="key">None</span>&nbsp;</span><span class="r"></span></p>
    <p id="t60" class="pln"><span class="n"><a href="#t60">60</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t61" class="pln"><span class="n"><a href="#t61">61</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t62" class="run"><span class="n"><a href="#t62">62</a></span><span class="t"><span class="key">def</span> <span class="nam">is_available</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t63" class="pln"><span class="n"><a href="#t63">63</a></span><span class="t">    <span class="str">r"""Returns a bool indicating if CUDA is currently available."""</span>&nbsp;</span><span class="r"></span></p>
    <p id="t64" class="mis show_mis"><span class="n"><a href="#t64">64</a></span><span class="t">    <span class="key">if</span> <span class="op">(</span><span class="key">not</span> <span class="nam">hasattr</span><span class="op">(</span><span class="nam">torch</span><span class="op">.</span><span class="nam">_C</span><span class="op">,</span> <span class="str">'_cuda_isDriverSufficient'</span><span class="op">)</span> <span class="key">or</span>&nbsp;</span><span class="r"></span></p>
    <p id="t65" class="pln"><span class="n"><a href="#t65">65</a></span><span class="t">            <span class="key">not</span> <span class="nam">torch</span><span class="op">.</span><span class="nam">_C</span><span class="op">.</span><span class="nam">_cuda_isDriverSufficient</span><span class="op">(</span><span class="op">)</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t66" class="mis show_mis"><span class="n"><a href="#t66">66</a></span><span class="t">        <span class="key">return</span> <span class="key">False</span>&nbsp;</span><span class="r"></span></p>
    <p id="t67" class="mis show_mis"><span class="n"><a href="#t67">67</a></span><span class="t">    <span class="key">return</span> <span class="nam">torch</span><span class="op">.</span><span class="nam">_C</span><span class="op">.</span><span class="nam">_cuda_getDeviceCount</span><span class="op">(</span><span class="op">)</span> <span class="op">></span> <span class="num">0</span>&nbsp;</span><span class="r"></span></p>
    <p id="t68" class="pln"><span class="n"><a href="#t68">68</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t69" class="pln"><span class="n"><a href="#t69">69</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t70" class="run"><span class="n"><a href="#t70">70</a></span><span class="t"><span class="key">def</span> <span class="nam">_sleep</span><span class="op">(</span><span class="nam">cycles</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t71" class="mis show_mis"><span class="n"><a href="#t71">71</a></span><span class="t">    <span class="nam">torch</span><span class="op">.</span><span class="nam">_C</span><span class="op">.</span><span class="nam">_cuda_sleep</span><span class="op">(</span><span class="nam">cycles</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t72" class="pln"><span class="n"><a href="#t72">72</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t73" class="pln"><span class="n"><a href="#t73">73</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t74" class="run"><span class="n"><a href="#t74">74</a></span><span class="t"><span class="key">def</span> <span class="nam">_load_cudart</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t75" class="pln"><span class="n"><a href="#t75">75</a></span><span class="t">    <span class="com"># First check the main program for CUDA symbols</span>&nbsp;</span><span class="r"></span></p>
    <p id="t76" class="mis show_mis"><span class="n"><a href="#t76">76</a></span><span class="t">    <span class="key">if</span> <span class="nam">platform</span><span class="op">.</span><span class="nam">system</span><span class="op">(</span><span class="op">)</span> <span class="op">==</span> <span class="str">'Windows'</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t77" class="mis show_mis"><span class="n"><a href="#t77">77</a></span><span class="t">        <span class="nam">lib</span> <span class="op">=</span> <span class="nam">find_cuda_windows_lib</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t78" class="pln"><span class="n"><a href="#t78">78</a></span><span class="t">    <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t79" class="mis show_mis"><span class="n"><a href="#t79">79</a></span><span class="t">        <span class="nam">lib</span> <span class="op">=</span> <span class="nam">ctypes</span><span class="op">.</span><span class="nam">cdll</span><span class="op">.</span><span class="nam">LoadLibrary</span><span class="op">(</span><span class="key">None</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t80" class="mis show_mis"><span class="n"><a href="#t80">80</a></span><span class="t">    <span class="key">if</span> <span class="nam">hasattr</span><span class="op">(</span><span class="nam">lib</span><span class="op">,</span> <span class="str">'cudaGetErrorName'</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t81" class="mis show_mis"><span class="n"><a href="#t81">81</a></span><span class="t">        <span class="key">return</span> <span class="nam">lib</span>&nbsp;</span><span class="r"></span></p>
    <p id="t82" class="pln"><span class="n"><a href="#t82">82</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t83" class="mis show_mis"><span class="n"><a href="#t83">83</a></span><span class="t">    <span class="key">raise</span> <span class="nam">RuntimeError</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p id="t84" class="pln"><span class="n"><a href="#t84">84</a></span><span class="t">        <span class="str">"couldn't find libcudart. Make sure CUDA libraries are installed in a "</span>&nbsp;</span><span class="r"></span></p>
    <p id="t85" class="pln"><span class="n"><a href="#t85">85</a></span><span class="t">        <span class="str">"default location, or that they're in {}."</span>&nbsp;</span><span class="r"></span></p>
    <p id="t86" class="pln"><span class="n"><a href="#t86">86</a></span><span class="t">        <span class="op">.</span><span class="nam">format</span><span class="op">(</span><span class="str">'DYLD_LIBRARY_PATH'</span> <span class="key">if</span> <span class="nam">platform</span><span class="op">.</span><span class="nam">system</span><span class="op">(</span><span class="op">)</span> <span class="op">==</span> <span class="str">'Darwin'</span> <span class="key">else</span>&nbsp;</span><span class="r"></span></p>
    <p id="t87" class="pln"><span class="n"><a href="#t87">87</a></span><span class="t">                <span class="str">'LD_LIBRARY_PATH'</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t88" class="pln"><span class="n"><a href="#t88">88</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t89" class="pln"><span class="n"><a href="#t89">89</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t90" class="run"><span class="n"><a href="#t90">90</a></span><span class="t"><span class="key">def</span> <span class="nam">_check_driver</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t91" class="mis show_mis"><span class="n"><a href="#t91">91</a></span><span class="t">    <span class="key">if</span> <span class="key">not</span> <span class="nam">hasattr</span><span class="op">(</span><span class="nam">torch</span><span class="op">.</span><span class="nam">_C</span><span class="op">,</span> <span class="str">'_cuda_isDriverSufficient'</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t92" class="mis show_mis"><span class="n"><a href="#t92">92</a></span><span class="t">        <span class="key">raise</span> <span class="nam">AssertionError</span><span class="op">(</span><span class="str">"Torch not compiled with CUDA enabled"</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t93" class="mis show_mis"><span class="n"><a href="#t93">93</a></span><span class="t">    <span class="key">if</span> <span class="key">not</span> <span class="nam">torch</span><span class="op">.</span><span class="nam">_C</span><span class="op">.</span><span class="nam">_cuda_isDriverSufficient</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t94" class="mis show_mis"><span class="n"><a href="#t94">94</a></span><span class="t">        <span class="key">if</span> <span class="nam">torch</span><span class="op">.</span><span class="nam">_C</span><span class="op">.</span><span class="nam">_cuda_getDriverVersion</span><span class="op">(</span><span class="op">)</span> <span class="op">==</span> <span class="num">0</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t95" class="pln"><span class="n"><a href="#t95">95</a></span><span class="t">            <span class="com"># found no NVIDIA driver on the system</span>&nbsp;</span><span class="r"></span></p>
    <p id="t96" class="mis show_mis"><span class="n"><a href="#t96">96</a></span><span class="t">            <span class="key">raise</span> <span class="nam">AssertionError</span><span class="op">(</span><span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p id="t97" class="pln"><span class="n"><a href="#t97">97</a></span><span class="t"><span class="str">Found no NVIDIA driver on your system. Please check that you</span>&nbsp;</span><span class="r"></span></p>
    <p id="t98" class="pln"><span class="n"><a href="#t98">98</a></span><span class="t"><span class="str">have an NVIDIA GPU and installed a driver from</span>&nbsp;</span><span class="r"></span></p>
    <p id="t99" class="pln"><span class="n"><a href="#t99">99</a></span><span class="t"><span class="str">http://www.nvidia.com/Download/index.aspx"""</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t100" class="pln"><span class="n"><a href="#t100">100</a></span><span class="t">        <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t101" class="pln"><span class="n"><a href="#t101">101</a></span><span class="t">            <span class="com"># TODO: directly link to the alternative bin that needs install</span>&nbsp;</span><span class="r"></span></p>
    <p id="t102" class="mis show_mis"><span class="n"><a href="#t102">102</a></span><span class="t">            <span class="key">raise</span> <span class="nam">AssertionError</span><span class="op">(</span><span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p id="t103" class="pln"><span class="n"><a href="#t103">103</a></span><span class="t"><span class="str">The NVIDIA driver on your system is too old (found version {}).</span>&nbsp;</span><span class="r"></span></p>
    <p id="t104" class="pln"><span class="n"><a href="#t104">104</a></span><span class="t"><span class="str">Please update your GPU driver by downloading and installing a new</span>&nbsp;</span><span class="r"></span></p>
    <p id="t105" class="pln"><span class="n"><a href="#t105">105</a></span><span class="t"><span class="str">version from the URL: http://www.nvidia.com/Download/index.aspx</span>&nbsp;</span><span class="r"></span></p>
    <p id="t106" class="pln"><span class="n"><a href="#t106">106</a></span><span class="t"><span class="str">Alternatively, go to: https://pytorch.org to install</span>&nbsp;</span><span class="r"></span></p>
    <p id="t107" class="pln"><span class="n"><a href="#t107">107</a></span><span class="t"><span class="str">a PyTorch version that has been compiled with your version</span>&nbsp;</span><span class="r"></span></p>
    <p id="t108" class="pln"><span class="n"><a href="#t108">108</a></span><span class="t"><span class="str">of the CUDA driver."""</span><span class="op">.</span><span class="nam">format</span><span class="op">(</span><span class="nam">str</span><span class="op">(</span><span class="nam">torch</span><span class="op">.</span><span class="nam">_C</span><span class="op">.</span><span class="nam">_cuda_getDriverVersion</span><span class="op">(</span><span class="op">)</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t109" class="pln"><span class="n"><a href="#t109">109</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t110" class="pln"><span class="n"><a href="#t110">110</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t111" class="run"><span class="n"><a href="#t111">111</a></span><span class="t"><span class="key">def</span> <span class="nam">_check_capability</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t112" class="mis show_mis"><span class="n"><a href="#t112">112</a></span><span class="t">    <span class="nam">incorrect_binary_warn</span> <span class="op">=</span> <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p id="t113" class="pln"><span class="n"><a href="#t113">113</a></span><span class="t"><span class="str">    Found GPU%d %s which requires CUDA_VERSION >= %d to</span>&nbsp;</span><span class="r"></span></p>
    <p id="t114" class="pln"><span class="n"><a href="#t114">114</a></span><span class="t"><span class="str">     work properly, but your PyTorch was compiled</span>&nbsp;</span><span class="r"></span></p>
    <p id="t115" class="pln"><span class="n"><a href="#t115">115</a></span><span class="t"><span class="str">     with CUDA_VERSION %d. Please install the correct PyTorch binary</span>&nbsp;</span><span class="r"></span></p>
    <p id="t116" class="pln"><span class="n"><a href="#t116">116</a></span><span class="t"><span class="str">     using instructions from https://pytorch.org</span>&nbsp;</span><span class="r"></span></p>
    <p id="t117" class="pln"><span class="n"><a href="#t117">117</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p id="t118" class="pln"><span class="n"><a href="#t118">118</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t119" class="mis show_mis"><span class="n"><a href="#t119">119</a></span><span class="t">    <span class="nam">old_gpu_warn</span> <span class="op">=</span> <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p id="t120" class="pln"><span class="n"><a href="#t120">120</a></span><span class="t"><span class="str">    Found GPU%d %s which is of cuda capability %d.%d.</span>&nbsp;</span><span class="r"></span></p>
    <p id="t121" class="pln"><span class="n"><a href="#t121">121</a></span><span class="t"><span class="str">    PyTorch no longer supports this GPU because it is too old.</span>&nbsp;</span><span class="r"></span></p>
    <p id="t122" class="pln"><span class="n"><a href="#t122">122</a></span><span class="t"><span class="str">    The minimum cuda capability that we support is 3.5.</span>&nbsp;</span><span class="r"></span></p>
    <p id="t123" class="pln"><span class="n"><a href="#t123">123</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p id="t124" class="pln"><span class="n"><a href="#t124">124</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t125" class="mis show_mis"><span class="n"><a href="#t125">125</a></span><span class="t">    <span class="nam">CUDA_VERSION</span> <span class="op">=</span> <span class="nam">torch</span><span class="op">.</span><span class="nam">_C</span><span class="op">.</span><span class="nam">_cuda_getCompiledVersion</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t126" class="mis show_mis"><span class="n"><a href="#t126">126</a></span><span class="t">    <span class="key">for</span> <span class="nam">d</span> <span class="key">in</span> <span class="nam">range</span><span class="op">(</span><span class="nam">device_count</span><span class="op">(</span><span class="op">)</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t127" class="mis show_mis"><span class="n"><a href="#t127">127</a></span><span class="t">        <span class="nam">capability</span> <span class="op">=</span> <span class="nam">get_device_capability</span><span class="op">(</span><span class="nam">d</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t128" class="mis show_mis"><span class="n"><a href="#t128">128</a></span><span class="t">        <span class="nam">major</span> <span class="op">=</span> <span class="nam">capability</span><span class="op">[</span><span class="num">0</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p id="t129" class="mis show_mis"><span class="n"><a href="#t129">129</a></span><span class="t">        <span class="nam">minor</span> <span class="op">=</span> <span class="nam">capability</span><span class="op">[</span><span class="num">1</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p id="t130" class="mis show_mis"><span class="n"><a href="#t130">130</a></span><span class="t">        <span class="nam">name</span> <span class="op">=</span> <span class="nam">get_device_name</span><span class="op">(</span><span class="nam">d</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t131" class="mis show_mis"><span class="n"><a href="#t131">131</a></span><span class="t">        <span class="key">if</span> <span class="nam">capability</span> <span class="op">==</span> <span class="op">(</span><span class="num">3</span><span class="op">,</span> <span class="num">0</span><span class="op">)</span> <span class="key">or</span> <span class="nam">major</span> <span class="op">&lt;</span> <span class="num">3</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t132" class="mis show_mis"><span class="n"><a href="#t132">132</a></span><span class="t">            <span class="nam">warnings</span><span class="op">.</span><span class="nam">warn</span><span class="op">(</span><span class="nam">old_gpu_warn</span> <span class="op">%</span> <span class="op">(</span><span class="nam">d</span><span class="op">,</span> <span class="nam">name</span><span class="op">,</span> <span class="nam">major</span><span class="op">,</span> <span class="nam">capability</span><span class="op">[</span><span class="num">1</span><span class="op">]</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t133" class="mis show_mis"><span class="n"><a href="#t133">133</a></span><span class="t">        <span class="key">elif</span> <span class="nam">CUDA_VERSION</span> <span class="op">&lt;=</span> <span class="num">9000</span> <span class="key">and</span> <span class="nam">major</span> <span class="op">>=</span> <span class="num">7</span> <span class="key">and</span> <span class="nam">minor</span> <span class="op">>=</span> <span class="num">5</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t134" class="mis show_mis"><span class="n"><a href="#t134">134</a></span><span class="t">            <span class="nam">warnings</span><span class="op">.</span><span class="nam">warn</span><span class="op">(</span><span class="nam">incorrect_binary_warn</span> <span class="op">%</span> <span class="op">(</span><span class="nam">d</span><span class="op">,</span> <span class="nam">name</span><span class="op">,</span> <span class="num">10000</span><span class="op">,</span> <span class="nam">CUDA_VERSION</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t135" class="pln"><span class="n"><a href="#t135">135</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t136" class="pln"><span class="n"><a href="#t136">136</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t137" class="run"><span class="n"><a href="#t137">137</a></span><span class="t"><span class="key">def</span> <span class="nam">is_initialized</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t138" class="pln"><span class="n"><a href="#t138">138</a></span><span class="t">    <span class="str">r"""Returns whether PyTorch's CUDA state has been initialized."""</span>&nbsp;</span><span class="r"></span></p>
    <p id="t139" class="run"><span class="n"><a href="#t139">139</a></span><span class="t">    <span class="key">return</span> <span class="nam">_initialized</span> <span class="key">and</span> <span class="key">not</span> <span class="nam">_is_in_bad_fork</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t140" class="pln"><span class="n"><a href="#t140">140</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t141" class="pln"><span class="n"><a href="#t141">141</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t142" class="run"><span class="n"><a href="#t142">142</a></span><span class="t"><span class="key">def</span> <span class="nam">_lazy_call</span><span class="op">(</span><span class="nam">callable</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t143" class="run"><span class="n"><a href="#t143">143</a></span><span class="t">    <span class="key">if</span> <span class="nam">is_initialized</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t144" class="mis show_mis"><span class="n"><a href="#t144">144</a></span><span class="t">        <span class="nam">callable</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t145" class="pln"><span class="n"><a href="#t145">145</a></span><span class="t">    <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t146" class="pln"><span class="n"><a href="#t146">146</a></span><span class="t">        <span class="com"># Don't store the actual traceback to avoid memory cycle</span>&nbsp;</span><span class="r"></span></p>
    <p id="t147" class="run"><span class="n"><a href="#t147">147</a></span><span class="t">        <span class="nam">_queued_calls</span><span class="op">.</span><span class="nam">append</span><span class="op">(</span><span class="op">(</span><span class="nam">callable</span><span class="op">,</span> <span class="nam">traceback</span><span class="op">.</span><span class="nam">format_stack</span><span class="op">(</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t148" class="pln"><span class="n"><a href="#t148">148</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t149" class="run"><span class="n"><a href="#t149">149</a></span><span class="t"><span class="nam">_lazy_call</span><span class="op">(</span><span class="nam">_check_capability</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t150" class="pln"><span class="n"><a href="#t150">150</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t151" class="pln"><span class="n"><a href="#t151">151</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t152" class="run"><span class="n"><a href="#t152">152</a></span><span class="t"><span class="key">class</span> <span class="nam">DeferredCudaCallError</span><span class="op">(</span><span class="nam">Exception</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t153" class="run"><span class="n"><a href="#t153">153</a></span><span class="t">    <span class="key">pass</span>&nbsp;</span><span class="r"></span></p>
    <p id="t154" class="pln"><span class="n"><a href="#t154">154</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t155" class="pln"><span class="n"><a href="#t155">155</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t156" class="run"><span class="n"><a href="#t156">156</a></span><span class="t"><span class="key">def</span> <span class="nam">init</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t157" class="pln"><span class="n"><a href="#t157">157</a></span><span class="t">    <span class="str">r"""Initialize PyTorch's CUDA state.  You may need to call</span>&nbsp;</span><span class="r"></span></p>
    <p id="t158" class="pln"><span class="n"><a href="#t158">158</a></span><span class="t"><span class="str">    this explicitly if you are interacting with PyTorch via</span>&nbsp;</span><span class="r"></span></p>
    <p id="t159" class="pln"><span class="n"><a href="#t159">159</a></span><span class="t"><span class="str">    its C API, as Python bindings for CUDA functionality will not</span>&nbsp;</span><span class="r"></span></p>
    <p id="t160" class="pln"><span class="n"><a href="#t160">160</a></span><span class="t"><span class="str">    be until this initialization takes place.  Ordinary users</span>&nbsp;</span><span class="r"></span></p>
    <p id="t161" class="pln"><span class="n"><a href="#t161">161</a></span><span class="t"><span class="str">    should not need this, as all of PyTorch's CUDA methods</span>&nbsp;</span><span class="r"></span></p>
    <p id="t162" class="pln"><span class="n"><a href="#t162">162</a></span><span class="t"><span class="str">    automatically initialize CUDA state on-demand.</span>&nbsp;</span><span class="r"></span></p>
    <p id="t163" class="pln"><span class="n"><a href="#t163">163</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t164" class="pln"><span class="n"><a href="#t164">164</a></span><span class="t"><span class="str">    Does nothing if the CUDA state is already initialized.</span>&nbsp;</span><span class="r"></span></p>
    <p id="t165" class="pln"><span class="n"><a href="#t165">165</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p id="t166" class="mis show_mis"><span class="n"><a href="#t166">166</a></span><span class="t">    <span class="nam">_lazy_init</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t167" class="pln"><span class="n"><a href="#t167">167</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t168" class="pln"><span class="n"><a href="#t168">168</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t169" class="run"><span class="n"><a href="#t169">169</a></span><span class="t"><span class="key">def</span> <span class="nam">_lazy_init</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t170" class="pln"><span class="n"><a href="#t170">170</a></span><span class="t">    <span class="key">global</span> <span class="nam">_initialized</span><span class="op">,</span> <span class="nam">_cudart</span><span class="op">,</span> <span class="nam">_queued_calls</span>&nbsp;</span><span class="r"></span></p>
    <p id="t171" class="mis show_mis"><span class="n"><a href="#t171">171</a></span><span class="t">    <span class="key">if</span> <span class="nam">is_initialized</span><span class="op">(</span><span class="op">)</span> <span class="key">or</span> <span class="nam">hasattr</span><span class="op">(</span><span class="nam">_tls</span><span class="op">,</span> <span class="str">'is_initializing'</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t172" class="mis show_mis"><span class="n"><a href="#t172">172</a></span><span class="t">        <span class="key">return</span>&nbsp;</span><span class="r"></span></p>
    <p id="t173" class="mis show_mis"><span class="n"><a href="#t173">173</a></span><span class="t">    <span class="key">with</span> <span class="nam">_initialization_lock</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t174" class="pln"><span class="n"><a href="#t174">174</a></span><span class="t">        <span class="com"># We be double-checked locking, boys!  This is OK because</span>&nbsp;</span><span class="r"></span></p>
    <p id="t175" class="pln"><span class="n"><a href="#t175">175</a></span><span class="t">        <span class="com"># the above test was GIL protected anyway.  The inner test</span>&nbsp;</span><span class="r"></span></p>
    <p id="t176" class="pln"><span class="n"><a href="#t176">176</a></span><span class="t">        <span class="com"># is for when a thread blocked on some other thread which was</span>&nbsp;</span><span class="r"></span></p>
    <p id="t177" class="pln"><span class="n"><a href="#t177">177</a></span><span class="t">        <span class="com"># doing the initialization; when they get the lock, they will</span>&nbsp;</span><span class="r"></span></p>
    <p id="t178" class="pln"><span class="n"><a href="#t178">178</a></span><span class="t">        <span class="com"># find there is nothing left to do.</span>&nbsp;</span><span class="r"></span></p>
    <p id="t179" class="mis show_mis"><span class="n"><a href="#t179">179</a></span><span class="t">        <span class="key">if</span> <span class="nam">is_initialized</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t180" class="mis show_mis"><span class="n"><a href="#t180">180</a></span><span class="t">            <span class="key">return</span>&nbsp;</span><span class="r"></span></p>
    <p id="t181" class="pln"><span class="n"><a href="#t181">181</a></span><span class="t">        <span class="com"># It is important to prevent other threads from entering _lazy_init</span>&nbsp;</span><span class="r"></span></p>
    <p id="t182" class="pln"><span class="n"><a href="#t182">182</a></span><span class="t">        <span class="com"># immediately, while we are still guaranteed to have the GIL, because some</span>&nbsp;</span><span class="r"></span></p>
    <p id="t183" class="pln"><span class="n"><a href="#t183">183</a></span><span class="t">        <span class="com"># of the C calls we make below will release the GIL</span>&nbsp;</span><span class="r"></span></p>
    <p id="t184" class="mis show_mis"><span class="n"><a href="#t184">184</a></span><span class="t">        <span class="key">if</span> <span class="nam">_is_in_bad_fork</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t185" class="mis show_mis"><span class="n"><a href="#t185">185</a></span><span class="t">            <span class="key">from</span> <span class="nam">sys</span> <span class="key">import</span> <span class="nam">version_info</span>&nbsp;</span><span class="r"></span></p>
    <p id="t186" class="mis show_mis"><span class="n"><a href="#t186">186</a></span><span class="t">            <span class="key">if</span> <span class="nam">version_info</span> <span class="op">&lt;</span> <span class="op">(</span><span class="num">3</span><span class="op">,</span> <span class="num">4</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t187" class="mis show_mis"><span class="n"><a href="#t187">187</a></span><span class="t">                <span class="nam">msg</span> <span class="op">=</span> <span class="op">(</span><span class="str">"To use CUDA with multiprocessing, you must use Python "</span>&nbsp;</span><span class="r"></span></p>
    <p id="t188" class="pln"><span class="n"><a href="#t188">188</a></span><span class="t">                       <span class="str">"3.4+ and the 'spawn' start method"</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t189" class="pln"><span class="n"><a href="#t189">189</a></span><span class="t">            <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t190" class="mis show_mis"><span class="n"><a href="#t190">190</a></span><span class="t">                <span class="nam">msg</span> <span class="op">=</span> <span class="op">(</span><span class="str">"To use CUDA with multiprocessing, you must use the "</span>&nbsp;</span><span class="r"></span></p>
    <p id="t191" class="pln"><span class="n"><a href="#t191">191</a></span><span class="t">                       <span class="str">"'spawn' start method"</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t192" class="mis show_mis"><span class="n"><a href="#t192">192</a></span><span class="t">            <span class="key">raise</span> <span class="nam">RuntimeError</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p id="t193" class="pln"><span class="n"><a href="#t193">193</a></span><span class="t">                <span class="str">"Cannot re-initialize CUDA in forked subprocess. "</span> <span class="op">+</span> <span class="nam">msg</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t194" class="mis show_mis"><span class="n"><a href="#t194">194</a></span><span class="t">        <span class="nam">_check_driver</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t195" class="mis show_mis"><span class="n"><a href="#t195">195</a></span><span class="t">        <span class="nam">torch</span><span class="op">.</span><span class="nam">_C</span><span class="op">.</span><span class="nam">_cuda_init</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t196" class="mis show_mis"><span class="n"><a href="#t196">196</a></span><span class="t">        <span class="nam">_cudart</span> <span class="op">=</span> <span class="nam">_load_cudart</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t197" class="mis show_mis"><span class="n"><a href="#t197">197</a></span><span class="t">        <span class="nam">_cudart</span><span class="op">.</span><span class="nam">cudaGetErrorName</span><span class="op">.</span><span class="nam">restype</span> <span class="op">=</span> <span class="nam">ctypes</span><span class="op">.</span><span class="nam">c_char_p</span>&nbsp;</span><span class="r"></span></p>
    <p id="t198" class="mis show_mis"><span class="n"><a href="#t198">198</a></span><span class="t">        <span class="nam">_cudart</span><span class="op">.</span><span class="nam">cudaGetErrorString</span><span class="op">.</span><span class="nam">restype</span> <span class="op">=</span> <span class="nam">ctypes</span><span class="op">.</span><span class="nam">c_char_p</span>&nbsp;</span><span class="r"></span></p>
    <p id="t199" class="pln"><span class="n"><a href="#t199">199</a></span><span class="t">        <span class="com"># Some of the queued calls may reentrantly call _lazy_init();</span>&nbsp;</span><span class="r"></span></p>
    <p id="t200" class="pln"><span class="n"><a href="#t200">200</a></span><span class="t">        <span class="com"># we need to just return without initializing in that case.</span>&nbsp;</span><span class="r"></span></p>
    <p id="t201" class="pln"><span class="n"><a href="#t201">201</a></span><span class="t">        <span class="com"># However, we must not let any *other* threads in!</span>&nbsp;</span><span class="r"></span></p>
    <p id="t202" class="mis show_mis"><span class="n"><a href="#t202">202</a></span><span class="t">        <span class="nam">_tls</span><span class="op">.</span><span class="nam">is_initializing</span> <span class="op">=</span> <span class="key">True</span>&nbsp;</span><span class="r"></span></p>
    <p id="t203" class="mis show_mis"><span class="n"><a href="#t203">203</a></span><span class="t">        <span class="key">try</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t204" class="mis show_mis"><span class="n"><a href="#t204">204</a></span><span class="t">            <span class="key">for</span> <span class="nam">queued_call</span><span class="op">,</span> <span class="nam">orig_traceback</span> <span class="key">in</span> <span class="nam">_queued_calls</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t205" class="mis show_mis"><span class="n"><a href="#t205">205</a></span><span class="t">                <span class="key">try</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t206" class="mis show_mis"><span class="n"><a href="#t206">206</a></span><span class="t">                    <span class="nam">queued_call</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t207" class="mis show_mis"><span class="n"><a href="#t207">207</a></span><span class="t">                <span class="key">except</span> <span class="nam">Exception</span> <span class="key">as</span> <span class="nam">e</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t208" class="mis show_mis"><span class="n"><a href="#t208">208</a></span><span class="t">                    <span class="nam">msg</span> <span class="op">=</span> <span class="op">(</span><span class="str">"CUDA call failed lazily at initialization with error: {}\n\n"</span>&nbsp;</span><span class="r"></span></p>
    <p id="t209" class="pln"><span class="n"><a href="#t209">209</a></span><span class="t">                           <span class="str">"CUDA call was originally invoked at:\n\n{}"</span><span class="op">)</span><span class="op">.</span><span class="nam">format</span><span class="op">(</span><span class="nam">str</span><span class="op">(</span><span class="nam">e</span><span class="op">)</span><span class="op">,</span> <span class="nam">orig_traceback</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t210" class="mis show_mis"><span class="n"><a href="#t210">210</a></span><span class="t">                    <span class="nam">raise_from</span><span class="op">(</span><span class="nam">DeferredCudaCallError</span><span class="op">(</span><span class="nam">msg</span><span class="op">)</span><span class="op">,</span> <span class="nam">e</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t211" class="pln"><span class="n"><a href="#t211">211</a></span><span class="t">        <span class="key">finally</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t212" class="mis show_mis"><span class="n"><a href="#t212">212</a></span><span class="t">            <span class="nam">delattr</span><span class="op">(</span><span class="nam">_tls</span><span class="op">,</span> <span class="str">'is_initializing'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t213" class="mis show_mis"><span class="n"><a href="#t213">213</a></span><span class="t">        <span class="nam">_initialized</span> <span class="op">=</span> <span class="key">True</span>&nbsp;</span><span class="r"></span></p>
    <p id="t214" class="pln"><span class="n"><a href="#t214">214</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t215" class="pln"><span class="n"><a href="#t215">215</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t216" class="run"><span class="n"><a href="#t216">216</a></span><span class="t"><span class="key">def</span> <span class="nam">cudart</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t217" class="mis show_mis"><span class="n"><a href="#t217">217</a></span><span class="t">    <span class="nam">_lazy_init</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t218" class="mis show_mis"><span class="n"><a href="#t218">218</a></span><span class="t">    <span class="key">return</span> <span class="nam">_cudart</span>&nbsp;</span><span class="r"></span></p>
    <p id="t219" class="pln"><span class="n"><a href="#t219">219</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t220" class="pln"><span class="n"><a href="#t220">220</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t221" class="run"><span class="n"><a href="#t221">221</a></span><span class="t"><span class="key">class</span> <span class="nam">cudaStatus</span><span class="op">(</span><span class="nam">object</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t222" class="run"><span class="n"><a href="#t222">222</a></span><span class="t">    <span class="nam">SUCCESS</span> <span class="op">=</span> <span class="num">0</span>&nbsp;</span><span class="r"></span></p>
    <p id="t223" class="run"><span class="n"><a href="#t223">223</a></span><span class="t">    <span class="nam">ERROR_NOT_READY</span> <span class="op">=</span> <span class="num">34</span>&nbsp;</span><span class="r"></span></p>
    <p id="t224" class="pln"><span class="n"><a href="#t224">224</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t225" class="pln"><span class="n"><a href="#t225">225</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t226" class="run"><span class="n"><a href="#t226">226</a></span><span class="t"><span class="key">class</span> <span class="nam">CudaError</span><span class="op">(</span><span class="nam">RuntimeError</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t227" class="run"><span class="n"><a href="#t227">227</a></span><span class="t">    <span class="key">def</span> <span class="nam">__init__</span><span class="op">(</span><span class="nam">self</span><span class="op">,</span> <span class="nam">code</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t228" class="mis show_mis"><span class="n"><a href="#t228">228</a></span><span class="t">        <span class="nam">msg</span> <span class="op">=</span> <span class="nam">cudart</span><span class="op">(</span><span class="op">)</span><span class="op">.</span><span class="nam">cudaGetErrorString</span><span class="op">(</span><span class="nam">code</span><span class="op">)</span><span class="op">.</span><span class="nam">decode</span><span class="op">(</span><span class="str">'utf-8'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t229" class="mis show_mis"><span class="n"><a href="#t229">229</a></span><span class="t">        <span class="nam">super</span><span class="op">(</span><span class="nam">CudaError</span><span class="op">,</span> <span class="nam">self</span><span class="op">)</span><span class="op">.</span><span class="nam">__init__</span><span class="op">(</span><span class="str">'{0} ({1})'</span><span class="op">.</span><span class="nam">format</span><span class="op">(</span><span class="nam">msg</span><span class="op">,</span> <span class="nam">code</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t230" class="pln"><span class="n"><a href="#t230">230</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t231" class="pln"><span class="n"><a href="#t231">231</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t232" class="run"><span class="n"><a href="#t232">232</a></span><span class="t"><span class="key">def</span> <span class="nam">check_error</span><span class="op">(</span><span class="nam">res</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t233" class="mis show_mis"><span class="n"><a href="#t233">233</a></span><span class="t">    <span class="key">if</span> <span class="nam">res</span> <span class="op">!=</span> <span class="nam">cudaStatus</span><span class="op">.</span><span class="nam">SUCCESS</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t234" class="mis show_mis"><span class="n"><a href="#t234">234</a></span><span class="t">        <span class="key">raise</span> <span class="nam">CudaError</span><span class="op">(</span><span class="nam">res</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t235" class="pln"><span class="n"><a href="#t235">235</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t236" class="pln"><span class="n"><a href="#t236">236</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t237" class="run"><span class="n"><a href="#t237">237</a></span><span class="t"><span class="key">class</span> <span class="nam">device</span><span class="op">(</span><span class="nam">object</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t238" class="pln"><span class="n"><a href="#t238">238</a></span><span class="t">    <span class="str">r"""Context-manager that changes the selected device.</span>&nbsp;</span><span class="r"></span></p>
    <p id="t239" class="pln"><span class="n"><a href="#t239">239</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t240" class="pln"><span class="n"><a href="#t240">240</a></span><span class="t"><span class="str">    Arguments:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t241" class="pln"><span class="n"><a href="#t241">241</a></span><span class="t"><span class="str">        device (torch.device or int): device index to select. It's a no-op if</span>&nbsp;</span><span class="r"></span></p>
    <p id="t242" class="pln"><span class="n"><a href="#t242">242</a></span><span class="t"><span class="str">            this argument is a negative integer or ``None``.</span>&nbsp;</span><span class="r"></span></p>
    <p id="t243" class="pln"><span class="n"><a href="#t243">243</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p id="t244" class="pln"><span class="n"><a href="#t244">244</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t245" class="run"><span class="n"><a href="#t245">245</a></span><span class="t">    <span class="key">def</span> <span class="nam">__init__</span><span class="op">(</span><span class="nam">self</span><span class="op">,</span> <span class="nam">device</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t246" class="mis show_mis"><span class="n"><a href="#t246">246</a></span><span class="t">        <span class="nam">self</span><span class="op">.</span><span class="nam">idx</span> <span class="op">=</span> <span class="nam">_get_device_index</span><span class="op">(</span><span class="nam">device</span><span class="op">,</span> <span class="nam">optional</span><span class="op">=</span><span class="key">True</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t247" class="mis show_mis"><span class="n"><a href="#t247">247</a></span><span class="t">        <span class="nam">self</span><span class="op">.</span><span class="nam">prev_idx</span> <span class="op">=</span> <span class="op">-</span><span class="num">1</span>&nbsp;</span><span class="r"></span></p>
    <p id="t248" class="pln"><span class="n"><a href="#t248">248</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t249" class="run"><span class="n"><a href="#t249">249</a></span><span class="t">    <span class="key">def</span> <span class="nam">__enter__</span><span class="op">(</span><span class="nam">self</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t250" class="mis show_mis"><span class="n"><a href="#t250">250</a></span><span class="t">        <span class="key">if</span> <span class="nam">self</span><span class="op">.</span><span class="nam">idx</span> <span class="op">==</span> <span class="op">-</span><span class="num">1</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t251" class="mis show_mis"><span class="n"><a href="#t251">251</a></span><span class="t">            <span class="key">return</span>&nbsp;</span><span class="r"></span></p>
    <p id="t252" class="mis show_mis"><span class="n"><a href="#t252">252</a></span><span class="t">        <span class="nam">self</span><span class="op">.</span><span class="nam">prev_idx</span> <span class="op">=</span> <span class="nam">torch</span><span class="op">.</span><span class="nam">_C</span><span class="op">.</span><span class="nam">_cuda_getDevice</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t253" class="mis show_mis"><span class="n"><a href="#t253">253</a></span><span class="t">        <span class="key">if</span> <span class="nam">self</span><span class="op">.</span><span class="nam">prev_idx</span> <span class="op">!=</span> <span class="nam">self</span><span class="op">.</span><span class="nam">idx</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t254" class="mis show_mis"><span class="n"><a href="#t254">254</a></span><span class="t">            <span class="nam">torch</span><span class="op">.</span><span class="nam">_C</span><span class="op">.</span><span class="nam">_cuda_setDevice</span><span class="op">(</span><span class="nam">self</span><span class="op">.</span><span class="nam">idx</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t255" class="mis show_mis"><span class="n"><a href="#t255">255</a></span><span class="t">        <span class="nam">_lazy_init</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t256" class="pln"><span class="n"><a href="#t256">256</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t257" class="run"><span class="n"><a href="#t257">257</a></span><span class="t">    <span class="key">def</span> <span class="nam">__exit__</span><span class="op">(</span><span class="nam">self</span><span class="op">,</span> <span class="op">*</span><span class="nam">args</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t258" class="mis show_mis"><span class="n"><a href="#t258">258</a></span><span class="t">        <span class="key">if</span> <span class="nam">self</span><span class="op">.</span><span class="nam">prev_idx</span> <span class="op">!=</span> <span class="nam">self</span><span class="op">.</span><span class="nam">idx</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t259" class="mis show_mis"><span class="n"><a href="#t259">259</a></span><span class="t">            <span class="nam">torch</span><span class="op">.</span><span class="nam">_C</span><span class="op">.</span><span class="nam">_cuda_setDevice</span><span class="op">(</span><span class="nam">self</span><span class="op">.</span><span class="nam">prev_idx</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t260" class="mis show_mis"><span class="n"><a href="#t260">260</a></span><span class="t">        <span class="key">return</span> <span class="key">False</span>&nbsp;</span><span class="r"></span></p>
    <p id="t261" class="pln"><span class="n"><a href="#t261">261</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t262" class="pln"><span class="n"><a href="#t262">262</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t263" class="run"><span class="n"><a href="#t263">263</a></span><span class="t"><span class="key">class</span> <span class="nam">device_of</span><span class="op">(</span><span class="nam">device</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t264" class="pln"><span class="n"><a href="#t264">264</a></span><span class="t">    <span class="str">r"""Context-manager that changes the current device to that of given object.</span>&nbsp;</span><span class="r"></span></p>
    <p id="t265" class="pln"><span class="n"><a href="#t265">265</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t266" class="pln"><span class="n"><a href="#t266">266</a></span><span class="t"><span class="str">    You can use both tensors and storages as arguments. If a given object is</span>&nbsp;</span><span class="r"></span></p>
    <p id="t267" class="pln"><span class="n"><a href="#t267">267</a></span><span class="t"><span class="str">    not allocated on a GPU, this is a no-op.</span>&nbsp;</span><span class="r"></span></p>
    <p id="t268" class="pln"><span class="n"><a href="#t268">268</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t269" class="pln"><span class="n"><a href="#t269">269</a></span><span class="t"><span class="str">    Arguments:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t270" class="pln"><span class="n"><a href="#t270">270</a></span><span class="t"><span class="str">        obj (Tensor or Storage): object allocated on the selected device.</span>&nbsp;</span><span class="r"></span></p>
    <p id="t271" class="pln"><span class="n"><a href="#t271">271</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p id="t272" class="pln"><span class="n"><a href="#t272">272</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t273" class="run"><span class="n"><a href="#t273">273</a></span><span class="t">    <span class="key">def</span> <span class="nam">__init__</span><span class="op">(</span><span class="nam">self</span><span class="op">,</span> <span class="nam">obj</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t274" class="mis show_mis"><span class="n"><a href="#t274">274</a></span><span class="t">        <span class="nam">idx</span> <span class="op">=</span> <span class="nam">obj</span><span class="op">.</span><span class="nam">get_device</span><span class="op">(</span><span class="op">)</span> <span class="key">if</span> <span class="nam">obj</span><span class="op">.</span><span class="nam">is_cuda</span> <span class="key">else</span> <span class="op">-</span><span class="num">1</span>&nbsp;</span><span class="r"></span></p>
    <p id="t275" class="mis show_mis"><span class="n"><a href="#t275">275</a></span><span class="t">        <span class="nam">super</span><span class="op">(</span><span class="nam">device_of</span><span class="op">,</span> <span class="nam">self</span><span class="op">)</span><span class="op">.</span><span class="nam">__init__</span><span class="op">(</span><span class="nam">idx</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t276" class="pln"><span class="n"><a href="#t276">276</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t277" class="pln"><span class="n"><a href="#t277">277</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t278" class="run"><span class="n"><a href="#t278">278</a></span><span class="t"><span class="key">def</span> <span class="nam">set_device</span><span class="op">(</span><span class="nam">device</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t279" class="pln"><span class="n"><a href="#t279">279</a></span><span class="t">    <span class="str">r"""Sets the current device.</span>&nbsp;</span><span class="r"></span></p>
    <p id="t280" class="pln"><span class="n"><a href="#t280">280</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t281" class="pln"><span class="n"><a href="#t281">281</a></span><span class="t"><span class="str">    Usage of this function is discouraged in favor of :any:`device`. In most</span>&nbsp;</span><span class="r"></span></p>
    <p id="t282" class="pln"><span class="n"><a href="#t282">282</a></span><span class="t"><span class="str">    cases it's better to use ``CUDA_VISIBLE_DEVICES`` environmental variable.</span>&nbsp;</span><span class="r"></span></p>
    <p id="t283" class="pln"><span class="n"><a href="#t283">283</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t284" class="pln"><span class="n"><a href="#t284">284</a></span><span class="t"><span class="str">    Arguments:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t285" class="pln"><span class="n"><a href="#t285">285</a></span><span class="t"><span class="str">        device (torch.device or int): selected device. This function is a no-op</span>&nbsp;</span><span class="r"></span></p>
    <p id="t286" class="pln"><span class="n"><a href="#t286">286</a></span><span class="t"><span class="str">            if this argument is negative.</span>&nbsp;</span><span class="r"></span></p>
    <p id="t287" class="pln"><span class="n"><a href="#t287">287</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p id="t288" class="mis show_mis"><span class="n"><a href="#t288">288</a></span><span class="t">    <span class="nam">device</span> <span class="op">=</span> <span class="nam">_get_device_index</span><span class="op">(</span><span class="nam">device</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t289" class="mis show_mis"><span class="n"><a href="#t289">289</a></span><span class="t">    <span class="key">if</span> <span class="nam">device</span> <span class="op">>=</span> <span class="num">0</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t290" class="mis show_mis"><span class="n"><a href="#t290">290</a></span><span class="t">        <span class="nam">torch</span><span class="op">.</span><span class="nam">_C</span><span class="op">.</span><span class="nam">_cuda_setDevice</span><span class="op">(</span><span class="nam">device</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t291" class="pln"><span class="n"><a href="#t291">291</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t292" class="pln"><span class="n"><a href="#t292">292</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t293" class="run"><span class="n"><a href="#t293">293</a></span><span class="t"><span class="key">def</span> <span class="nam">get_device_name</span><span class="op">(</span><span class="nam">device</span><span class="op">=</span><span class="key">None</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t294" class="pln"><span class="n"><a href="#t294">294</a></span><span class="t">    <span class="str">r"""Gets the name of a device.</span>&nbsp;</span><span class="r"></span></p>
    <p id="t295" class="pln"><span class="n"><a href="#t295">295</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t296" class="pln"><span class="n"><a href="#t296">296</a></span><span class="t"><span class="str">    Arguments:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t297" class="pln"><span class="n"><a href="#t297">297</a></span><span class="t"><span class="str">        device (torch.device or int, optional): device for which to return the</span>&nbsp;</span><span class="r"></span></p>
    <p id="t298" class="pln"><span class="n"><a href="#t298">298</a></span><span class="t"><span class="str">            name. This function is a no-op if this argument is a negative</span>&nbsp;</span><span class="r"></span></p>
    <p id="t299" class="pln"><span class="n"><a href="#t299">299</a></span><span class="t"><span class="str">            integer. It uses the current device, given by :func:`~torch.cuda.current_device`,</span>&nbsp;</span><span class="r"></span></p>
    <p id="t300" class="pln"><span class="n"><a href="#t300">300</a></span><span class="t"><span class="str">            if :attr:`device` is ``None`` (default).</span>&nbsp;</span><span class="r"></span></p>
    <p id="t301" class="pln"><span class="n"><a href="#t301">301</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p id="t302" class="mis show_mis"><span class="n"><a href="#t302">302</a></span><span class="t">    <span class="key">return</span> <span class="nam">get_device_properties</span><span class="op">(</span><span class="nam">device</span><span class="op">)</span><span class="op">.</span><span class="nam">name</span>&nbsp;</span><span class="r"></span></p>
    <p id="t303" class="pln"><span class="n"><a href="#t303">303</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t304" class="pln"><span class="n"><a href="#t304">304</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t305" class="run"><span class="n"><a href="#t305">305</a></span><span class="t"><span class="key">def</span> <span class="nam">get_device_capability</span><span class="op">(</span><span class="nam">device</span><span class="op">=</span><span class="key">None</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t306" class="pln"><span class="n"><a href="#t306">306</a></span><span class="t">    <span class="str">r"""Gets the cuda capability of a device.</span>&nbsp;</span><span class="r"></span></p>
    <p id="t307" class="pln"><span class="n"><a href="#t307">307</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t308" class="pln"><span class="n"><a href="#t308">308</a></span><span class="t"><span class="str">    Arguments:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t309" class="pln"><span class="n"><a href="#t309">309</a></span><span class="t"><span class="str">        device (torch.device or int, optional): device for which to return the</span>&nbsp;</span><span class="r"></span></p>
    <p id="t310" class="pln"><span class="n"><a href="#t310">310</a></span><span class="t"><span class="str">            device capability. This function is a no-op if this argument is</span>&nbsp;</span><span class="r"></span></p>
    <p id="t311" class="pln"><span class="n"><a href="#t311">311</a></span><span class="t"><span class="str">            a negative integer. It uses the current device, given by</span>&nbsp;</span><span class="r"></span></p>
    <p id="t312" class="pln"><span class="n"><a href="#t312">312</a></span><span class="t"><span class="str">            :func:`~torch.cuda.current_device`, if :attr:`device` is ``None``</span>&nbsp;</span><span class="r"></span></p>
    <p id="t313" class="pln"><span class="n"><a href="#t313">313</a></span><span class="t"><span class="str">            (default).</span>&nbsp;</span><span class="r"></span></p>
    <p id="t314" class="pln"><span class="n"><a href="#t314">314</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t315" class="pln"><span class="n"><a href="#t315">315</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t316" class="pln"><span class="n"><a href="#t316">316</a></span><span class="t"><span class="str">        tuple(int, int): the major and minor cuda capability of the device</span>&nbsp;</span><span class="r"></span></p>
    <p id="t317" class="pln"><span class="n"><a href="#t317">317</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p id="t318" class="mis show_mis"><span class="n"><a href="#t318">318</a></span><span class="t">    <span class="nam">prop</span> <span class="op">=</span> <span class="nam">get_device_properties</span><span class="op">(</span><span class="nam">device</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t319" class="mis show_mis"><span class="n"><a href="#t319">319</a></span><span class="t">    <span class="key">return</span> <span class="nam">prop</span><span class="op">.</span><span class="nam">major</span><span class="op">,</span> <span class="nam">prop</span><span class="op">.</span><span class="nam">minor</span>&nbsp;</span><span class="r"></span></p>
    <p id="t320" class="pln"><span class="n"><a href="#t320">320</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t321" class="pln"><span class="n"><a href="#t321">321</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t322" class="run"><span class="n"><a href="#t322">322</a></span><span class="t"><span class="key">def</span> <span class="nam">get_device_properties</span><span class="op">(</span><span class="nam">device</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t323" class="mis show_mis"><span class="n"><a href="#t323">323</a></span><span class="t">    <span class="nam">_lazy_init</span><span class="op">(</span><span class="op">)</span>  <span class="com"># will define _get_device_properties and _CudaDeviceProperties</span>&nbsp;</span><span class="r"></span></p>
    <p id="t324" class="mis show_mis"><span class="n"><a href="#t324">324</a></span><span class="t">    <span class="nam">device</span> <span class="op">=</span> <span class="nam">_get_device_index</span><span class="op">(</span><span class="nam">device</span><span class="op">,</span> <span class="nam">optional</span><span class="op">=</span><span class="key">True</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t325" class="mis show_mis"><span class="n"><a href="#t325">325</a></span><span class="t">    <span class="key">if</span> <span class="nam">device</span> <span class="op">&lt;</span> <span class="num">0</span> <span class="key">or</span> <span class="nam">device</span> <span class="op">>=</span> <span class="nam">device_count</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t326" class="mis show_mis"><span class="n"><a href="#t326">326</a></span><span class="t">        <span class="key">raise</span> <span class="nam">AssertionError</span><span class="op">(</span><span class="str">"Invalid device id"</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t327" class="mis show_mis"><span class="n"><a href="#t327">327</a></span><span class="t">    <span class="key">return</span> <span class="nam">_get_device_properties</span><span class="op">(</span><span class="nam">device</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t328" class="pln"><span class="n"><a href="#t328">328</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t329" class="pln"><span class="n"><a href="#t329">329</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t330" class="run"><span class="n"><a href="#t330">330</a></span><span class="t"><span class="op">@</span><span class="nam">contextlib</span><span class="op">.</span><span class="nam">contextmanager</span>&nbsp;</span><span class="r"></span></p>
    <p id="t331" class="pln"><span class="n"><a href="#t331">331</a></span><span class="t"><span class="key">def</span> <span class="nam">stream</span><span class="op">(</span><span class="nam">stream</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t332" class="pln"><span class="n"><a href="#t332">332</a></span><span class="t">    <span class="str">r"""Context-manager that selects a given stream.</span>&nbsp;</span><span class="r"></span></p>
    <p id="t333" class="pln"><span class="n"><a href="#t333">333</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t334" class="pln"><span class="n"><a href="#t334">334</a></span><span class="t"><span class="str">    All CUDA kernels queued within its context will be enqueued on a selected</span>&nbsp;</span><span class="r"></span></p>
    <p id="t335" class="pln"><span class="n"><a href="#t335">335</a></span><span class="t"><span class="str">    stream.</span>&nbsp;</span><span class="r"></span></p>
    <p id="t336" class="pln"><span class="n"><a href="#t336">336</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t337" class="pln"><span class="n"><a href="#t337">337</a></span><span class="t"><span class="str">    Arguments:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t338" class="pln"><span class="n"><a href="#t338">338</a></span><span class="t"><span class="str">        stream (Stream): selected stream. This manager is a no-op if it's</span>&nbsp;</span><span class="r"></span></p>
    <p id="t339" class="pln"><span class="n"><a href="#t339">339</a></span><span class="t"><span class="str">            ``None``.</span>&nbsp;</span><span class="r"></span></p>
    <p id="t340" class="pln"><span class="n"><a href="#t340">340</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t341" class="pln"><span class="n"><a href="#t341">341</a></span><span class="t"><span class="str">    .. note:: Streams are per-device. If the selected stream is not on the</span>&nbsp;</span><span class="r"></span></p>
    <p id="t342" class="pln"><span class="n"><a href="#t342">342</a></span><span class="t"><span class="str">        current device, this function will also change the current device to</span>&nbsp;</span><span class="r"></span></p>
    <p id="t343" class="pln"><span class="n"><a href="#t343">343</a></span><span class="t"><span class="str">        match the stream.</span>&nbsp;</span><span class="r"></span></p>
    <p id="t344" class="pln"><span class="n"><a href="#t344">344</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p id="t345" class="mis show_mis"><span class="n"><a href="#t345">345</a></span><span class="t">    <span class="key">if</span> <span class="nam">stream</span> <span class="key">is</span> <span class="key">None</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t346" class="mis show_mis"><span class="n"><a href="#t346">346</a></span><span class="t">        <span class="key">yield</span>&nbsp;</span><span class="r"></span></p>
    <p id="t347" class="mis show_mis"><span class="n"><a href="#t347">347</a></span><span class="t">        <span class="key">return</span>&nbsp;</span><span class="r"></span></p>
    <p id="t348" class="mis show_mis"><span class="n"><a href="#t348">348</a></span><span class="t">    <span class="nam">src_prev_stream</span> <span class="op">=</span> <span class="nam">current_stream</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t349" class="pln"><span class="n"><a href="#t349">349</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t350" class="mis show_mis"><span class="n"><a href="#t350">350</a></span><span class="t">    <span class="key">if</span> <span class="nam">src_prev_stream</span><span class="op">.</span><span class="nam">device</span> <span class="op">!=</span> <span class="nam">stream</span><span class="op">.</span><span class="nam">device</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t351" class="pln"><span class="n"><a href="#t351">351</a></span><span class="t">        <span class="com"># The given stream is on a different device; have to restore the</span>&nbsp;</span><span class="r"></span></p>
    <p id="t352" class="pln"><span class="n"><a href="#t352">352</a></span><span class="t">        <span class="com"># current_stream on that device on exit as well</span>&nbsp;</span><span class="r"></span></p>
    <p id="t353" class="mis show_mis"><span class="n"><a href="#t353">353</a></span><span class="t">        <span class="key">with</span> <span class="nam">device</span><span class="op">(</span><span class="nam">stream</span><span class="op">.</span><span class="nam">device</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t354" class="mis show_mis"><span class="n"><a href="#t354">354</a></span><span class="t">            <span class="nam">dst_prev_stream</span> <span class="op">=</span> <span class="nam">current_stream</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t355" class="pln"><span class="n"><a href="#t355">355</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t356" class="mis show_mis"><span class="n"><a href="#t356">356</a></span><span class="t">    <span class="nam">torch</span><span class="op">.</span><span class="nam">_C</span><span class="op">.</span><span class="nam">_cuda_setStream</span><span class="op">(</span><span class="nam">stream</span><span class="op">.</span><span class="nam">_cdata</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t357" class="mis show_mis"><span class="n"><a href="#t357">357</a></span><span class="t">    <span class="key">try</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t358" class="mis show_mis"><span class="n"><a href="#t358">358</a></span><span class="t">        <span class="key">yield</span>&nbsp;</span><span class="r"></span></p>
    <p id="t359" class="pln"><span class="n"><a href="#t359">359</a></span><span class="t">    <span class="key">finally</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t360" class="mis show_mis"><span class="n"><a href="#t360">360</a></span><span class="t">        <span class="key">if</span> <span class="nam">src_prev_stream</span><span class="op">.</span><span class="nam">device</span> <span class="op">!=</span> <span class="nam">stream</span><span class="op">.</span><span class="nam">device</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t361" class="mis show_mis"><span class="n"><a href="#t361">361</a></span><span class="t">            <span class="nam">torch</span><span class="op">.</span><span class="nam">_C</span><span class="op">.</span><span class="nam">_cuda_setStream</span><span class="op">(</span><span class="nam">dst_prev_stream</span><span class="op">.</span><span class="nam">_cdata</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t362" class="mis show_mis"><span class="n"><a href="#t362">362</a></span><span class="t">        <span class="nam">torch</span><span class="op">.</span><span class="nam">_C</span><span class="op">.</span><span class="nam">_cuda_setStream</span><span class="op">(</span><span class="nam">src_prev_stream</span><span class="op">.</span><span class="nam">_cdata</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t363" class="pln"><span class="n"><a href="#t363">363</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t364" class="pln"><span class="n"><a href="#t364">364</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t365" class="run"><span class="n"><a href="#t365">365</a></span><span class="t"><span class="key">def</span> <span class="nam">device_count</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t366" class="pln"><span class="n"><a href="#t366">366</a></span><span class="t">    <span class="str">r"""Returns the number of GPUs available."""</span>&nbsp;</span><span class="r"></span></p>
    <p id="t367" class="mis show_mis"><span class="n"><a href="#t367">367</a></span><span class="t">    <span class="key">if</span> <span class="nam">is_available</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t368" class="mis show_mis"><span class="n"><a href="#t368">368</a></span><span class="t">        <span class="key">return</span> <span class="nam">torch</span><span class="op">.</span><span class="nam">_C</span><span class="op">.</span><span class="nam">_cuda_getDeviceCount</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t369" class="pln"><span class="n"><a href="#t369">369</a></span><span class="t">    <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t370" class="mis show_mis"><span class="n"><a href="#t370">370</a></span><span class="t">        <span class="key">return</span> <span class="num">0</span>&nbsp;</span><span class="r"></span></p>
    <p id="t371" class="pln"><span class="n"><a href="#t371">371</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t372" class="pln"><span class="n"><a href="#t372">372</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t373" class="run"><span class="n"><a href="#t373">373</a></span><span class="t"><span class="key">def</span> <span class="nam">current_device</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t374" class="pln"><span class="n"><a href="#t374">374</a></span><span class="t">    <span class="str">r"""Returns the index of a currently selected device."""</span>&nbsp;</span><span class="r"></span></p>
    <p id="t375" class="mis show_mis"><span class="n"><a href="#t375">375</a></span><span class="t">    <span class="nam">_lazy_init</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t376" class="mis show_mis"><span class="n"><a href="#t376">376</a></span><span class="t">    <span class="key">return</span> <span class="nam">torch</span><span class="op">.</span><span class="nam">_C</span><span class="op">.</span><span class="nam">_cuda_getDevice</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t377" class="pln"><span class="n"><a href="#t377">377</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t378" class="pln"><span class="n"><a href="#t378">378</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t379" class="run"><span class="n"><a href="#t379">379</a></span><span class="t"><span class="key">def</span> <span class="nam">synchronize</span><span class="op">(</span><span class="nam">device</span><span class="op">=</span><span class="key">None</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t380" class="pln"><span class="n"><a href="#t380">380</a></span><span class="t">    <span class="str">r"""Waits for all kernels in all streams on a CUDA device to complete.</span>&nbsp;</span><span class="r"></span></p>
    <p id="t381" class="pln"><span class="n"><a href="#t381">381</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t382" class="pln"><span class="n"><a href="#t382">382</a></span><span class="t"><span class="str">    Arguments:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t383" class="pln"><span class="n"><a href="#t383">383</a></span><span class="t"><span class="str">        device (torch.device or int, optional): device for which to synchronize.</span>&nbsp;</span><span class="r"></span></p>
    <p id="t384" class="pln"><span class="n"><a href="#t384">384</a></span><span class="t"><span class="str">            It uses the current device, given by :func:`~torch.cuda.current_device`,</span>&nbsp;</span><span class="r"></span></p>
    <p id="t385" class="pln"><span class="n"><a href="#t385">385</a></span><span class="t"><span class="str">            if :attr:`device` is ``None`` (default).</span>&nbsp;</span><span class="r"></span></p>
    <p id="t386" class="pln"><span class="n"><a href="#t386">386</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p id="t387" class="mis show_mis"><span class="n"><a href="#t387">387</a></span><span class="t">    <span class="nam">_lazy_init</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t388" class="mis show_mis"><span class="n"><a href="#t388">388</a></span><span class="t">    <span class="key">with</span> <span class="nam">torch</span><span class="op">.</span><span class="nam">cuda</span><span class="op">.</span><span class="nam">device</span><span class="op">(</span><span class="nam">device</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t389" class="mis show_mis"><span class="n"><a href="#t389">389</a></span><span class="t">        <span class="key">return</span> <span class="nam">torch</span><span class="op">.</span><span class="nam">_C</span><span class="op">.</span><span class="nam">_cuda_synchronize</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t390" class="pln"><span class="n"><a href="#t390">390</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t391" class="pln"><span class="n"><a href="#t391">391</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t392" class="run"><span class="n"><a href="#t392">392</a></span><span class="t"><span class="key">def</span> <span class="nam">ipc_collect</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t393" class="pln"><span class="n"><a href="#t393">393</a></span><span class="t">    <span class="str">r"""Force collects GPU memory after it has been released by CUDA IPC.</span>&nbsp;</span><span class="r"></span></p>
    <p id="t394" class="pln"><span class="n"><a href="#t394">394</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t395" class="pln"><span class="n"><a href="#t395">395</a></span><span class="t"><span class="str">    .. note::</span>&nbsp;</span><span class="r"></span></p>
    <p id="t396" class="pln"><span class="n"><a href="#t396">396</a></span><span class="t"><span class="str">        Checks if any sent CUDA tensors could be cleaned from the memory. Force</span>&nbsp;</span><span class="r"></span></p>
    <p id="t397" class="pln"><span class="n"><a href="#t397">397</a></span><span class="t"><span class="str">        closes shared memory file used for reference counting if there is no</span>&nbsp;</span><span class="r"></span></p>
    <p id="t398" class="pln"><span class="n"><a href="#t398">398</a></span><span class="t"><span class="str">        active counters. Useful when the producer process stopped actively sending</span>&nbsp;</span><span class="r"></span></p>
    <p id="t399" class="pln"><span class="n"><a href="#t399">399</a></span><span class="t"><span class="str">        tensors and want to release unused memory.</span>&nbsp;</span><span class="r"></span></p>
    <p id="t400" class="pln"><span class="n"><a href="#t400">400</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p id="t401" class="mis show_mis"><span class="n"><a href="#t401">401</a></span><span class="t">    <span class="nam">_lazy_init</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t402" class="mis show_mis"><span class="n"><a href="#t402">402</a></span><span class="t">    <span class="key">return</span> <span class="nam">torch</span><span class="op">.</span><span class="nam">_C</span><span class="op">.</span><span class="nam">_cuda_ipc_collect</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t403" class="pln"><span class="n"><a href="#t403">403</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t404" class="pln"><span class="n"><a href="#t404">404</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t405" class="run"><span class="n"><a href="#t405">405</a></span><span class="t"><span class="key">def</span> <span class="nam">current_stream</span><span class="op">(</span><span class="nam">device</span><span class="op">=</span><span class="key">None</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t406" class="pln"><span class="n"><a href="#t406">406</a></span><span class="t">    <span class="str">r"""Returns the currently selected :class:`Stream` for a given device.</span>&nbsp;</span><span class="r"></span></p>
    <p id="t407" class="pln"><span class="n"><a href="#t407">407</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t408" class="pln"><span class="n"><a href="#t408">408</a></span><span class="t"><span class="str">    Arguments:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t409" class="pln"><span class="n"><a href="#t409">409</a></span><span class="t"><span class="str">        device (torch.device or int, optional): selected device. Returns</span>&nbsp;</span><span class="r"></span></p>
    <p id="t410" class="pln"><span class="n"><a href="#t410">410</a></span><span class="t"><span class="str">            the currently selected :class:`Stream` for the current device, given</span>&nbsp;</span><span class="r"></span></p>
    <p id="t411" class="pln"><span class="n"><a href="#t411">411</a></span><span class="t"><span class="str">            by :func:`~torch.cuda.current_device`, if :attr:`device` is ``None``</span>&nbsp;</span><span class="r"></span></p>
    <p id="t412" class="pln"><span class="n"><a href="#t412">412</a></span><span class="t"><span class="str">            (default).</span>&nbsp;</span><span class="r"></span></p>
    <p id="t413" class="pln"><span class="n"><a href="#t413">413</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p id="t414" class="mis show_mis"><span class="n"><a href="#t414">414</a></span><span class="t">    <span class="nam">_lazy_init</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t415" class="mis show_mis"><span class="n"><a href="#t415">415</a></span><span class="t">    <span class="key">return</span> <span class="nam">torch</span><span class="op">.</span><span class="nam">cuda</span><span class="op">.</span><span class="nam">Stream</span><span class="op">(</span><span class="nam">_cdata</span><span class="op">=</span><span class="nam">torch</span><span class="op">.</span><span class="nam">_C</span><span class="op">.</span><span class="nam">_cuda_getCurrentStream</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p id="t416" class="pln"><span class="n"><a href="#t416">416</a></span><span class="t">        <span class="nam">_get_device_index</span><span class="op">(</span><span class="nam">device</span><span class="op">,</span> <span class="nam">optional</span><span class="op">=</span><span class="key">True</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t417" class="pln"><span class="n"><a href="#t417">417</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t418" class="pln"><span class="n"><a href="#t418">418</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t419" class="run"><span class="n"><a href="#t419">419</a></span><span class="t"><span class="key">def</span> <span class="nam">default_stream</span><span class="op">(</span><span class="nam">device</span><span class="op">=</span><span class="key">None</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t420" class="pln"><span class="n"><a href="#t420">420</a></span><span class="t">    <span class="str">r"""Returns the default :class:`Stream` for a given device.</span>&nbsp;</span><span class="r"></span></p>
    <p id="t421" class="pln"><span class="n"><a href="#t421">421</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t422" class="pln"><span class="n"><a href="#t422">422</a></span><span class="t"><span class="str">    Arguments:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t423" class="pln"><span class="n"><a href="#t423">423</a></span><span class="t"><span class="str">        device (torch.device or int, optional): selected device. Returns</span>&nbsp;</span><span class="r"></span></p>
    <p id="t424" class="pln"><span class="n"><a href="#t424">424</a></span><span class="t"><span class="str">            the default :class:`Stream` for the current device, given by</span>&nbsp;</span><span class="r"></span></p>
    <p id="t425" class="pln"><span class="n"><a href="#t425">425</a></span><span class="t"><span class="str">            :func:`~torch.cuda.current_device`, if :attr:`device` is ``None``</span>&nbsp;</span><span class="r"></span></p>
    <p id="t426" class="pln"><span class="n"><a href="#t426">426</a></span><span class="t"><span class="str">            (default).</span>&nbsp;</span><span class="r"></span></p>
    <p id="t427" class="pln"><span class="n"><a href="#t427">427</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p id="t428" class="mis show_mis"><span class="n"><a href="#t428">428</a></span><span class="t">    <span class="nam">_lazy_init</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t429" class="mis show_mis"><span class="n"><a href="#t429">429</a></span><span class="t">    <span class="key">return</span> <span class="nam">torch</span><span class="op">.</span><span class="nam">cuda</span><span class="op">.</span><span class="nam">Stream</span><span class="op">(</span><span class="nam">_cdata</span><span class="op">=</span><span class="nam">torch</span><span class="op">.</span><span class="nam">_C</span><span class="op">.</span><span class="nam">_cuda_getDefaultStream</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p id="t430" class="pln"><span class="n"><a href="#t430">430</a></span><span class="t">        <span class="nam">_get_device_index</span><span class="op">(</span><span class="nam">device</span><span class="op">,</span> <span class="nam">optional</span><span class="op">=</span><span class="key">True</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t431" class="pln"><span class="n"><a href="#t431">431</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t432" class="pln"><span class="n"><a href="#t432">432</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t433" class="run"><span class="n"><a href="#t433">433</a></span><span class="t"><span class="key">def</span> <span class="nam">current_blas_handle</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t434" class="pln"><span class="n"><a href="#t434">434</a></span><span class="t">    <span class="str">r"""Returns cublasHandle_t pointer to current cuBLAS handle"""</span>&nbsp;</span><span class="r"></span></p>
    <p id="t435" class="mis show_mis"><span class="n"><a href="#t435">435</a></span><span class="t">    <span class="nam">_lazy_init</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t436" class="mis show_mis"><span class="n"><a href="#t436">436</a></span><span class="t">    <span class="key">return</span> <span class="nam">torch</span><span class="op">.</span><span class="nam">_C</span><span class="op">.</span><span class="nam">_cuda_getCurrentBlasHandle</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t437" class="pln"><span class="n"><a href="#t437">437</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t438" class="pln"><span class="n"><a href="#t438">438</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t439" class="run"><span class="n"><a href="#t439">439</a></span><span class="t"><span class="key">from</span> <span class="op">.</span><span class="nam">memory</span> <span class="key">import</span> <span class="op">*</span>&nbsp;</span><span class="r"></span></p>
    <p id="t440" class="pln"><span class="n"><a href="#t440">440</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t441" class="pln"><span class="n"><a href="#t441">441</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t442" class="run"><span class="n"><a href="#t442">442</a></span><span class="t"><span class="key">from</span> <span class="op">.</span><span class="nam">random</span> <span class="key">import</span> <span class="op">*</span>&nbsp;</span><span class="r"></span></p>
    <p id="t443" class="pln"><span class="n"><a href="#t443">443</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t444" class="pln"><span class="n"><a href="#t444">444</a></span><span class="t"><span class="com">################################################################################</span>&nbsp;</span><span class="r"></span></p>
    <p id="t445" class="pln"><span class="n"><a href="#t445">445</a></span><span class="t"><span class="com"># Define Storage and Tensor classes</span>&nbsp;</span><span class="r"></span></p>
    <p id="t446" class="pln"><span class="n"><a href="#t446">446</a></span><span class="t"><span class="com">################################################################################</span>&nbsp;</span><span class="r"></span></p>
    <p id="t447" class="pln"><span class="n"><a href="#t447">447</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t448" class="pln"><span class="n"><a href="#t448">448</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t449" class="run"><span class="n"><a href="#t449">449</a></span><span class="t"><span class="key">from</span> <span class="op">.</span><span class="op">.</span><span class="nam">storage</span> <span class="key">import</span> <span class="nam">_StorageBase</span>&nbsp;</span><span class="r"></span></p>
    <p id="t450" class="pln"><span class="n"><a href="#t450">450</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t451" class="pln"><span class="n"><a href="#t451">451</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t452" class="run"><span class="n"><a href="#t452">452</a></span><span class="t"><span class="key">def</span> <span class="nam">_dummy_type</span><span class="op">(</span><span class="nam">name</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t453" class="run"><span class="n"><a href="#t453">453</a></span><span class="t">    <span class="key">def</span> <span class="nam">init_err</span><span class="op">(</span><span class="nam">self</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t454" class="mis show_mis"><span class="n"><a href="#t454">454</a></span><span class="t">        <span class="nam">class_name</span> <span class="op">=</span> <span class="nam">self</span><span class="op">.</span><span class="nam">__class__</span><span class="op">.</span><span class="nam">__name__</span>&nbsp;</span><span class="r"></span></p>
    <p id="t455" class="mis show_mis"><span class="n"><a href="#t455">455</a></span><span class="t">        <span class="key">raise</span> <span class="nam">RuntimeError</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p id="t456" class="pln"><span class="n"><a href="#t456">456</a></span><span class="t">            <span class="str">"Tried to instantiate dummy base class {}"</span><span class="op">.</span><span class="nam">format</span><span class="op">(</span><span class="nam">class_name</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t457" class="run"><span class="n"><a href="#t457">457</a></span><span class="t">    <span class="key">return</span> <span class="nam">type</span><span class="op">(</span><span class="nam">storage_name</span><span class="op">,</span> <span class="op">(</span><span class="nam">object</span><span class="op">,</span><span class="op">)</span><span class="op">,</span> <span class="op">{</span><span class="str">"__init__"</span><span class="op">:</span> <span class="nam">init_err</span><span class="op">}</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t458" class="pln"><span class="n"><a href="#t458">458</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t459" class="pln"><span class="n"><a href="#t459">459</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t460" class="run"><span class="n"><a href="#t460">460</a></span><span class="t"><span class="key">if</span> <span class="key">not</span> <span class="nam">hasattr</span><span class="op">(</span><span class="nam">torch</span><span class="op">.</span><span class="nam">_C</span><span class="op">,</span> <span class="str">'CudaDoubleStorageBase'</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t461" class="pln"><span class="n"><a href="#t461">461</a></span><span class="t">    <span class="com"># Define dummy base classes</span>&nbsp;</span><span class="r"></span></p>
    <p id="t462" class="run"><span class="n"><a href="#t462">462</a></span><span class="t">    <span class="key">for</span> <span class="nam">t</span> <span class="key">in</span> <span class="op">[</span><span class="str">'Double'</span><span class="op">,</span> <span class="str">'Float'</span><span class="op">,</span> <span class="str">'Long'</span><span class="op">,</span> <span class="str">'Int'</span><span class="op">,</span> <span class="str">'Short'</span><span class="op">,</span> <span class="str">'Char'</span><span class="op">,</span> <span class="str">'Byte'</span><span class="op">,</span> <span class="str">'Half'</span><span class="op">,</span> <span class="str">'Bool'</span><span class="op">,</span> <span class="str">'BFloat16'</span><span class="op">]</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t463" class="run"><span class="n"><a href="#t463">463</a></span><span class="t">        <span class="nam">storage_name</span> <span class="op">=</span> <span class="str">'Cuda{0}StorageBase'</span><span class="op">.</span><span class="nam">format</span><span class="op">(</span><span class="nam">t</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t464" class="run"><span class="n"><a href="#t464">464</a></span><span class="t">        <span class="nam">tensor_name</span> <span class="op">=</span> <span class="str">'Cuda{0}TensorBase'</span><span class="op">.</span><span class="nam">format</span><span class="op">(</span><span class="nam">t</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t465" class="pln"><span class="n"><a href="#t465">465</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t466" class="run"><span class="n"><a href="#t466">466</a></span><span class="t">        <span class="nam">torch</span><span class="op">.</span><span class="nam">_C</span><span class="op">.</span><span class="nam">__dict__</span><span class="op">[</span><span class="nam">storage_name</span><span class="op">]</span> <span class="op">=</span> <span class="nam">_dummy_type</span><span class="op">(</span><span class="nam">storage_name</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t467" class="run"><span class="n"><a href="#t467">467</a></span><span class="t">        <span class="nam">torch</span><span class="op">.</span><span class="nam">_C</span><span class="op">.</span><span class="nam">__dict__</span><span class="op">[</span><span class="nam">tensor_name</span><span class="op">]</span> <span class="op">=</span> <span class="nam">_dummy_type</span><span class="op">(</span><span class="nam">tensor_name</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t468" class="pln"><span class="n"><a href="#t468">468</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t469" class="run"><span class="n"><a href="#t469">469</a></span><span class="t">    <span class="nam">torch</span><span class="op">.</span><span class="nam">_C</span><span class="op">.</span><span class="nam">__dict__</span><span class="op">[</span><span class="str">'_CudaStreamBase'</span><span class="op">]</span> <span class="op">=</span> <span class="nam">_dummy_type</span><span class="op">(</span><span class="str">'CudaStreamBase'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t470" class="run"><span class="n"><a href="#t470">470</a></span><span class="t">    <span class="nam">torch</span><span class="op">.</span><span class="nam">_C</span><span class="op">.</span><span class="nam">__dict__</span><span class="op">[</span><span class="str">'_CudaEventBase'</span><span class="op">]</span> <span class="op">=</span> <span class="nam">_dummy_type</span><span class="op">(</span><span class="str">'CudaEventBase'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t471" class="pln"><span class="n"><a href="#t471">471</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t472" class="pln"><span class="n"><a href="#t472">472</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t473" class="run"><span class="n"><a href="#t473">473</a></span><span class="t"><span class="op">@</span><span class="nam">staticmethod</span>&nbsp;</span><span class="r"></span></p>
    <p id="t474" class="pln"><span class="n"><a href="#t474">474</a></span><span class="t"><span class="key">def</span> <span class="nam">_lazy_new</span><span class="op">(</span><span class="nam">cls</span><span class="op">,</span> <span class="op">*</span><span class="nam">args</span><span class="op">,</span> <span class="op">**</span><span class="nam">kwargs</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t475" class="mis show_mis"><span class="n"><a href="#t475">475</a></span><span class="t">    <span class="nam">_lazy_init</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t476" class="pln"><span class="n"><a href="#t476">476</a></span><span class="t">    <span class="com"># We may need to call lazy init again if we are a forked child</span>&nbsp;</span><span class="r"></span></p>
    <p id="t477" class="pln"><span class="n"><a href="#t477">477</a></span><span class="t">    <span class="com"># del _CudaBase.__new__</span>&nbsp;</span><span class="r"></span></p>
    <p id="t478" class="mis show_mis"><span class="n"><a href="#t478">478</a></span><span class="t">    <span class="key">return</span> <span class="nam">super</span><span class="op">(</span><span class="nam">_CudaBase</span><span class="op">,</span> <span class="nam">cls</span><span class="op">)</span><span class="op">.</span><span class="nam">__new__</span><span class="op">(</span><span class="nam">cls</span><span class="op">,</span> <span class="op">*</span><span class="nam">args</span><span class="op">,</span> <span class="op">**</span><span class="nam">kwargs</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t479" class="pln"><span class="n"><a href="#t479">479</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t480" class="pln"><span class="n"><a href="#t480">480</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t481" class="run"><span class="n"><a href="#t481">481</a></span><span class="t"><span class="key">class</span> <span class="nam">_CudaBase</span><span class="op">(</span><span class="nam">object</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t482" class="run"><span class="n"><a href="#t482">482</a></span><span class="t">    <span class="nam">is_cuda</span> <span class="op">=</span> <span class="key">True</span>&nbsp;</span><span class="r"></span></p>
    <p id="t483" class="run"><span class="n"><a href="#t483">483</a></span><span class="t">    <span class="nam">is_sparse</span> <span class="op">=</span> <span class="key">False</span>&nbsp;</span><span class="r"></span></p>
    <p id="t484" class="pln"><span class="n"><a href="#t484">484</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t485" class="run"><span class="n"><a href="#t485">485</a></span><span class="t">    <span class="key">def</span> <span class="nam">type</span><span class="op">(</span><span class="nam">self</span><span class="op">,</span> <span class="op">*</span><span class="nam">args</span><span class="op">,</span> <span class="op">**</span><span class="nam">kwargs</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t486" class="mis show_mis"><span class="n"><a href="#t486">486</a></span><span class="t">        <span class="key">with</span> <span class="nam">device</span><span class="op">(</span><span class="nam">self</span><span class="op">.</span><span class="nam">get_device</span><span class="op">(</span><span class="op">)</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t487" class="mis show_mis"><span class="n"><a href="#t487">487</a></span><span class="t">            <span class="key">return</span> <span class="nam">super</span><span class="op">(</span><span class="nam">_CudaBase</span><span class="op">,</span> <span class="nam">self</span><span class="op">)</span><span class="op">.</span><span class="nam">type</span><span class="op">(</span><span class="op">*</span><span class="nam">args</span><span class="op">,</span> <span class="op">**</span><span class="nam">kwargs</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t488" class="pln"><span class="n"><a href="#t488">488</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t489" class="run"><span class="n"><a href="#t489">489</a></span><span class="t">    <span class="nam">__new__</span> <span class="op">=</span> <span class="nam">_lazy_new</span>&nbsp;</span><span class="r"></span></p>
    <p id="t490" class="pln"><span class="n"><a href="#t490">490</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t491" class="pln"><span class="n"><a href="#t491">491</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t492" class="run"><span class="n"><a href="#t492">492</a></span><span class="t"><span class="key">class</span> <span class="nam">DoubleStorage</span><span class="op">(</span><span class="nam">_CudaBase</span><span class="op">,</span> <span class="nam">torch</span><span class="op">.</span><span class="nam">_C</span><span class="op">.</span><span class="nam">CudaDoubleStorageBase</span><span class="op">,</span> <span class="nam">_StorageBase</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t493" class="run"><span class="n"><a href="#t493">493</a></span><span class="t">    <span class="key">pass</span>&nbsp;</span><span class="r"></span></p>
    <p id="t494" class="pln"><span class="n"><a href="#t494">494</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t495" class="pln"><span class="n"><a href="#t495">495</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t496" class="run"><span class="n"><a href="#t496">496</a></span><span class="t"><span class="key">class</span> <span class="nam">FloatStorage</span><span class="op">(</span><span class="nam">_CudaBase</span><span class="op">,</span> <span class="nam">torch</span><span class="op">.</span><span class="nam">_C</span><span class="op">.</span><span class="nam">CudaFloatStorageBase</span><span class="op">,</span> <span class="nam">_StorageBase</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t497" class="run"><span class="n"><a href="#t497">497</a></span><span class="t">    <span class="key">pass</span>&nbsp;</span><span class="r"></span></p>
    <p id="t498" class="pln"><span class="n"><a href="#t498">498</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t499" class="pln"><span class="n"><a href="#t499">499</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t500" class="run"><span class="n"><a href="#t500">500</a></span><span class="t"><span class="key">class</span> <span class="nam">LongStorage</span><span class="op">(</span><span class="nam">_CudaBase</span><span class="op">,</span> <span class="nam">torch</span><span class="op">.</span><span class="nam">_C</span><span class="op">.</span><span class="nam">CudaLongStorageBase</span><span class="op">,</span> <span class="nam">_StorageBase</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t501" class="run"><span class="n"><a href="#t501">501</a></span><span class="t">    <span class="key">pass</span>&nbsp;</span><span class="r"></span></p>
    <p id="t502" class="pln"><span class="n"><a href="#t502">502</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t503" class="pln"><span class="n"><a href="#t503">503</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t504" class="run"><span class="n"><a href="#t504">504</a></span><span class="t"><span class="key">class</span> <span class="nam">IntStorage</span><span class="op">(</span><span class="nam">_CudaBase</span><span class="op">,</span> <span class="nam">torch</span><span class="op">.</span><span class="nam">_C</span><span class="op">.</span><span class="nam">CudaIntStorageBase</span><span class="op">,</span> <span class="nam">_StorageBase</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t505" class="run"><span class="n"><a href="#t505">505</a></span><span class="t">    <span class="key">pass</span>&nbsp;</span><span class="r"></span></p>
    <p id="t506" class="pln"><span class="n"><a href="#t506">506</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t507" class="pln"><span class="n"><a href="#t507">507</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t508" class="run"><span class="n"><a href="#t508">508</a></span><span class="t"><span class="key">class</span> <span class="nam">ShortStorage</span><span class="op">(</span><span class="nam">_CudaBase</span><span class="op">,</span> <span class="nam">torch</span><span class="op">.</span><span class="nam">_C</span><span class="op">.</span><span class="nam">CudaShortStorageBase</span><span class="op">,</span> <span class="nam">_StorageBase</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t509" class="run"><span class="n"><a href="#t509">509</a></span><span class="t">    <span class="key">pass</span>&nbsp;</span><span class="r"></span></p>
    <p id="t510" class="pln"><span class="n"><a href="#t510">510</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t511" class="pln"><span class="n"><a href="#t511">511</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t512" class="run"><span class="n"><a href="#t512">512</a></span><span class="t"><span class="key">class</span> <span class="nam">CharStorage</span><span class="op">(</span><span class="nam">_CudaBase</span><span class="op">,</span> <span class="nam">torch</span><span class="op">.</span><span class="nam">_C</span><span class="op">.</span><span class="nam">CudaCharStorageBase</span><span class="op">,</span> <span class="nam">_StorageBase</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t513" class="run"><span class="n"><a href="#t513">513</a></span><span class="t">    <span class="key">pass</span>&nbsp;</span><span class="r"></span></p>
    <p id="t514" class="pln"><span class="n"><a href="#t514">514</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t515" class="pln"><span class="n"><a href="#t515">515</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t516" class="run"><span class="n"><a href="#t516">516</a></span><span class="t"><span class="key">class</span> <span class="nam">ByteStorage</span><span class="op">(</span><span class="nam">_CudaBase</span><span class="op">,</span> <span class="nam">torch</span><span class="op">.</span><span class="nam">_C</span><span class="op">.</span><span class="nam">CudaByteStorageBase</span><span class="op">,</span> <span class="nam">_StorageBase</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t517" class="run"><span class="n"><a href="#t517">517</a></span><span class="t">    <span class="key">pass</span>&nbsp;</span><span class="r"></span></p>
    <p id="t518" class="pln"><span class="n"><a href="#t518">518</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t519" class="pln"><span class="n"><a href="#t519">519</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t520" class="run"><span class="n"><a href="#t520">520</a></span><span class="t"><span class="key">class</span> <span class="nam">HalfStorage</span><span class="op">(</span><span class="nam">_CudaBase</span><span class="op">,</span> <span class="nam">torch</span><span class="op">.</span><span class="nam">_C</span><span class="op">.</span><span class="nam">CudaHalfStorageBase</span><span class="op">,</span> <span class="nam">_StorageBase</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t521" class="run"><span class="n"><a href="#t521">521</a></span><span class="t">    <span class="key">pass</span>&nbsp;</span><span class="r"></span></p>
    <p id="t522" class="pln"><span class="n"><a href="#t522">522</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t523" class="pln"><span class="n"><a href="#t523">523</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t524" class="run"><span class="n"><a href="#t524">524</a></span><span class="t"><span class="key">class</span> <span class="nam">BoolStorage</span><span class="op">(</span><span class="nam">_CudaBase</span><span class="op">,</span> <span class="nam">torch</span><span class="op">.</span><span class="nam">_C</span><span class="op">.</span><span class="nam">CudaBoolStorageBase</span><span class="op">,</span> <span class="nam">_StorageBase</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t525" class="run"><span class="n"><a href="#t525">525</a></span><span class="t">    <span class="key">pass</span>&nbsp;</span><span class="r"></span></p>
    <p id="t526" class="pln"><span class="n"><a href="#t526">526</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t527" class="pln"><span class="n"><a href="#t527">527</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t528" class="run"><span class="n"><a href="#t528">528</a></span><span class="t"><span class="key">class</span> <span class="nam">BFloat16Storage</span><span class="op">(</span><span class="nam">_CudaBase</span><span class="op">,</span> <span class="nam">torch</span><span class="op">.</span><span class="nam">_C</span><span class="op">.</span><span class="nam">CudaBFloat16StorageBase</span><span class="op">,</span> <span class="nam">_StorageBase</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t529" class="run"><span class="n"><a href="#t529">529</a></span><span class="t">    <span class="key">pass</span>&nbsp;</span><span class="r"></span></p>
    <p id="t530" class="pln"><span class="n"><a href="#t530">530</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t531" class="run"><span class="n"><a href="#t531">531</a></span><span class="t"><span class="nam">torch</span><span class="op">.</span><span class="nam">_storage_classes</span><span class="op">.</span><span class="nam">add</span><span class="op">(</span><span class="nam">DoubleStorage</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t532" class="run"><span class="n"><a href="#t532">532</a></span><span class="t"><span class="nam">torch</span><span class="op">.</span><span class="nam">_storage_classes</span><span class="op">.</span><span class="nam">add</span><span class="op">(</span><span class="nam">FloatStorage</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t533" class="run"><span class="n"><a href="#t533">533</a></span><span class="t"><span class="nam">torch</span><span class="op">.</span><span class="nam">_storage_classes</span><span class="op">.</span><span class="nam">add</span><span class="op">(</span><span class="nam">LongStorage</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t534" class="run"><span class="n"><a href="#t534">534</a></span><span class="t"><span class="nam">torch</span><span class="op">.</span><span class="nam">_storage_classes</span><span class="op">.</span><span class="nam">add</span><span class="op">(</span><span class="nam">IntStorage</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t535" class="run"><span class="n"><a href="#t535">535</a></span><span class="t"><span class="nam">torch</span><span class="op">.</span><span class="nam">_storage_classes</span><span class="op">.</span><span class="nam">add</span><span class="op">(</span><span class="nam">ShortStorage</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t536" class="run"><span class="n"><a href="#t536">536</a></span><span class="t"><span class="nam">torch</span><span class="op">.</span><span class="nam">_storage_classes</span><span class="op">.</span><span class="nam">add</span><span class="op">(</span><span class="nam">CharStorage</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t537" class="run"><span class="n"><a href="#t537">537</a></span><span class="t"><span class="nam">torch</span><span class="op">.</span><span class="nam">_storage_classes</span><span class="op">.</span><span class="nam">add</span><span class="op">(</span><span class="nam">ByteStorage</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t538" class="run"><span class="n"><a href="#t538">538</a></span><span class="t"><span class="nam">torch</span><span class="op">.</span><span class="nam">_storage_classes</span><span class="op">.</span><span class="nam">add</span><span class="op">(</span><span class="nam">HalfStorage</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t539" class="run"><span class="n"><a href="#t539">539</a></span><span class="t"><span class="nam">torch</span><span class="op">.</span><span class="nam">_storage_classes</span><span class="op">.</span><span class="nam">add</span><span class="op">(</span><span class="nam">BoolStorage</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t540" class="run"><span class="n"><a href="#t540">540</a></span><span class="t"><span class="nam">torch</span><span class="op">.</span><span class="nam">_storage_classes</span><span class="op">.</span><span class="nam">add</span><span class="op">(</span><span class="nam">BFloat16Storage</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t541" class="pln"><span class="n"><a href="#t541">541</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t542" class="run"><span class="n"><a href="#t542">542</a></span><span class="t"><span class="key">from</span> <span class="op">.</span> <span class="key">import</span> <span class="nam">sparse</span>&nbsp;</span><span class="r"></span></p>
    <p id="t543" class="run"><span class="n"><a href="#t543">543</a></span><span class="t"><span class="key">from</span> <span class="op">.</span> <span class="key">import</span> <span class="nam">profiler</span>&nbsp;</span><span class="r"></span></p>
    <p id="t544" class="run"><span class="n"><a href="#t544">544</a></span><span class="t"><span class="key">from</span> <span class="op">.</span> <span class="key">import</span> <span class="nam">nvtx</span>&nbsp;</span><span class="r"></span></p>
    <p id="t545" class="run"><span class="n"><a href="#t545">545</a></span><span class="t"><span class="key">from</span> <span class="op">.</span><span class="nam">streams</span> <span class="key">import</span> <span class="nam">Stream</span><span class="op">,</span> <span class="nam">Event</span>&nbsp;</span><span class="r"></span></p>
</div>
<div id="footer">
    <div class="content">
        <p>
            <a class="nav" href="index.html">&#xab; index</a> &nbsp; &nbsp; <a class="nav" href="https://coverage.readthedocs.io">coverage.py v5.0.3</a>,
            created at 2020-03-12 23:04
        </p>
    </div>
</div>
</body>
</html>
