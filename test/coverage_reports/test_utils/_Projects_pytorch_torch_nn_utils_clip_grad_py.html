<!DOCTYPE html>
<html>
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=emulateIE7" />
    <title>Coverage for C:\Projects\pytorch\torch\nn\utils\clip_grad.py: 0%</title>
    <link rel="stylesheet" href="style.css" type="text/css">
    <script type="text/javascript" src="jquery.min.js"></script>
    <script type="text/javascript" src="jquery.hotkeys.js"></script>
    <script type="text/javascript" src="jquery.isonscreen.js"></script>
    <script type="text/javascript" src="coverage_html.js"></script>
    <script type="text/javascript">
        jQuery(document).ready(coverage.pyfile_ready);
    </script>
</head>
<body class="pyfile">
<div id="header">
    <div class="content">
        <h1>Coverage for <b>C:\Projects\pytorch\torch\nn\utils\clip_grad.py</b> :
            <span class="pc_cov">0%</span>
        </h1>
        <img id="keyboard_icon" src="keybd_closed.png" alt="Show keyboard shortcuts" />
        <h2 class="stats">
            26 statements &nbsp;
            <span class="run shortkey_r button_toggle_run">0 run</span>
            <span class="mis show_mis shortkey_m button_toggle_mis">26 missing</span>
            <span class="exc show_exc shortkey_x button_toggle_exc">0 excluded</span>
        </h2>
    </div>
</div>
<div class="help_panel">
    <img id="panel_icon" src="keybd_open.png" alt="Hide keyboard shortcuts" />
    <p class="legend">Hot-keys on this page</p>
    <div>
    <p class="keyhelp">
        <span class="key">r</span>
        <span class="key">m</span>
        <span class="key">x</span>
        <span class="key">p</span> &nbsp; toggle line displays
    </p>
    <p class="keyhelp">
        <span class="key">j</span>
        <span class="key">k</span> &nbsp; next/prev highlighted chunk
    </p>
    <p class="keyhelp">
        <span class="key">0</span> &nbsp; (zero) top of page
    </p>
    <p class="keyhelp">
        <span class="key">1</span> &nbsp; (one) first highlighted chunk
    </p>
    </div>
</div>
<div id="source">
    <p id="t1" class="mis show_mis"><span class="n"><a href="#t1">1</a></span><span class="t"><span class="key">import</span> <span class="nam">warnings</span>&nbsp;</span><span class="r"></span></p>
    <p id="t2" class="mis show_mis"><span class="n"><a href="#t2">2</a></span><span class="t"><span class="key">import</span> <span class="nam">torch</span>&nbsp;</span><span class="r"></span></p>
    <p id="t3" class="mis show_mis"><span class="n"><a href="#t3">3</a></span><span class="t"><span class="key">from</span> <span class="nam">torch</span><span class="op">.</span><span class="nam">_six</span> <span class="key">import</span> <span class="nam">inf</span>&nbsp;</span><span class="r"></span></p>
    <p id="t4" class="pln"><span class="n"><a href="#t4">4</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t5" class="pln"><span class="n"><a href="#t5">5</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t6" class="mis show_mis"><span class="n"><a href="#t6">6</a></span><span class="t"><span class="key">def</span> <span class="nam">clip_grad_norm_</span><span class="op">(</span><span class="nam">parameters</span><span class="op">,</span> <span class="nam">max_norm</span><span class="op">,</span> <span class="nam">norm_type</span><span class="op">=</span><span class="num">2</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t7" class="pln"><span class="n"><a href="#t7">7</a></span><span class="t">    <span class="str">r"""Clips gradient norm of an iterable of parameters.</span>&nbsp;</span><span class="r"></span></p>
    <p id="t8" class="pln"><span class="n"><a href="#t8">8</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t9" class="pln"><span class="n"><a href="#t9">9</a></span><span class="t"><span class="str">    The norm is computed over all gradients together, as if they were</span>&nbsp;</span><span class="r"></span></p>
    <p id="t10" class="pln"><span class="n"><a href="#t10">10</a></span><span class="t"><span class="str">    concatenated into a single vector. Gradients are modified in-place.</span>&nbsp;</span><span class="r"></span></p>
    <p id="t11" class="pln"><span class="n"><a href="#t11">11</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t12" class="pln"><span class="n"><a href="#t12">12</a></span><span class="t"><span class="str">    Arguments:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t13" class="pln"><span class="n"><a href="#t13">13</a></span><span class="t"><span class="str">        parameters (Iterable[Tensor] or Tensor): an iterable of Tensors or a</span>&nbsp;</span><span class="r"></span></p>
    <p id="t14" class="pln"><span class="n"><a href="#t14">14</a></span><span class="t"><span class="str">            single Tensor that will have gradients normalized</span>&nbsp;</span><span class="r"></span></p>
    <p id="t15" class="pln"><span class="n"><a href="#t15">15</a></span><span class="t"><span class="str">        max_norm (float or int): max norm of the gradients</span>&nbsp;</span><span class="r"></span></p>
    <p id="t16" class="pln"><span class="n"><a href="#t16">16</a></span><span class="t"><span class="str">        norm_type (float or int): type of the used p-norm. Can be ``'inf'`` for</span>&nbsp;</span><span class="r"></span></p>
    <p id="t17" class="pln"><span class="n"><a href="#t17">17</a></span><span class="t"><span class="str">            infinity norm.</span>&nbsp;</span><span class="r"></span></p>
    <p id="t18" class="pln"><span class="n"><a href="#t18">18</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t19" class="pln"><span class="n"><a href="#t19">19</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t20" class="pln"><span class="n"><a href="#t20">20</a></span><span class="t"><span class="str">        Total norm of the parameters (viewed as a single vector).</span>&nbsp;</span><span class="r"></span></p>
    <p id="t21" class="pln"><span class="n"><a href="#t21">21</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p id="t22" class="mis show_mis"><span class="n"><a href="#t22">22</a></span><span class="t">    <span class="key">if</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">parameters</span><span class="op">,</span> <span class="nam">torch</span><span class="op">.</span><span class="nam">Tensor</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t23" class="mis show_mis"><span class="n"><a href="#t23">23</a></span><span class="t">        <span class="nam">parameters</span> <span class="op">=</span> <span class="op">[</span><span class="nam">parameters</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p id="t24" class="mis show_mis"><span class="n"><a href="#t24">24</a></span><span class="t">    <span class="nam">parameters</span> <span class="op">=</span> <span class="nam">list</span><span class="op">(</span><span class="nam">filter</span><span class="op">(</span><span class="key">lambda</span> <span class="nam">p</span><span class="op">:</span> <span class="nam">p</span><span class="op">.</span><span class="nam">grad</span> <span class="key">is</span> <span class="key">not</span> <span class="key">None</span><span class="op">,</span> <span class="nam">parameters</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t25" class="mis show_mis"><span class="n"><a href="#t25">25</a></span><span class="t">    <span class="nam">max_norm</span> <span class="op">=</span> <span class="nam">float</span><span class="op">(</span><span class="nam">max_norm</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t26" class="mis show_mis"><span class="n"><a href="#t26">26</a></span><span class="t">    <span class="nam">norm_type</span> <span class="op">=</span> <span class="nam">float</span><span class="op">(</span><span class="nam">norm_type</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t27" class="mis show_mis"><span class="n"><a href="#t27">27</a></span><span class="t">    <span class="key">if</span> <span class="nam">norm_type</span> <span class="op">==</span> <span class="nam">inf</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t28" class="mis show_mis"><span class="n"><a href="#t28">28</a></span><span class="t">        <span class="nam">total_norm</span> <span class="op">=</span> <span class="nam">max</span><span class="op">(</span><span class="nam">p</span><span class="op">.</span><span class="nam">grad</span><span class="op">.</span><span class="nam">detach</span><span class="op">(</span><span class="op">)</span><span class="op">.</span><span class="nam">abs</span><span class="op">(</span><span class="op">)</span><span class="op">.</span><span class="nam">max</span><span class="op">(</span><span class="op">)</span> <span class="key">for</span> <span class="nam">p</span> <span class="key">in</span> <span class="nam">parameters</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t29" class="pln"><span class="n"><a href="#t29">29</a></span><span class="t">    <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t30" class="mis show_mis"><span class="n"><a href="#t30">30</a></span><span class="t">        <span class="nam">total_norm</span> <span class="op">=</span> <span class="nam">torch</span><span class="op">.</span><span class="nam">norm</span><span class="op">(</span><span class="nam">torch</span><span class="op">.</span><span class="nam">stack</span><span class="op">(</span><span class="op">[</span><span class="nam">torch</span><span class="op">.</span><span class="nam">norm</span><span class="op">(</span><span class="nam">p</span><span class="op">.</span><span class="nam">grad</span><span class="op">.</span><span class="nam">detach</span><span class="op">(</span><span class="op">)</span><span class="op">,</span> <span class="nam">norm_type</span><span class="op">)</span> <span class="key">for</span> <span class="nam">p</span> <span class="key">in</span> <span class="nam">parameters</span><span class="op">]</span><span class="op">)</span><span class="op">,</span> <span class="nam">norm_type</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t31" class="mis show_mis"><span class="n"><a href="#t31">31</a></span><span class="t">    <span class="nam">clip_coef</span> <span class="op">=</span> <span class="nam">max_norm</span> <span class="op">/</span> <span class="op">(</span><span class="nam">total_norm</span> <span class="op">+</span> <span class="num">1e-6</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t32" class="mis show_mis"><span class="n"><a href="#t32">32</a></span><span class="t">    <span class="key">if</span> <span class="nam">clip_coef</span> <span class="op">&lt;</span> <span class="num">1</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t33" class="mis show_mis"><span class="n"><a href="#t33">33</a></span><span class="t">        <span class="key">for</span> <span class="nam">p</span> <span class="key">in</span> <span class="nam">parameters</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t34" class="mis show_mis"><span class="n"><a href="#t34">34</a></span><span class="t">            <span class="nam">p</span><span class="op">.</span><span class="nam">grad</span><span class="op">.</span><span class="nam">detach</span><span class="op">(</span><span class="op">)</span><span class="op">.</span><span class="nam">mul_</span><span class="op">(</span><span class="nam">clip_coef</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t35" class="mis show_mis"><span class="n"><a href="#t35">35</a></span><span class="t">    <span class="key">return</span> <span class="nam">total_norm</span>&nbsp;</span><span class="r"></span></p>
    <p id="t36" class="pln"><span class="n"><a href="#t36">36</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t37" class="pln"><span class="n"><a href="#t37">37</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t38" class="mis show_mis"><span class="n"><a href="#t38">38</a></span><span class="t"><span class="key">def</span> <span class="nam">clip_grad_norm</span><span class="op">(</span><span class="nam">parameters</span><span class="op">,</span> <span class="nam">max_norm</span><span class="op">,</span> <span class="nam">norm_type</span><span class="op">=</span><span class="num">2</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t39" class="pln"><span class="n"><a href="#t39">39</a></span><span class="t">    <span class="str">r"""Clips gradient norm of an iterable of parameters.</span>&nbsp;</span><span class="r"></span></p>
    <p id="t40" class="pln"><span class="n"><a href="#t40">40</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t41" class="pln"><span class="n"><a href="#t41">41</a></span><span class="t"><span class="str">    .. warning::</span>&nbsp;</span><span class="r"></span></p>
    <p id="t42" class="pln"><span class="n"><a href="#t42">42</a></span><span class="t"><span class="str">        This method is now deprecated in favor of</span>&nbsp;</span><span class="r"></span></p>
    <p id="t43" class="pln"><span class="n"><a href="#t43">43</a></span><span class="t"><span class="str">        :func:`torch.nn.utils.clip_grad_norm_`.</span>&nbsp;</span><span class="r"></span></p>
    <p id="t44" class="pln"><span class="n"><a href="#t44">44</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p id="t45" class="mis show_mis"><span class="n"><a href="#t45">45</a></span><span class="t">    <span class="nam">warnings</span><span class="op">.</span><span class="nam">warn</span><span class="op">(</span><span class="str">"torch.nn.utils.clip_grad_norm is now deprecated in favor "</span>&nbsp;</span><span class="r"></span></p>
    <p id="t46" class="pln"><span class="n"><a href="#t46">46</a></span><span class="t">                  <span class="str">"of torch.nn.utils.clip_grad_norm_."</span><span class="op">,</span> <span class="nam">stacklevel</span><span class="op">=</span><span class="num">2</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t47" class="mis show_mis"><span class="n"><a href="#t47">47</a></span><span class="t">    <span class="key">return</span> <span class="nam">clip_grad_norm_</span><span class="op">(</span><span class="nam">parameters</span><span class="op">,</span> <span class="nam">max_norm</span><span class="op">,</span> <span class="nam">norm_type</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t48" class="pln"><span class="n"><a href="#t48">48</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t49" class="pln"><span class="n"><a href="#t49">49</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t50" class="mis show_mis"><span class="n"><a href="#t50">50</a></span><span class="t"><span class="key">def</span> <span class="nam">clip_grad_value_</span><span class="op">(</span><span class="nam">parameters</span><span class="op">,</span> <span class="nam">clip_value</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t51" class="pln"><span class="n"><a href="#t51">51</a></span><span class="t">    <span class="str">r"""Clips gradient of an iterable of parameters at specified value.</span>&nbsp;</span><span class="r"></span></p>
    <p id="t52" class="pln"><span class="n"><a href="#t52">52</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t53" class="pln"><span class="n"><a href="#t53">53</a></span><span class="t"><span class="str">    Gradients are modified in-place.</span>&nbsp;</span><span class="r"></span></p>
    <p id="t54" class="pln"><span class="n"><a href="#t54">54</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t55" class="pln"><span class="n"><a href="#t55">55</a></span><span class="t"><span class="str">    Arguments:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t56" class="pln"><span class="n"><a href="#t56">56</a></span><span class="t"><span class="str">        parameters (Iterable[Tensor] or Tensor): an iterable of Tensors or a</span>&nbsp;</span><span class="r"></span></p>
    <p id="t57" class="pln"><span class="n"><a href="#t57">57</a></span><span class="t"><span class="str">            single Tensor that will have gradients normalized</span>&nbsp;</span><span class="r"></span></p>
    <p id="t58" class="pln"><span class="n"><a href="#t58">58</a></span><span class="t"><span class="str">        clip_value (float or int): maximum allowed value of the gradients.</span>&nbsp;</span><span class="r"></span></p>
    <p id="t59" class="pln"><span class="n"><a href="#t59">59</a></span><span class="t"><span class="str">            The gradients are clipped in the range</span>&nbsp;</span><span class="r"></span></p>
    <p id="t60" class="pln"><span class="n"><a href="#t60">60</a></span><span class="t"><span class="str">            :math:`\left[\text{-clip\_value}, \text{clip\_value}\right]`</span>&nbsp;</span><span class="r"></span></p>
    <p id="t61" class="pln"><span class="n"><a href="#t61">61</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p id="t62" class="mis show_mis"><span class="n"><a href="#t62">62</a></span><span class="t">    <span class="key">if</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">parameters</span><span class="op">,</span> <span class="nam">torch</span><span class="op">.</span><span class="nam">Tensor</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t63" class="mis show_mis"><span class="n"><a href="#t63">63</a></span><span class="t">        <span class="nam">parameters</span> <span class="op">=</span> <span class="op">[</span><span class="nam">parameters</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p id="t64" class="mis show_mis"><span class="n"><a href="#t64">64</a></span><span class="t">    <span class="nam">clip_value</span> <span class="op">=</span> <span class="nam">float</span><span class="op">(</span><span class="nam">clip_value</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t65" class="mis show_mis"><span class="n"><a href="#t65">65</a></span><span class="t">    <span class="key">for</span> <span class="nam">p</span> <span class="key">in</span> <span class="nam">filter</span><span class="op">(</span><span class="key">lambda</span> <span class="nam">p</span><span class="op">:</span> <span class="nam">p</span><span class="op">.</span><span class="nam">grad</span> <span class="key">is</span> <span class="key">not</span> <span class="key">None</span><span class="op">,</span> <span class="nam">parameters</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t66" class="mis show_mis"><span class="n"><a href="#t66">66</a></span><span class="t">        <span class="nam">p</span><span class="op">.</span><span class="nam">grad</span><span class="op">.</span><span class="nam">data</span><span class="op">.</span><span class="nam">clamp_</span><span class="op">(</span><span class="nam">min</span><span class="op">=</span><span class="op">-</span><span class="nam">clip_value</span><span class="op">,</span> <span class="nam">max</span><span class="op">=</span><span class="nam">clip_value</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
</div>
<div id="footer">
    <div class="content">
        <p>
            <a class="nav" href="index.html">&#xab; index</a> &nbsp; &nbsp; <a class="nav" href="https://coverage.readthedocs.io">coverage.py v5.0.3</a>,
            created at 2020-03-12 09:03
        </p>
    </div>
</div>
</body>
</html>
